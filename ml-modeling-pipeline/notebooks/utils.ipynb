{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Percentages (Polars DataFrame):\n",
      "      A     B    C\n",
      "0  25.0  50.0  0.0\n",
      "\n",
      "Missing Percentages (Pandas DataFrame):\n",
      "      A     B    C\n",
      "0  25.0  50.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "\n",
    "def calculate_missing_percentages(\n",
    "    df: Union[pl.DataFrame, pd.DataFrame], \n",
    "    missing_value: float = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the percentage of missing values in each column of a DataFrame (Polars or Pandas), \n",
    "    accounting for a specified missing value if provided.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame or pd.DataFrame): The input DataFrame which might contain missing values.\n",
    "        missing_value (float, optional): A custom value to treat as missing. If None, \n",
    "                                         the function will consider only None or NaN values as missing.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with one row showing the percentage of missing values for each column.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an unsupported DataFrame type is provided (neither Polars nor Pandas).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for Polars DataFrame\n",
    "    if isinstance(df, pl.DataFrame):\n",
    "        total_rows = df.height\n",
    "        \n",
    "        # Define the missing condition based on whether a custom missing value is provided\n",
    "        if missing_value is not None:\n",
    "            missing_condition = lambda col: (pl.col(col).is_null() | (pl.col(col) == missing_value)).sum().alias(col)\n",
    "        else:\n",
    "            missing_condition = lambda col: pl.col(col).is_null().sum().alias(col)\n",
    "        \n",
    "        # Calculate missing counts for each column\n",
    "        missing_counts = df.select([missing_condition(col) for col in df.columns])\n",
    "        \n",
    "        # Convert counts to percentages and return as Pandas DataFrame\n",
    "        missing_percentage = (missing_counts / total_rows * 100).to_pandas()\n",
    "        return missing_percentage\n",
    "    \n",
    "    # Check for Pandas DataFrame\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        # Calculate missing counts based on custom missing value or NaN\n",
    "        if missing_value is not None:\n",
    "            missing_counts = df.isnull().sum() + df.eq(missing_value).sum()\n",
    "        else:\n",
    "            missing_counts = df.isnull().sum()\n",
    "\n",
    "        # Convert counts to percentages and return as Pandas DataFrame\n",
    "        missing_percentage = (missing_counts / total_rows * 100).to_frame().T\n",
    "        return missing_percentage\n",
    "    \n",
    "    # Raise error for unsupported DataFrame types\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported DataFrame type. Please provide either a Polars or Pandas DataFrame.\")\n",
    "\n",
    "\n",
    "# Sample Data (works for both Pandas and Polars DataFrames)\n",
    "data = {\n",
    "    'A': [1, 2, None, 4],\n",
    "    'B': [None, 1, 2, None],\n",
    "    'C': [5, 6, 7, 8]\n",
    "}\n",
    "\n",
    "# Example 1: Using Polars DataFrame\n",
    "polars_df = pl.DataFrame(data)\n",
    "\n",
    "# Calculate missing percentages in Polars DataFrame\n",
    "polars_missing_percentages = calculate_missing_percentages(polars_df)\n",
    "print(\"Missing Percentages (Polars DataFrame):\")\n",
    "print(polars_missing_percentages)\n",
    "\n",
    "# Example 2: Using Pandas DataFrame\n",
    "pandas_df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate missing percentages in Pandas DataFrame\n",
    "pandas_missing_percentages = calculate_missing_percentages(pandas_df)\n",
    "print(\"\\nMissing Percentages (Pandas DataFrame):\")\n",
    "print(pandas_missing_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_specific_values(\n",
    "    df: pl.DataFrame,  # Input Polars DataFrame\n",
    "    column_name: str,  # Column name to check\n",
    "    value: Any  # Specific value to remove (can be int, float, str, etc.)\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove rows from a Polars DataFrame based on a specific value in a given column.\n",
    "\n",
    "    This function filters out rows from the DataFrame where the specified column \n",
    "    contains the given value, returning a cleaned DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): The input Polars DataFrame.\n",
    "        column_name (str): The name of the column where the specific value is checked.\n",
    "        value (Any): The value that will trigger row removal if found in the specified column.\n",
    "                     This can be an int, float, string, or other types.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: A new DataFrame with rows containing the specified value removed.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the column does not exist in the DataFrame.\n",
    "        ValueError: If the value type does not match the column type.\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        raise KeyError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    return df.filter(df[column_name] != value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (12, 4)\n",
      "┌─────────────────────┬─────┬─────┬─────────────┐\n",
      "│ time                ┆ lat ┆ lon ┆ temperature │\n",
      "│ ---                 ┆ --- ┆ --- ┆ ---         │\n",
      "│ datetime[ns]        ┆ i64 ┆ i64 ┆ f64         │\n",
      "╞═════════════════════╪═════╪═════╪═════════════╡\n",
      "│ 2023-01-01 00:00:00 ┆ 10  ┆ 30  ┆ 8.58694     │\n",
      "│ 2023-01-01 00:00:00 ┆ 10  ┆ 40  ┆ 16.899987   │\n",
      "│ 2023-01-01 00:00:00 ┆ 20  ┆ 30  ┆ 31.264098   │\n",
      "│ 2023-01-01 00:00:00 ┆ 20  ┆ 40  ┆ 25.477382   │\n",
      "│ 2023-01-02 00:00:00 ┆ 10  ┆ 30  ┆ 10.841174   │\n",
      "│ …                   ┆ …   ┆ …   ┆ …           │\n",
      "│ 2023-01-02 00:00:00 ┆ 20  ┆ 40  ┆ 26.906074   │\n",
      "│ 2023-01-03 00:00:00 ┆ 10  ┆ 30  ┆ 22.603768   │\n",
      "│ 2023-01-03 00:00:00 ┆ 10  ┆ 40  ┆ -2.146431   │\n",
      "│ 2023-01-03 00:00:00 ┆ 20  ┆ 30  ┆ 26.722581   │\n",
      "│ 2023-01-03 00:00:00 ┆ 20  ┆ 40  ┆ 17.598968   │\n",
      "└─────────────────────┴─────┴─────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "def xr_to_polars(\n",
    "    dataset: xr.Dataset,\n",
    "    variables: list = None,\n",
    "    start_date: str = None,\n",
    "    end_date: str = None,\n",
    "    time_dim_candidates: list = ['time', 'TIME', 'Time', 'datetime', 'DATE']\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert an xarray Dataset to a Polars DataFrame in a universal manner.\n",
    "\n",
    "    This function handles datasets with various time dimension names, allows\n",
    "    selection of specific variables, and supports date range filtering.\n",
    "\n",
    "    Args:\n",
    "        dataset (xr.Dataset): The input xarray dataset.\n",
    "        variables (list, optional): List of variable names to include. If None, include all variables.\n",
    "        start_date (str, optional): The start date for data selection (e.g., '1981-09-01').\n",
    "        end_date (str, optional): The end date for data selection (e.g., '2024-10-17').\n",
    "        time_dim_candidates (list, optional): List of possible time dimension names to identify the time dimension.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The converted Polars DataFrame.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If no valid time dimension is found or if specified variables are missing.\n",
    "    \"\"\"\n",
    "    # Identify the time dimension\n",
    "    time_dim = next((dim for dim in time_dim_candidates if dim in dataset.dims), None)\n",
    "    if not time_dim:\n",
    "        raise ValueError(f\"No recognized time dimension found. Tried: {time_dim_candidates}\")\n",
    "\n",
    "    # Select specific variables if provided\n",
    "    if variables is not None:\n",
    "        missing_vars = [var for var in variables if var not in dataset.data_vars]\n",
    "        if missing_vars:\n",
    "            raise ValueError(f\"Variables not found in dataset: {missing_vars}\")\n",
    "        dataset = dataset[variables]\n",
    "    \n",
    "    # Apply date filtering if specified\n",
    "    if start_date or end_date:\n",
    "        # Determine the maximum valid date dynamically if end_date is not provided\n",
    "        if not end_date:\n",
    "            max_valid_date = dataset[variables[0]].dropna(dim=time_dim, how='all')[time_dim].max().values\n",
    "            end_date = pd.to_datetime(max_valid_date).strftime('%Y-%m-%d')\n",
    "        dataset = dataset.sel({time_dim: slice(start_date, end_date)})\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    df_pandas = dataset.to_dataframe().reset_index()\n",
    "    \n",
    "    # Convert pandas DataFrame to Polars DataFrame\n",
    "    df_polars = pl.from_pandas(df_pandas)\n",
    "    \n",
    "    return df_polars\n",
    "\n",
    "# Example Usage\n",
    "# Create a sample xarray dataset\n",
    "data = xr.Dataset(\n",
    "    {\n",
    "        \"temperature\": ((\"time\", \"lat\", \"lon\"), 15 + 8 * np.random.randn(3, 2, 2)),\n",
    "        \"precipitation\": ((\"time\", \"lat\", \"lon\"), 10 * np.random.rand(3, 2, 2)),\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": pd.date_range(\"2023-01-01\", periods=3),\n",
    "        \"lat\": [10, 20],\n",
    "        \"lon\": [30, 40],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Define the list of variables and date range for selection\n",
    "variables = [\"temperature\"]\n",
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2023-01-03\"\n",
    "\n",
    "# Convert xarray dataset to Polars DataFrame\n",
    "df_polars = xr_to_polars(dataset=data, variables=variables, start_date=start_date, end_date=end_date)\n",
    "\n",
    "# Print the result\n",
    "print(df_polars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import Union, Any\n",
    "\n",
    "def convert_column_to_type(\n",
    "    df: pl.DataFrame, \n",
    "    column_name: str, \n",
    "    dtype: Union[type, str]\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a specified column in a Polars DataFrame to a desired type.\n",
    "\n",
    "    Args:\n",
    "    df (pl.DataFrame): The input Polars DataFrame.\n",
    "    column_name (str): The name of the column to convert.\n",
    "    dtype (Union[type, str]): The desired type for the column. Can be a type or string.\n",
    "\n",
    "    Returns:\n",
    "    pl.DataFrame: A new DataFrame with the specified column converted to the desired type.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified column doesn't exist in the DataFrame.\n",
    "    TypeError: If the dtype is not supported or invalid.\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "    \n",
    "    if isinstance(dtype, str):\n",
    "        try:\n",
    "            dtype = getattr(pl, dtype)\n",
    "        except AttributeError:\n",
    "            raise TypeError(f\"Invalid dtype '{dtype}' provided.\")\n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.col(column_name).cast(dtype).alias(column_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xarrays \n",
    "# pandas \n",
    "# polars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
