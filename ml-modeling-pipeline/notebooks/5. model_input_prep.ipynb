{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model input data prep\n",
    "In this notebook we will prepare 5 files for our model which are:\n",
    "\n",
    "- target - our target variable\n",
    "- mask \n",
    "- covariates - features \n",
    "- metadata \n",
    "- distance matrix"
   ],
   "id": "71eae17399162dd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "941c75b4e89eeea2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset('/Users/adamprzychodni/Documents/Repos/ml-drought-forecasting/ml-modeling-pipeline/data/04_feature/features.nc')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ds",
   "id": "54ffb02ee9bcabbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Target",
   "id": "9be2eb05b9d18b64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Extract relevant variables\n",
    "targets = ['swvl1']\n",
    "data_arrays = [ds[var] for var in targets]\n",
    "\n",
    "# 2. Flatten latitude and longitude into a single node dimension\n",
    "# Combine the latitude and longitude as one \"node\" dimension\n",
    "data_arrays_flattened = [da.stack(node=('latitude', 'longitude')) for da in data_arrays]\n",
    "\n",
    "# 3. Convert each variable's DataArray to a numpy array and add a new channel dimension\n",
    "# (so we have the shape (time, nodes, channels))\n",
    "target = np.stack([da.to_numpy() for da in data_arrays_flattened], axis=-1)"
   ],
   "id": "a4d2de36d5bb71fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "target",
   "id": "6c5e0f5612429ec3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save as .npy file\n",
    "np.save('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/target.npy', target)"
   ],
   "id": "448e09511c6cd7b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mask ",
   "id": "fe4e0375d60c5556"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "mask = np.where(~np.isnan(target), 1, 0)",
   "id": "506a45793c84fd0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "mask",
   "id": "dc8cbb0fcf547f11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save as .npy file\n",
    "np.save('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/mask.npy', mask)"
   ],
   "id": "b5431b9e2ff1f0e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Covariates ",
   "id": "213bd33b88666a50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Assuming your dataset is called ds\n",
    "# Example dataset variables: t2m, sst, tp, pev\n",
    "\n",
    "# 1. Extract relevant variables\n",
    "variables = ['t2m', 'd2m', 'msl', 'sp', 'sst', 'skt', 'e', 'pev', 'mlspr', 'ro', 'slt',\n",
    "             # 'swvl1', #\n",
    "             'stl1', 'cvh', 'lai_hv', 'cvl', 'tcc', 'mper', 'tco3', 'lsm']\n",
    "\n",
    "data_arrays = [ds[var] for var in variables]\n",
    "\n",
    "# 2. Flatten latitude and longitude into a single node dimension\n",
    "# Combine the latitude and longitude as one \"node\" dimension\n",
    "data_arrays_flattened = [da.stack(node=('latitude', 'longitude')) for da in data_arrays]\n",
    "\n",
    "# 3. Convert each variable's DataArray to a numpy array and add a new channel dimension\n",
    "# (so we have the shape (time, nodes, channels))\n",
    "covariates = np.stack([da.to_numpy() for da in data_arrays_flattened], axis=-1)\n",
    "\n",
    "covariates = np.nan_to_num(covariates, nan=0.0)"
   ],
   "id": "53f60d8349870583"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "covariates",
   "id": "b57141c32a558724"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save as .npy file\n",
    "np.save('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/covariates.npy', covariates)"
   ],
   "id": "70661c4748aa6479"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metadata",
   "id": "951969b8ed6ecf5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def generate_and_save_metadata(df: pd.DataFrame, lat_col: str = 'lat', lon_col: str = 'lon', save_directory: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates metadata from a given DataFrame by identifying unique latitude and longitude\n",
    "    combinations and assigning a unique node ID to each combination. The metadata is then\n",
    "    saved to a specified Parquet file.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - lat_col (str): The name of the column containing latitude data.\n",
    "    - lon_col (str): The name of the column containing longitude data.\n",
    "    - save_directory (str, optional): The directory where the metadata file will be saved. If None, \n",
    "                                      the file will be saved in the current working directory.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame containing the metadata with latitude, longitude, and 'node_id' as columns.\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame contains necessary columns\n",
    "    if lat_col not in df.columns or lon_col not in df.columns:\n",
    "        raise ValueError(f\"DataFrame must contain '{lat_col}' and '{lon_col}' columns.\")\n",
    "\n",
    "    # Create a unique node ID for each unique latitude-longitude combination\n",
    "    unique_lat_lon = df[[lat_col, lon_col]].drop_duplicates().reset_index(drop=True)\n",
    "    unique_lat_lon['node_id'] = unique_lat_lon.index\n",
    "\n",
    "    # Create the metadata DataFrame\n",
    "    metadata = unique_lat_lon.set_index('node_id')\n",
    "\n",
    "    # Handle save directory and save metadata to Parquet file\n",
    "    if save_directory:\n",
    "        os.makedirs(save_directory, exist_ok=True)  # Create directory if it doesn't exist\n",
    "        file_path = os.path.join(save_directory, \"metadata.parquet\")\n",
    "    else:\n",
    "        file_path = \"metadata.parquet\"  # Save in the current working directory\n",
    "\n",
    "    metadata.to_parquet(file_path)\n",
    "    print(f\"Metadata file saved at: {file_path}\")\n",
    "\n",
    "    return metadata\n"
   ],
   "id": "65bc22b990f9c4bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assume you've already stacked your data arrays as 'data_arrays_flattened'\n",
    "# We'll use one of the flattened DataArrays to extract the node information\n",
    "da_flattened = data_arrays_flattened[0]  # Using the first variable for example\n",
    "\n",
    "# Get the MultiIndex from the 'node' dimension\n",
    "node_index = da_flattened.indexes['node']\n",
    "\n",
    "# Extract latitude and longitude from the MultiIndex\n",
    "latitudes = node_index.get_level_values('latitude').values\n",
    "longitudes = node_index.get_level_values('longitude').values\n",
    "\n",
    "# Create a DataFrame with 'lat' and 'lon' columns\n",
    "df = pd.DataFrame({\n",
    "    'lat': latitudes,\n",
    "    'lon': longitudes\n",
    "})\n",
    "\n",
    "# Now use your 'generate_and_save_metadata' function\n",
    "metadata = generate_and_save_metadata(\n",
    "    df,\n",
    "    lat_col='lat',\n",
    "    lon_col='lon',\n",
    "    save_directory='ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/'\n",
    ")\n"
   ],
   "id": "67e0565a88e51835"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_parquet(\"ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/metadata.parquet\")"
   ],
   "id": "abc44cee5f5fcfce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "metadata",
   "id": "118179ba8bf00404"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Converting the DataFrame to a numpy ndarray\n",
    "metadata_array = metadata.to_numpy()"
   ],
   "id": "ce8329c9171c9d38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save as .npy file\n",
    "np.save('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/metadata.npy', metadata_array)"
   ],
   "id": "eca2d6f755362fab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Distance matrix ",
   "id": "3f2c26db2077085e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tsl.ops.similarities import geographical_distance\n",
    "# Calculate geographical distances with coordinates converted to radians.\n",
    "distances = geographical_distance(metadata_array, to_rad=True)"
   ],
   "id": "52da286a6ecdcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "distances",
   "id": "c710b27c8edc0de0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save as .npy file\n",
    "np.save('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/distances.npy', distances)"
   ],
   "id": "5716401aa9ca852a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
