{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training notebook \n",
    "\n",
    "In this notebook, we will create the graph, build the STGNN model, perform training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SoilWaterDataset object \n",
    "\n",
    "SoilWaterDataset is a fundamental object created based on TabularDataset from the TSL library. Using this object, we will be able to enabling efficient loading, preprocessing, and spatiotemporal structuring of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List\n",
    "import numpy as np \n",
    "\n",
    "from tsl.datasets.prototypes import TabularDataset\n",
    "\n",
    "class SoilWaterDataset(TabularDataset):\n",
    "\n",
    "    similarity_options = {'distance', 'correlation'}\n",
    "\n",
    "    def __init__(self,\n",
    "                 root: str = None\n",
    "                 ):\n",
    "\n",
    "        self.root = root\n",
    "\n",
    "        # Load data\n",
    "        target, mask, u, dist, metadata = self.load()\n",
    "\n",
    "        covariates = {\n",
    "            'u': (u),\n",
    "            'metadata' : (metadata),\n",
    "            'distances': (dist)\n",
    "        }\n",
    "\n",
    "        super().__init__(target=target,\n",
    "                         mask=mask,\n",
    "                         covariates=covariates,\n",
    "                         similarity_score='distance',\n",
    "                         temporal_aggregation='mean',\n",
    "                         spatial_aggregation='mean',\n",
    "                         name='DroughtDataset')\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load data from files.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Containing target, mask, covariates, distances, and metadata.\n",
    "        \"\"\"\n",
    "        target_path = f\"{self.root}target.npy\"\n",
    "        mask_path = f\"{self.root}mask.npy\"\n",
    "        dist_path = f\"{self.root}distances.npy\"\n",
    "        covariates_path = f\"{self.root}covariates.npy\"\n",
    "        metadata_path = f\"{self.root}metadata.npy\"\n",
    "\n",
    "        # Load main data\n",
    "        target = np.load(target_path)\n",
    "        mask = np.load(mask_path)\n",
    "        u = np.load(covariates_path)\n",
    "        dist = np.load(dist_path)\n",
    "        metadata = np.load(metadata_path)\n",
    "\n",
    "        return target, mask, u, dist, metadata\n",
    "\n",
    "\n",
    "    def compute_similarity(self, method: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute similarity matrix based on the specified method.\n",
    "\n",
    "        Args:\n",
    "            method (str): The similarity computation method ('distance' or 'correlation').\n",
    "            **kwargs: Additional keyword arguments for similarity computation.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Computed similarity matrix.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unknown similarity method is provided.\n",
    "        \"\"\"\n",
    "        if method == \"distance\":\n",
    "            # Calculate a Gaussian kernel similarity from the distance matrix, using a default or provided 'theta'\n",
    "            theta = kwargs.get('theta', np.std(self.distances))\n",
    "            return self.gaussian_kernel(self.distances, theta=theta)\n",
    "        elif method == \"correlation\":\n",
    "            # Compute the average correlation between nodes over the target features\n",
    "            # Reshape target data to have nodes as columns\n",
    "            target_values = self.target.values.reshape(len(self.target), -1, len(self.target_node_feature))\n",
    "            # Average over the target features\n",
    "            target_mean = target_values.mean(axis=2)\n",
    "            # Compute correlation between nodes\n",
    "            corr = np.corrcoef(target_mean, rowvar=False)\n",
    "            return (corr + 1) / 2  # Normalize to [0, 1]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown similarity method: {method}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian_kernel(distances, theta):\n",
    "        \"\"\"\n",
    "        Compute Gaussian kernel similarity from distances.\n",
    "\n",
    "        Args:\n",
    "            distances (numpy.ndarray): Distance matrix.\n",
    "            theta (float): Kernel bandwidth parameter.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Gaussian kernel similarity matrix.\n",
    "        \"\"\"\n",
    "        return np.exp(-(distances ** 2) / (2 * (theta ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SoilWaterDataset(root='ml-drought-forecasting/soil-water-forecasting/data/05_model_input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-4.2025931e-06],\n",
       "        [-4.2025931e-06],\n",
       "        [-4.2025931e-06],\n",
       "        ...,\n",
       "        [-4.2025931e-06],\n",
       "        [-4.2025931e-06],\n",
       "        [-4.2025931e-06]],\n",
       "\n",
       "       [[-9.8175369e-06],\n",
       "        [-9.8175369e-06],\n",
       "        [-9.8175369e-06],\n",
       "        ...,\n",
       "        [-9.8175369e-06],\n",
       "        [-9.8175369e-06],\n",
       "        [-9.8175369e-06]],\n",
       "\n",
       "       [[ 4.5859342e-06],\n",
       "        [ 4.5859342e-06],\n",
       "        [ 4.5859342e-06],\n",
       "        ...,\n",
       "        [ 4.5859342e-06],\n",
       "        [ 4.5859342e-06],\n",
       "        [ 4.5859342e-06]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.5608966e-06],\n",
       "        [ 1.5608966e-06],\n",
       "        [ 1.5608966e-06],\n",
       "        ...,\n",
       "        [ 1.5608966e-06],\n",
       "        [ 1.5608966e-06],\n",
       "        [ 1.5608966e-06]],\n",
       "\n",
       "       [[ 1.2002420e-06],\n",
       "        [ 1.2002420e-06],\n",
       "        [ 1.2002420e-06],\n",
       "        ...,\n",
       "        [ 1.2002420e-06],\n",
       "        [ 1.2002420e-06],\n",
       "        [ 1.2002420e-06]],\n",
       "\n",
       "       [[-4.9313530e-06],\n",
       "        [-4.9313530e-06],\n",
       "        [-4.9313530e-06],\n",
       "        ...,\n",
       "        [-4.9313530e-06],\n",
       "        [-4.9313530e-06],\n",
       "        [-4.9313530e-06]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has missing values: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Has missing values: {dataset.has_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_mask(dataset.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u': array([[[ 2.94796997e+02,  2.91070618e+02,  1.01160688e+05, ...,\n",
       "          -1.19325705e-09,  5.65088913e-03,  0.00000000e+00],\n",
       "         [ 2.94720825e+02,  2.90953430e+02,  1.01172688e+05, ...,\n",
       "          -1.19325705e-09,  5.64719364e-03,  0.00000000e+00],\n",
       "         [ 2.94691528e+02,  2.90701477e+02,  1.01184812e+05, ...,\n",
       "          -1.19325705e-09,  5.64600155e-03,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.91923950e+02,  2.87041321e+02,  1.01571438e+05, ...,\n",
       "          -1.19325705e-09,  5.84162399e-03,  0.00000000e+00],\n",
       "         [ 2.92054810e+02,  2.87088196e+02,  1.01587562e+05, ...,\n",
       "          -1.19325705e-09,  5.82457706e-03,  0.00000000e+00],\n",
       "         [ 2.92066528e+02,  2.87248352e+02,  1.01605938e+05, ...,\n",
       "          -1.19325705e-09,  5.80800697e-03,  0.00000000e+00]],\n",
       " \n",
       "        [[ 2.95360138e+02,  2.91539581e+02,  1.01597125e+05, ...,\n",
       "           1.60071068e-09,  5.51155582e-03,  0.00000000e+00],\n",
       "         [ 2.95342560e+02,  2.91631378e+02,  1.01593375e+05, ...,\n",
       "           1.60071068e-09,  5.50988689e-03,  0.00000000e+00],\n",
       "         [ 2.95449982e+02,  2.91689972e+02,  1.01594500e+05, ...,\n",
       "           1.60071068e-09,  5.50631061e-03,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.91481232e+02,  2.87076691e+02,  1.01299875e+05, ...,\n",
       "           1.60071068e-09,  5.63720241e-03,  0.00000000e+00],\n",
       "         [ 2.91602325e+02,  2.87256378e+02,  1.01321125e+05, ...,\n",
       "           1.60071068e-09,  5.64340129e-03,  0.00000000e+00],\n",
       "         [ 2.91785919e+02,  2.87465363e+02,  1.01342625e+05, ...,\n",
       "           1.60071068e-09,  5.64995781e-03,  0.00000000e+00]],\n",
       " \n",
       "        [[ 2.95027771e+02,  2.90736176e+02,  1.01465000e+05, ...,\n",
       "          -2.79396772e-09,  5.47569245e-03,  0.00000000e+00],\n",
       "         [ 2.95137146e+02,  2.90894379e+02,  1.01442125e+05, ...,\n",
       "          -2.79396772e-09,  5.46853989e-03,  0.00000000e+00],\n",
       "         [ 2.95412537e+02,  2.91087738e+02,  1.01422375e+05, ...,\n",
       "          -2.79396772e-09,  5.45459241e-03,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.90377380e+02,  2.85150238e+02,  1.01798125e+05, ...,\n",
       "          -2.79396772e-09,  5.71232289e-03,  0.00000000e+00],\n",
       "         [ 2.90340271e+02,  2.85126801e+02,  1.01812500e+05, ...,\n",
       "          -2.79396772e-09,  5.72412461e-03,  0.00000000e+00],\n",
       "         [ 2.90508240e+02,  2.85286957e+02,  1.01824875e+05, ...,\n",
       "          -2.79396772e-09,  5.73604554e-03,  0.00000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2.91278564e+02,  2.86795044e+02,  1.01857500e+05, ...,\n",
       "          -2.64844857e-09,  6.75473735e-03,  0.00000000e+00],\n",
       "         [ 2.91165283e+02,  2.86777466e+02,  1.01846625e+05, ...,\n",
       "          -2.64844857e-09,  6.74591586e-03,  0.00000000e+00],\n",
       "         [ 2.91257080e+02,  2.86828247e+02,  1.01843625e+05, ...,\n",
       "          -2.64844857e-09,  6.73268363e-03,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.97968018e+02,  2.93185669e+02,  1.02089625e+05, ...,\n",
       "          -2.64844857e-09,  5.92909381e-03,  0.00000000e+00],\n",
       "         [ 2.97831299e+02,  2.93000122e+02,  1.02103750e+05, ...,\n",
       "          -2.64844857e-09,  5.93505427e-03,  0.00000000e+00],\n",
       "         [ 2.97616455e+02,  2.92796997e+02,  1.02115500e+05, ...,\n",
       "          -2.64844857e-09,  5.94208762e-03,  0.00000000e+00]],\n",
       " \n",
       "        [[ 2.94269531e+02,  2.91275787e+02,  1.01399625e+05, ...,\n",
       "          -8.00355338e-10,  6.20374456e-03,  0.00000000e+00],\n",
       "         [ 2.94136719e+02,  2.91182037e+02,  1.01439125e+05, ...,\n",
       "          -8.00355338e-10,  6.19683042e-03,  0.00000000e+00],\n",
       "         [ 2.93890625e+02,  2.91254303e+02,  1.01475250e+05, ...,\n",
       "          -8.00355338e-10,  6.18622079e-03,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.95574219e+02,  2.90769928e+02,  1.01831375e+05, ...,\n",
       "          -8.00355338e-10,  5.60722128e-03,  0.00000000e+00],\n",
       "         [ 2.95650391e+02,  2.90848053e+02,  1.01843000e+05, ...,\n",
       "          -8.00355338e-10,  5.61902300e-03,  0.00000000e+00],\n",
       "         [ 2.95718750e+02,  2.90875397e+02,  1.01855250e+05, ...,\n",
       "          -8.00355338e-10,  5.62891737e-03,  0.00000000e+00]],\n",
       " \n",
       "        [[ 2.94670990e+02,  2.90892212e+02,  1.01235938e+05, ...,\n",
       "          -2.72120815e-09,  5.95810637e-03,  0.00000000e+00],\n",
       "         [ 2.94553802e+02,  2.90939087e+02,  1.01247938e+05, ...,\n",
       "          -2.72120815e-09,  5.95154986e-03,  0.00000000e+00],\n",
       "         [ 2.94516693e+02,  2.90890259e+02,  1.01260062e+05, ...,\n",
       "          -2.72120815e-09,  5.94177470e-03,  0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.93079193e+02,  2.87925415e+02,  1.01529812e+05, ...,\n",
       "          -2.72120815e-09,  5.60620055e-03,  0.00000000e+00],\n",
       "         [ 2.93128021e+02,  2.87952759e+02,  1.01510438e+05, ...,\n",
       "          -2.72120815e-09,  5.63040003e-03,  0.00000000e+00],\n",
       "         [ 2.93157318e+02,  2.88009399e+02,  1.01494062e+05, ...,\n",
       "          -2.72120815e-09,  5.65674528e-03,  0.00000000e+00]]],\n",
       "       dtype=float32),\n",
       " 'metadata': array([[ -30., -180.],\n",
       "        [ -30., -179.],\n",
       "        [ -30., -178.],\n",
       "        ...,\n",
       "        [  30.,  177.],\n",
       "        [  30.,  178.],\n",
       "        [  30.,  179.]], dtype=float32),\n",
       " 'distances': array([[   0.     ,   96.29746,  192.59308, ..., 6679.2637 , 6675.0654 ,\n",
       "         6672.545  ],\n",
       "        [  96.29746,    0.     ,   96.29746, ..., 6685.1367 , 6679.2637 ,\n",
       "         6675.0654 ],\n",
       "        [ 192.59308,   96.29746,    0.     , ..., 6692.6807 , 6685.1367 ,\n",
       "         6679.2637 ],\n",
       "        ...,\n",
       "        [6679.2637 , 6685.1367 , 6692.6807 , ...,    0.     ,   96.29746,\n",
       "          192.59308],\n",
       "        [6675.0654 , 6679.2637 , 6685.1367 , ...,   96.29746,    0.     ,\n",
       "           96.29746],\n",
       "        [6672.545  , 6675.0654 , 6679.2637 , ...,  192.59308,   96.29746,\n",
       "            0.     ]], dtype=float32)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create connectivity to our graph \n",
    "\n",
    "Here, we adjust the connectivity to retain only the five nearest neighbors (knn=5) per node, while excluding self-loops and normalizing along the specified axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:38:41.500430Z",
     "start_time": "2024-11-08T18:38:41.498443Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim = dataset.compute_similarity(\"distance\")  # or dataset.compute_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.9998158 , 0.9992636 , ..., 0.4123332 , 0.41279253,\n",
       "        0.41306838],\n",
       "       [0.9998158 , 1.        , 0.9998158 , ..., 0.411691  , 0.4123332 ,\n",
       "        0.41279253],\n",
       "       [0.9992636 , 0.9998158 , 1.        , ..., 0.41086674, 0.411691  ,\n",
       "        0.4123332 ],\n",
       "       ...,\n",
       "       [0.4123332 , 0.411691  , 0.41086674, ..., 1.        , 0.9998158 ,\n",
       "        0.9992636 ],\n",
       "       [0.41279253, 0.4123332 , 0.411691  , ..., 0.9998158 , 1.        ,\n",
       "        0.9998158 ],\n",
       "       [0.41306838, 0.41279253, 0.4123332 , ..., 0.9992636 , 0.9998158 ,\n",
       "        1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust connectivity to reduce the number of edges\n",
    "connectivity = dataset.get_connectivity(          \n",
    "    knn=5,     \n",
    "    include_self=False,\n",
    "    normalize_axis=1,\n",
    "    layout=\"edge_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, edge_weight = connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 21959, 21959, 21959],\n",
       "       [    1,   359,   360, ..., 21599, 21600, 21958]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20002224, 0.20002224, 0.20000282, ..., 0.20000282, 0.20002224,\n",
       "       0.20002224], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_matrix(matrix):\n",
    "#     return pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (21960, 21960):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21950</th>\n",
       "      <th>21951</th>\n",
       "      <th>21952</th>\n",
       "      <th>21953</th>\n",
       "      <th>21954</th>\n",
       "      <th>21955</th>\n",
       "      <th>21956</th>\n",
       "      <th>21957</th>\n",
       "      <th>21958</th>\n",
       "      <th>21959</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21955</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21956</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21957</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21958</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21959</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21960 rows × 21960 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5      6      \\\n",
       "0      0.000000  0.200022  0.000000  0.000000  0.000000  0.000000    0.0   \n",
       "1      0.200022  0.000000  0.200022  0.000000  0.000000  0.000000    0.0   \n",
       "2      0.000000  0.200022  0.000000  0.200022  0.000000  0.000000    0.0   \n",
       "3      0.000000  0.000000  0.200022  0.000000  0.200022  0.000000    0.0   \n",
       "4      0.000000  0.000000  0.000000  0.200022  0.000000  0.200022    0.0   \n",
       "...         ...       ...       ...       ...       ...       ...    ...   \n",
       "21955  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0   \n",
       "21956  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0   \n",
       "21957  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0   \n",
       "21958  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0   \n",
       "21959  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.0   \n",
       "\n",
       "       7      8      9      ...  21950  21951  21952  21953     21954  \\\n",
       "0        0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "1        0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "2        0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "3        0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "4        0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "...      ...    ...    ...  ...    ...    ...    ...    ...       ...   \n",
       "21955    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.200022   \n",
       "21956    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "21957    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "21958    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "21959    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0  0.000000   \n",
       "\n",
       "          21955     21956     21957     21958     21959  \n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "21955  0.000000  0.200022  0.000000  0.000000  0.000000  \n",
       "21956  0.200022  0.000000  0.200022  0.000000  0.000000  \n",
       "21957  0.000000  0.200022  0.000000  0.200022  0.000000  \n",
       "21958  0.000000  0.000000  0.200022  0.000000  0.200022  \n",
       "21959  0.000000  0.000000  0.000000  0.200022  0.000000  \n",
       "\n",
       "[21960 rows x 21960 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from tsl.ops.connectivity import edge_index_to_adj\n",
    "# \n",
    "# adj = edge_index_to_adj(edge_index, edge_weight)\n",
    "# print(f'A {adj.shape}:')\n",
    "# print_matrix(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create torch_dataset \n",
    "\n",
    "torch_dataset, created using SpatioTemporalDataset from the tsl library, structures time-series and spatial data (target, covariates, mask, and connectivity) into a form optimized for spatiotemporal model training, enabling easy handling of lookback windows and prediction horizons in forecasting tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data import SpatioTemporalDataset\n",
    "\n",
    "# covariates=dict(u=dataset.covariates['u'])\n",
    "covariates=dataset.covariates\n",
    "mask = dataset.mask\n",
    "\n",
    "torch_dataset = SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      mask=mask,\n",
    "                                      covariates=covariates,\n",
    "                                      connectivity=connectivity,\n",
    "                                      horizon=6, # Predict 7 step ahead\n",
    "                                      window=12, # Use 30 timestamps to predict the next one\n",
    "                                      stride=1 # Move 7 step forward each time\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dataset.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datamodule\n",
    "\n",
    "datamodule, created with SpatioTemporalDataModule, manages the SpatioTemporalDataset by applying scaling, splitting data into train/validation/test sets, and preparing data loaders with batch processing, enabling efficient, modular, and scalable data handling for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scalers = {\n",
    "    'target': MinMaxScaler(axis=(0, 1)),\n",
    "    'u': MinMaxScaler(axis=(0, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "                                 \n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=0.35, test_len=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=None, val_len=None, test_len=None, scalers=[target, u], batch_size=8)\n"
     ]
    }
   ],
   "source": [
    "# Create a SpatioTemporalDataModule\n",
    "datamodule = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    mask_scaling=True,\n",
    "    splitter=splitter,\n",
    "    batch_size=8,\n",
    "    workers=15,\n",
    "    )\n",
    "\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatioTemporalDataModule(train_len=141, val_len=69, test_len=25, scalers=[target, u], batch_size=8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]),\n",
       " 'val': array([153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
       "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
       "        218, 219, 220, 221]),\n",
       " 'test': array([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.splitter.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create STGNN Model Architecture\n",
    "\n",
    "The **TimeAndGraphAnisoModel** is built based on code from [HD-TTS\n",
    " repository](https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/time_and_graph_anisotropic.py) and the research paper by Cini et al. (2023d). This model utilizes spatiotemporal architectures equipped with anisotropic message passing for effective time and space representation.\n",
    "\n",
    "### Reference\n",
    "Cini, A., Marisca, I., Zambon, D., and Alippi, C. *Taming Local Effects in Graph-Based Spatiotemporal Forecasting.* In *Advances in Neural Information Processing Systems,* volume 36, pp. 55375–55393. Curran Associates, Inc., 2023.  \n",
    "[https://arxiv.org/abs/2302.04071](https://arxiv.org/abs/2302.04071)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from torch import Tensor, nn\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "\n",
    "from tsl.nn.blocks.decoders import MLPDecoder\n",
    "from tsl.nn.blocks.encoders import DCRNN, ConditionalBlock\n",
    "from tsl.nn.models.base_model import BaseModel\n",
    "\n",
    "\n",
    "class DCRNNModel(BaseModel):\n",
    "    r\"\"\"The Diffusion Convolutional Recurrent Neural Network from the paper\n",
    "    `\"Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic\n",
    "    Forecasting\" <https://arxiv.org/abs/1707.01926>`_ (Li et al., ICLR 2018).\n",
    "\n",
    "    Differently from the original implementation, the recurrent decoder is\n",
    "    substituted with a fixed-length nonlinear readout.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): Number of features of the input sample.\n",
    "        output_size (int): Number of output channels.\n",
    "        horizon (int): Number of future time steps to forecast.\n",
    "        exog_size (int): Number of features of the input covariate,\n",
    "            if any. (default: :obj:`0`)\n",
    "        hidden_size (int): Number of hidden units.\n",
    "            (default: :obj:`32`)\n",
    "        kernel_size (int): Order of the spatial diffusion process.\n",
    "            (default: :obj:`2`)\n",
    "        ff_size (int): Number of units in the nonlinear readout.\n",
    "            (default: :obj:`256`)\n",
    "        n_layers (int): Number of DCRNN cells.\n",
    "            (default: :obj:`1`)\n",
    "        dropout (float): Dropout probability.\n",
    "            (default: :obj:`0`)\n",
    "        activation (str): Activation function in the readout.\n",
    "            (default: :obj:`'relu'`)\n",
    "    \"\"\"\n",
    "\n",
    "    return_type = Tensor\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 output_size: int,\n",
    "                 horizon: int,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 kernel_size: int = 2,\n",
    "                 ff_size: int = 256,\n",
    "                 n_layers: int = 1,\n",
    "                 cache_support: bool = False,\n",
    "                 dropout: float = 0.,\n",
    "                 activation: str = 'relu'):\n",
    "        super(DCRNNModel, self).__init__()\n",
    "        if exog_size:\n",
    "            self.input_encoder = ConditionalBlock(input_size=input_size,\n",
    "                                                  exog_size=exog_size,\n",
    "                                                  output_size=hidden_size,\n",
    "                                                  activation=activation)\n",
    "        else:\n",
    "            self.input_encoder = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.dcrnn = DCRNN(input_size=hidden_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           n_layers=n_layers,\n",
    "                           k=kernel_size,\n",
    "                           return_only_last_state=True)\n",
    "        self.cache_support = cache_support\n",
    "\n",
    "        self.readout = MLPDecoder(input_size=hidden_size,\n",
    "                                  hidden_size=ff_size,\n",
    "                                  output_size=output_size,\n",
    "                                  horizon=horizon,\n",
    "                                  activation=activation,\n",
    "                                  dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Adj,\n",
    "                edge_weight: OptTensor = None,\n",
    "                u: OptTensor = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if u is not None:\n",
    "            if u.dim() == 3:\n",
    "                u = rearrange(u, 'b s c -> b s 1 c')\n",
    "            x = self.input_encoder(x, u)\n",
    "        else:\n",
    "            x = self.input_encoder(x)\n",
    "\n",
    "        out = self.dcrnn(x,\n",
    "                         edge_index,\n",
    "                         edge_weight,\n",
    "                         cache_support=self.cache_support)\n",
    "        return self.readout(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model \n",
    "\n",
    "Model is configured with hidden units, feed-forward layers, multiple SpatioTemporalConvNet blocks, and utilizes temporal and spatial convolution kernels, layer normalization, and gated mechanisms; it adapts to the dataset’s input size, number of nodes, horizon, and available exogenous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 32          # Number of hidden units\n",
    "ff_size = 64             # Number of units in the feed-forward layers\n",
    "n_layers = 3              # Number of SpatioTemporalConvNet blocks\n",
    "kernel_size = 3  \n",
    "# spatial_kernel_size = 3   # Order of the spatial diffusion process\n",
    "# norm='layer'\n",
    "# gated=True\n",
    "\n",
    "input_size = torch_dataset.n_channels\n",
    "output_size = torch_dataset.n_channels\n",
    "# n_nodes = torch_dataset.n_nodes\n",
    "horizon = torch_dataset.horizon\n",
    "exog_size = torch_dataset.input_map.u.shape[-1] if 'u' in torch_dataset else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeAndGraphAnisoModel(\n",
      "  (emb): None\n",
      "  (encoder): Linear(in_features=20, out_features=32, bias=True)\n",
      "  (decoder): MLPDecoder(\n",
      "    (readout): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Dense(\n",
      "          (affinity): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (activation): ELU(alpha=1.0)\n",
      "          (dropout): Identity()\n",
      "        )\n",
      "      )\n",
      "      (readout): Linear(in_features=32, out_features=6, bias=True)\n",
      "    )\n",
      "    (rearrange): Rearrange('b n (h f) -> b h n f', f=1, h=6)\n",
      "  )\n",
      "  (stmp_conv): GraphAnisoGRU(cell=GraphAnisoGRUCell, return_only_last_state=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DCRNNModel(\n",
    "    input_size=input_size,\n",
    "    output_size=output_size,\n",
    "    horizon=horizon,\n",
    "    exog_size=exog_size,\n",
    "    hidden_size=hidden_size,\n",
    "    kernel_size=kernel_size,\n",
    "    ff_size=ff_size,\n",
    "    n_layers=n_layers,\n",
    ")\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "Number of model (TimeAndGraphAnisoModel) parameters:     23913\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training \n",
    "\n",
    "This setup initializes a Predictor for the model with a masked mean-squared error loss function and multiple evaluation metrics (MSE, MAE, MAPE, and specific MSE at selected timesteps), then configures a Trainer using PyTorch Lightning with early stopping and model checkpointing based on validation MSE, gradient clipping to prevent exploding gradients, and 16-bit precision for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.metrics.torch import MaskedMSE, MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Predictor\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = MaskedMSE()\n",
    "\n",
    "# Setup metrics\n",
    "metrics = {\n",
    "    'mse': MaskedMSE(),\n",
    "    'mae': MaskedMAE(),\n",
    "    'mape': MaskedMAPE(),\n",
    "    'mse_at_3': MaskedMSE(at=2),  # '2' indicates the third time step\n",
    "    'mse_at_6': MaskedMSE(at=5)\n",
    "}\n",
    "\n",
    "# Setup predictor\n",
    "predictor = Predictor(\n",
    "    model=model,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs={'lr': 0.001},\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_mse',\n",
    "    patience=30,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Logs \n",
    "dirpath = Path('ml-drought-forecasting/soil-water-forecasting/data/06_models/DCRNN/logs')\n",
    "\n",
    "dirpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=dirpath,\n",
    "    save_top_k=1,\n",
    "    monitor='val_mse', \n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Setup trainer\n",
    "trainer = pl.Trainer(max_epochs=100,\n",
    "                    #  logger=logger,\n",
    "                    #  limit_train_batches=100,  # end an epoch after 200 updates\n",
    "                     callbacks=[early_stop_callback, checkpoint_callback],\n",
    "                     log_every_n_steps=2,\n",
    "                     gradient_clip_val=1.0,    # Prevent exploding gradients\n",
    "                     precision=16\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set float32 matmul precision to 'medium' or 'high'\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /teamspace/studios/this_studio/logs exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMSE              | 0      | train\n",
      "1 | train_metrics | MetricCollection       | 0      | train\n",
      "2 | val_metrics   | MetricCollection       | 0      | train\n",
      "3 | test_metrics  | MetricCollection       | 0      | train\n",
      "4 | model         | TimeAndGraphAnisoModel | 23.9 K | train\n",
      "-----------------------------------------------------------------\n",
      "23.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.9 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n",
      "81        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ef788bfe66470dba31791d9a1f3aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "Arguments ['metadata', 'distances'] are filtered out. Only args ['x', 'u', 'edge_index', 'edge_weight'] are forwarded to the model (TimeAndGraphAnisoModel).\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fdded76ed044b5966b59f18f64134e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f94b55236bf4187abe7511022522a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751f06a83c1e4be4a912fdda77d84c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d33fb6b2ca45b5a3d7e3ba5c468164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b92fbcdbd1467bba6310fe8f1096d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56429617ebe7440098d12231d3cd908c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22021f24e08445fb61e9c703e9cf7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2f9c83bac5424a80a7b0ef2938d7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c129d8d767d42e381a8e842fea54887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d412627975b4eb9bf8294bdb743260a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d507cf54f224a4988d0ee1e918d208e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8c1eadb96947958bca380be1d15234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5c2084091249748737df2ffeb66e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc519c91abd4474a3262e935a4cde22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9405bc0a7dcf49e0827e30acb5799b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796b52de1ef6469fb130071ee4830b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee55e982c51b44219dbb7eb54019f691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef752c971e46421db2975f11fad35484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620e48cd7ccb46d0b28600a28ca98194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b8ef970eef4601b276aed3fcd70584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc62cb74eb3d4ac09a3045ae19c96fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b597c6484440609af76f19cb739535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0ce5efb6934476bd6a85d309190157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2daafe9991bc4e569e73102056c1070b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36d66daa7e744e88139cf7006b98b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ca9516e3674debb3423b7ac6cb64d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea35e825b714557b2b54eee5137f8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4fd0df8aca445f83c52e8f76c06272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a727884f3040bcb2464f09e56562c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d895ed5ba54832b73703d6d886fdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2997783544f54c99a8e6958c09d48a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d030d2ef52f34e778fadde872009744c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c9759e169b4e73bab926ffe255830c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2fa211a6174f65ab09de8989293fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46666f6bd3c2447c9887809c2d82f261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aad08c6cb84443fb98f92eef1d06e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dbe5dfee2547a986bd7d64a695d5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4394c12e21ef45d39ba2d94f895a7455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89598bd218a147f6aad24fd9f5e34b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d38e4dd8bc418da3eaaa8d00a4fb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e724f948154b47b7ca085ca7d6714c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f860748940124989974b88a1190e2a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01ed8717a51418f8d60f5eb958a2b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890bc7f648724d149f74e8ac54f3ddcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0591a711c34501b3055973db7ab27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c633de09dd8f45979d40c3e215fc4a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42826d020fd342609ebdf6460159a02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5edd44497f4b818769ff577f95bf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23733bd2e0774c069862a0f5fa56f9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e4f21f59484ea39eb846dcb298b772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64839d62e7846088fa5245127922bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b5127d78b0480d9250ef62152e27d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a2351b5cb14e4da806a44272cbd9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d005fa0e6e4d37ac3032f3408b1368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffd003f2fdf49628111d69cd9c34dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e27f994e834e37af9b7605a92b3e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c1316d1abd4d65a6c24aab66a50ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382c1af227ce40f69e764f24b85cefff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8a213f64d24f14bb1a31ab2e571eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033f1436841b4ff79cd1e94d5cfd0b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28f31cfef79440cb555041bce549490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea5a3f5bfd7461da8534eb5801ddd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601df9b13cad4cc2acffb2c4fc0ed1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb4d715d8114c488b46a0bf770da777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54a46cc11eb4797a0a0e8a751c6fba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5651c483f76a4fb88c3f11c85f4d4d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964671a36647470aa81cad469d32e37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37923ae5e95480389e714eac3cf2b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1e8dadc3e746bd8b78532312109894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f90e5380a1b4a23b8f661b0cc88cda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62240e126ff4d60a1d2b57658435ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4569a0ca4334a95be779a70b712858b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157e2647ff9e404d8ff02027b8863f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52326431bd1448b497ca4dc4669031f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1b3418c59f494b868557140e853e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7428c72d74a8448d9c1eeea22d111988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9f2704cba8457b8380d368925ed140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b866505a3459403986f1406cb4cd4bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f5a162815247adb5dda0d1d43418a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e4cb989bdb4d0797d4fb19ec83753e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2343318ace4980b8a2d2dba230b40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2372c6eadff4bcea38acd5348888ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5603167b41f24925915272584aeef384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025750a06cb84fdfae2dd000f74fae23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ef3698cc7a4d999d9a385d51204027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27260f65d6b0407b8f3be74ff7edce6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d006b2348c45d3b0f2b857fa3be98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ffa11c951c4d8c8aaf4fdf6ca0218a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12a8898b3904e948926abe63a59d1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d980cd3dca494a109ede9ec1e63658f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab30547aeabb4949aeff00b8e18fcb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29b9df5e3394f3ebfa91887a7530c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7783cd37014c78836754d0668eb1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339398ffca82431fba890572d7680f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903b7bb701b645a9bcf35837203ada16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6829c3aeba3c499db7e39643a7173f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b263c84dada4e1b83d8d275ce7f0a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c5617498d047bd90bc8d4909357088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223512fded9f4eb3bc1f479becbb0bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49b985d18a14632a9aa308b99783d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded8cd6c9ec4425a8b2e992852a4dc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "trainer.fit(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the best checkpoint\n",
    "best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "print(f\"Best checkpoint saved at: {best_checkpoint_path}\")\n",
    "\n",
    "# Load the model from the best checkpoint\n",
    "from pytorch_lightning.utilities.memory import load_obj\n",
    "\n",
    "trained_model = TimeAndGraphAnisoModel(\n",
    "    input_size=input_size,\n",
    "    horizon=horizon,\n",
    "    n_nodes=n_nodes,\n",
    "    output_size=input_size,\n",
    "    exog_size=exog_size,\n",
    "    hidden_size=hidden_size\n",
    ")\n",
    "\n",
    "# Load checkpoint weights\n",
    "state_dict = torch.load(best_checkpoint_path)[\"state_dict\"]\n",
    "trained_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/logs/epoch=86-step=1479.ckpt\n"
     ]
    }
   ],
   "source": [
    "# print(checkpoint_callback.best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n",
      "Predictor with already instantiated model is loading a state_dict from /teamspace/studios/this_studio/logs/epoch=86-step=1479.ckpt. Cannot  check if model hyperparameters are the same.\n"
     ]
    }
   ],
   "source": [
    "predictor.load_model(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n",
      "Predictor with already instantiated model is loading a state_dict from /teamspace/studios/this_studio/logs/epoch=86-step=1479.ckpt. Cannot  check if model hyperparameters are the same.\n"
     ]
    }
   ],
   "source": [
    "predictor.load_model('/teamspace/studios/this_studio/logs/epoch=86-step=1479.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbcba6804a240f7b7c07efa2568a66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arguments ['metadata', 'distances'] are filtered out. Only args ['x', 'edge_index', 'edge_weight', 'u'] are forwarded to the model (TimeAndGraphAnisoModel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.000349479349097237    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.007187105715274811    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mape         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2584.482177734375     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.000349479349097237    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mse_at_3       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00036978835123591125   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mse_at_6       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00036310526775196195   </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.000349479349097237   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.007187105715274811   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mape        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2584.482177734375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.000349479349097237   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mse_at_3      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00036978835123591125  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mse_at_6      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00036310526775196195  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_mae': 0.007187105715274811,\n",
       "  'test_mape': 2584.482177734375,\n",
       "  'test_mse': 0.000349479349097237,\n",
       "  'test_mse_at_3': 0.00036978835123591125,\n",
       "  'test_mse_at_6': 0.00036310526775196195,\n",
       "  'test_loss': 0.000349479349097237}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550f45a7372648b2ad43f5e73dd70507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00033514376264065504   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0071140737272799015   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_mape          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     636.721435546875      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00033514376264065504   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_mse_at_3        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0003464221372269094   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_mse_at_6        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0003566509112715721   </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00033514376264065504  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0071140737272799015  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_mape         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    636.721435546875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00033514376264065504  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_mse_at_3       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0003464221372269094  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_mse_at_6       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0003566509112715721  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_mae': 0.0071140737272799015,\n",
       "  'val_mape': 636.721435546875,\n",
       "  'val_mse': 0.00033514376264065504,\n",
       "  'val_mse_at_3': 0.0003464221372269094,\n",
       "  'val_mse_at_6': 0.0003566509112715721,\n",
       "  'val_loss': 0.00033514376264065504}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e86fb26dfa417096e17f19b325808d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_test = trainer.predict(predictor, datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]),\n",
       " 'val': array([153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
       "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
       "        218, 219, 220, 221]),\n",
       " 'test': array([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(ds['date'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01', '2000-02-01', '2000-03-01', '2000-04-01',\n",
       "               '2000-05-01', '2000-06-01', '2000-07-01', '2000-08-01',\n",
       "               '2000-09-01', '2000-10-01',\n",
       "               ...\n",
       "               '2022-03-01', '2022-04-01', '2022-05-01', '2022-06-01',\n",
       "               '2022-07-01', '2022-08-01', '2022-09-01', '2022-10-01',\n",
       "               '2022-11-01', '2022-12-01'],\n",
       "              dtype='datetime64[ns]', length=276, freq=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]),\n",
       " 'val': array([153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
       "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
       "        218, 219, 220, 221]),\n",
       " 'test': array([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.splitter.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140]\n",
      "Validation indices: [153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221]\n",
      "Test indices: [234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258]\n",
      "Shape of y: (25, 6, 21960)\n",
      "Shape of y_hat: (25, 6, 21960)\n",
      "Shape of mask: (25, 6, 21960)\n",
      "Shape of node_ids: (3294000,)\n",
      "Shape of lat_column: (3294000,)\n",
      "Shape of lon_column: (3294000,)\n",
      "Shape of test_dates_steps: (150,)\n",
      "Shape of all_dates_expanded: (3294000,)\n",
      "Shape of y_flat: (3294000,)\n",
      "Shape of y_hat_flat: (3294000,)\n",
      "Shape of mask_flat: (3294000,)\n",
      "Shape of filtered_dates: (3294000,)\n",
      "Shape of filtered_lat: (3294000,)\n",
      "Shape of filtered_lon: (3294000,)\n",
      "Shape of filtered_y: (3294000,)\n",
      "Shape of filtered_y_hat: (3294000,)\n",
      "Shape of filtered_node_ids: (3294000,)\n",
      "        date   lat    lon  node_id        y     y_hat\n",
      "0 2019-07-01 -30.0 -180.0        0  0.00001 -0.000218\n",
      "1 2019-07-01 -30.0 -179.0        1  0.00001 -0.000157\n",
      "2 2019-07-01 -30.0 -178.0        2  0.00001 -0.000154\n",
      "3 2019-07-01 -30.0 -177.0        3  0.00001 -0.000120\n",
      "4 2019-07-01 -30.0 -176.0        4  0.00001 -0.000367\n",
      "(3294000, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import xarray as xr\n",
    "\n",
    "# 1. Load Metadata and Dates\n",
    "metadata_array = np.load('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/metadata.npy')  # Shape: (21960, 2)\n",
    "latitudes = metadata_array[:, 0]\n",
    "longitudes = metadata_array[:, 1]\n",
    "num_nodes = len(latitudes)\n",
    "\n",
    "# Load the original dataset\n",
    "# ds = xr.open_dataset('path_to_your_dataset.nc')  # Replace with your actual path\n",
    "dates = pd.to_datetime(ds['date'].values)\n",
    "total_time_steps = len(dates)\n",
    "\n",
    "# Initialize splitter\n",
    "# splitter = TemporalSplitter(val_len=0.35, test_len=0.1)\n",
    "\n",
    "# Assume you have a SpatioTemporalDataset instance\n",
    "# dataset = your_spatio_temporal_dataset  # Replace with your actual dataset variable\n",
    "\n",
    "# Fit the splitter to the dataset\n",
    "# splitter.fit(dataset)\n",
    "\n",
    "# 2. Correctly Retrieve the Split Indices\n",
    "split_indices = datamodule.splitter.indices\n",
    "train_indices = split_indices['train']\n",
    "val_indices = split_indices['val']\n",
    "test_indices = split_indices['test']\n",
    "\n",
    "print(f\"Train indices: {train_indices}\")\n",
    "print(f\"Validation indices: {val_indices}\")\n",
    "print(f\"Test indices: {test_indices}\")\n",
    "\n",
    "# 3. Process Predictions and Actual Values\n",
    "y_list = []\n",
    "y_hat_list = []\n",
    "mask_list = []\n",
    "\n",
    "for batch in predictions_test:\n",
    "    y_tensor = batch['y']\n",
    "    y_hat_tensor = batch['y_hat']\n",
    "    mask_tensor = batch['mask']\n",
    "    \n",
    "    y_np = y_tensor.cpu().numpy().squeeze(-1)      # Shape: (batch_size, steps, nodes)\n",
    "    y_hat_np = y_hat_tensor.cpu().numpy().squeeze(-1)\n",
    "    mask_np = mask_tensor.cpu().numpy().squeeze(-1)\n",
    "    \n",
    "    y_list.append(y_np)\n",
    "    y_hat_list.append(y_hat_np)\n",
    "    mask_list.append(mask_np)\n",
    "\n",
    "# Concatenate along the batch dimension\n",
    "y = np.concatenate(y_list, axis=0)         # Shape: (num_test_batches, steps, nodes)\n",
    "y_hat = np.concatenate(y_hat_list, axis=0) # Shape: (num_test_batches, steps, nodes)\n",
    "mask = np.concatenate(mask_list, axis=0)   # Shape: (num_test_batches, steps, nodes)\n",
    "\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "print(f\"Shape of y_hat: {y_hat.shape}\")\n",
    "print(f\"Shape of mask: {mask.shape}\")\n",
    "\n",
    "# 4. Map Node IDs to Geographical Coordinates\n",
    "num_steps = y.shape[1]          # Number of prediction steps (e.g., 6)\n",
    "num_test_dates = y.shape[0]     # Number of test dates (e.g., 25)\n",
    "\n",
    "# Create node_ids, lat, lon repeated for each step\n",
    "node_ids = np.tile(np.arange(num_nodes), num_test_dates * num_steps)  # Shape: (3,294,000,)\n",
    "lat_column = np.tile(latitudes, num_test_dates * num_steps)\n",
    "lon_column = np.tile(longitudes, num_test_dates * num_steps)\n",
    "\n",
    "print(f\"Shape of node_ids: {node_ids.shape}\")\n",
    "print(f\"Shape of lat_column: {lat_column.shape}\")\n",
    "print(f\"Shape of lon_column: {lon_column.shape}\")\n",
    "\n",
    "# 5. Align Predictions with Dates\n",
    "\n",
    "# Repeat each test date for the number of prediction steps\n",
    "test_dates_steps = np.repeat(dates[test_indices], num_steps)  # Shape: (25 * 6,) => (150,)\n",
    "\n",
    "# Now, repeat each date for all nodes to align with the predictions\n",
    "all_dates_expanded = np.repeat(test_dates_steps, num_nodes)   # Shape: (150 * 21960,) => (3,294,000,)\n",
    "\n",
    "print(f\"Shape of test_dates_steps: {test_dates_steps.shape}\")       # (150,)\n",
    "print(f\"Shape of all_dates_expanded: {all_dates_expanded.shape}\") # (3,294,000,)\n",
    "\n",
    "# 6. Flatten the Predictions and Mask\n",
    "y_flat = y.flatten()         # Shape: (3,294,000,)\n",
    "y_hat_flat = y_hat.flatten()\n",
    "mask_flat = mask.flatten()\n",
    "\n",
    "print(f\"Shape of y_flat: {y_flat.shape}\")\n",
    "print(f\"Shape of y_hat_flat: {y_hat_flat.shape}\")\n",
    "print(f\"Shape of mask_flat: {mask_flat.shape}\")\n",
    "\n",
    "# 7. Apply Mask to Filter Valid Entries\n",
    "valid_indices = mask_flat.astype(bool)  # Ensure mask is boolean\n",
    "\n",
    "filtered_dates = all_dates_expanded[valid_indices]  # Shape: (num_valid_entries,)\n",
    "filtered_lat = lat_column[valid_indices]\n",
    "filtered_lon = lon_column[valid_indices]\n",
    "filtered_y = y_flat[valid_indices]\n",
    "filtered_y_hat = y_hat_flat[valid_indices]\n",
    "filtered_node_ids = node_ids[valid_indices]\n",
    "\n",
    "print(f\"Shape of filtered_dates: {filtered_dates.shape}\")\n",
    "print(f\"Shape of filtered_lat: {filtered_lat.shape}\")\n",
    "print(f\"Shape of filtered_lon: {filtered_lon.shape}\")\n",
    "print(f\"Shape of filtered_y: {filtered_y.shape}\")\n",
    "print(f\"Shape of filtered_y_hat: {filtered_y_hat.shape}\")\n",
    "print(f\"Shape of filtered_node_ids: {filtered_node_ids.shape}\")\n",
    "\n",
    "# 8. Create the DataFrame\n",
    "df_predictions = pd.DataFrame({\n",
    "    'date': filtered_dates,\n",
    "    'lat': filtered_lat,\n",
    "    'lon': filtered_lon,\n",
    "    'node_id': filtered_node_ids,\n",
    "    'y': filtered_y,\n",
    "    'y_hat': filtered_y_hat\n",
    "})\n",
    "\n",
    "print(df_predictions.head())\n",
    "print(df_predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>node_id</th>\n",
       "      <th>y</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293995</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>21955</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293996</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>21956</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293997</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>21957</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293998</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>21958</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293999</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>21959</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3294000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   lat    lon  node_id         y     y_hat\n",
       "0       2019-07-01 -30.0 -180.0        0  0.000010 -0.000218\n",
       "1       2019-07-01 -30.0 -179.0        1  0.000010 -0.000157\n",
       "2       2019-07-01 -30.0 -178.0        2  0.000010 -0.000154\n",
       "3       2019-07-01 -30.0 -177.0        3  0.000010 -0.000120\n",
       "4       2019-07-01 -30.0 -176.0        4  0.000010 -0.000367\n",
       "...            ...   ...    ...      ...       ...       ...\n",
       "3293995 2021-07-01  30.0  175.0    21955 -0.000005 -0.001788\n",
       "3293996 2021-07-01  30.0  176.0    21956 -0.000005 -0.001751\n",
       "3293997 2021-07-01  30.0  177.0    21957 -0.000005 -0.001880\n",
       "3293998 2021-07-01  30.0  178.0    21958 -0.000005 -0.001606\n",
       "3293999 2021-07-01  30.0  179.0    21959 -0.000005 -0.001478\n",
       "\n",
       "[3294000 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('ml-drought-forecasting/ml-modeling-pipeline/data/07_model_output/predictions.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_variable_on_map(\n",
    "    dataset: pd.DataFrame,\n",
    "    variable: str,\n",
    "    lat_dim: str = 'latitude',\n",
    "    lon_dim: str = 'longitude',\n",
    "    projection: str = 'natural earth',\n",
    "    color_scale: str = 'Viridis',\n",
    "    title: Optional[str] = None,\n",
    "    animation_frame: Optional[str] = None,\n",
    "    hover_precision: int = 2,\n",
    ") -> go.Figure:\n",
    "\n",
    "    df = dataset\n",
    "\n",
    "    # Drop NaNs\n",
    "    df = df.dropna(subset=[variable])\n",
    "\n",
    "    # Handle animation frame\n",
    "    if animation_frame:\n",
    "        df[animation_frame] = df[animation_frame].astype(str)\n",
    "    else:\n",
    "        df['Frame'] = 'Frame'\n",
    "    \n",
    "    # Create scatter_geo plot\n",
    "    fig = px.scatter_geo(\n",
    "        df,\n",
    "        lat=lat_dim,\n",
    "        lon=lon_dim,\n",
    "        color=variable,\n",
    "        animation_frame=animation_frame if animation_frame else 'Frame',\n",
    "        projection=projection,\n",
    "        color_continuous_scale=color_scale,\n",
    "        title=title,\n",
    "        labels={variable: variable.upper()},\n",
    "        hover_data={variable: f':.{hover_precision}f'},\n",
    "    )\n",
    "    \n",
    "    # Add Play/Pause buttons\n",
    "    fig.update_layout(\n",
    "        updatemenus=[dict(\n",
    "            type='buttons',\n",
    "            buttons=[\n",
    "                dict(label='Play',\n",
    "                     method='animate',\n",
    "                     args=[None, {\"frame\": {\"duration\": 500, \"redraw\": True}, \"fromcurrent\": True}]),\n",
    "                dict(label='Pause',\n",
    "                     method='animate',\n",
    "                     args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}])\n",
    "            ],\n",
    "            showactive=False,\n",
    "            x=0.1,\n",
    "            y=0\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "fig = visualize_variable_on_map(\n",
    "    dataset=df,\n",
    "    variable='y',\n",
    "    lat_dim='lat',\n",
    "    lon_dim='lon',\n",
    "    animation_frame='date',\n",
    "    title='Volumetric soil water layer 1',\n",
    "    color_scale = [\n",
    "        [0.0, \"darkred\"],\n",
    "        [0.1, \"red\"],\n",
    "        [0.2, \"orangered\"],\n",
    "        [0.3, \"lightgreen\"],\n",
    "        [0.4, \"limegreen\"],\n",
    "        [0.5, \"green\"],\n",
    "        [0.55, \"darkseagreen\"],\n",
    "        [0.6, \"darkgreen\"],\n",
    "        [0.7, \"lightblue\"],\n",
    "        [0.8, \"skyblue\"],\n",
    "        [0.9, \"deepskyblue\"],\n",
    "        [1.0, \"blue\"]\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_plotly(predictions, metadata, idx, horizon=None, \n",
    "                                 batches_to_visualize=None, variables_to_visualize=None):\n",
    "    \"\"\"\n",
    "    Visualize predicted vs actual values using Plotly for specified batches and variables with variable-specific normalization.\n",
    "    \n",
    "    Parameters:\n",
    "    - predictions (dict): Contains 'y' and 'y_hat' tensors.\n",
    "    - metadata (pd.DataFrame): DataFrame with 'lat' and 'lon' columns.\n",
    "    - idx (int): Index of the item being visualized.\n",
    "    - horizon (int, optional): Number of time steps to visualize. Defaults to the maximum horizon in data.\n",
    "    - batches_to_visualize (list or range, optional): List of batch indices to visualize. Defaults to all batches.\n",
    "    - variables_to_visualize (list or range, optional): List of variable indices to visualize. Defaults to all variables.\n",
    "    \"\"\"\n",
    "    # Extract predictions and actual values\n",
    "    y_hat = predictions['y_hat'].squeeze().numpy()  # Shape: [batch, horizon, spatial_dim, variables]\n",
    "    y = predictions['y'].squeeze().numpy()          # Shape: [batch, horizon, spatial_dim, variables]\n",
    "\n",
    "    # Ensure y_hat and y have the same shape\n",
    "    assert y_hat.shape == y.shape, \"Predictions and actual values must have the same shape\"\n",
    "\n",
    "    # Determine the horizon if not provided\n",
    "    if horizon is None:\n",
    "        horizon = y_hat.shape[1]\n",
    "\n",
    "    # Determine the number of variables\n",
    "    if y_hat.ndim == 3:\n",
    "        # Shape: [batch, horizon, spatial_dim]\n",
    "        num_variables = 1\n",
    "        y_hat = y_hat[..., np.newaxis]  # Add a variables dimension\n",
    "        y = y[..., np.newaxis]\n",
    "    else:\n",
    "        num_variables = y_hat.shape[-1]\n",
    "\n",
    "    if variables_to_visualize is None:\n",
    "        variables_to_visualize = list(range(num_variables))\n",
    "    else:\n",
    "        # Ensure the variable indices are within the correct range\n",
    "        variables_to_visualize = [v for v in variables_to_visualize if v < num_variables]\n",
    "        if not variables_to_visualize:\n",
    "            raise ValueError(\"No valid variables to visualize. Check 'variables_to_visualize' indices.\")\n",
    "\n",
    "    # Get latitude and longitude from metadata\n",
    "    lats = metadata['lat'].values\n",
    "    lons = metadata['lon'].values\n",
    "\n",
    "    # Ensure that the number of spatial points matches the number of lats and lons\n",
    "    spatial_dim = y_hat.shape[2]\n",
    "    if spatial_dim != len(lats):\n",
    "        raise ValueError(f\"The number of spatial points in predictions ({spatial_dim}) does not match the number of locations in metadata ({len(lats)}).\")\n",
    "\n",
    "    # Calculate the min and max for lats and lons for setting map extent\n",
    "    lat_min, lat_max = lats.min(), lats.max()\n",
    "    lon_min, lon_max = lons.min(), lons.max()\n",
    "\n",
    "    # If batches_to_visualize is None, visualize all batches\n",
    "    if batches_to_visualize is None:\n",
    "        batches_to_visualize = range(y_hat.shape[0])\n",
    "    else:\n",
    "        # Ensure the batch indices are within the correct range\n",
    "        batches_to_visualize = [b for b in batches_to_visualize if b < y_hat.shape[0]]\n",
    "        if not batches_to_visualize:\n",
    "            raise ValueError(\"No valid batches to visualize. Check 'batches_to_visualize' indices.\")\n",
    "\n",
    "    # Precompute min and max for each variable in variables_to_visualize\n",
    "    var_min_max = {}\n",
    "    for var in variables_to_visualize:\n",
    "        var_data_y = y[..., var]  # Shape: [batch, horizon, spatial_dim]\n",
    "        var_data_y_hat = y_hat[..., var]  # Shape: [batch, horizon, spatial_dim]\n",
    "        min_val = min(np.min(var_data_y), np.min(var_data_y_hat))\n",
    "        max_val = max(np.max(var_data_y), np.max(var_data_y_hat))\n",
    "        import numpy as np\n",
    "\n",
    "        # ...\n",
    "\n",
    "        # Loop through each batch and variable\n",
    "        for batch in batches_to_visualize:\n",
    "            for var in variables_to_visualize:\n",
    "                frames = []\n",
    "                slider_steps = []\n",
    "\n",
    "                # Retrieve normalization for the current variable\n",
    "                min_val, max_val = var_min_max[var]\n",
    "\n",
    "                # Get the highest and lowest values of the variable\n",
    "                var_min = np.min(y_hat[batch, :, :, var])\n",
    "                var_max = np.max(y_hat[batch, :, :, var])\n",
    "\n",
    "                # Update the min and max values if necessary\n",
    "                if var_min < min_val:\n",
    "                    min_val = var_min\n",
    "                if var_max > max_val:\n",
    "                    max_val = var_max\n",
    "\n",
    "                # Update the normalization dictionary\n",
    "                var_min_max[var] = (min_val, max_val)\n",
    "\n",
    "                # ...\n",
    "\n",
    "                # Predicted data for current month\n",
    "                pred_data = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y_hat[batch, time_step, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Predicted'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Predicted',\n",
    "                    showlegend=False\n",
    "                )\n",
    "\n",
    "                # Actual data for current month\n",
    "                actual_data = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y[batch, time_step, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Actual'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Actual',\n",
    "                    showlegend=False\n",
    "                )\n",
    "\n",
    "                # ...\n",
    "\n",
    "                # Initial data (first frame)\n",
    "                pred_data_initial = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y_hat[batch, 0, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Predicted'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Predicted',\n",
    "                    showlegend=True\n",
    "                )\n",
    "\n",
    "                actual_data_initial = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y[batch, 0, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Actual'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Actual',\n",
    "                    showlegend=True\n",
    "                )\n",
    "\n",
    "                # ...\n",
    "                        visible=True,\n",
    "                        prefix=\"Date: \",\n",
    "                        xanchor=\"right\",\n",
    "                        font=dict(size=14, color=\"#666\")\n",
    "                    ),\n",
    "                )],\n",
    "                geo=dict(\n",
    "                    scope='world',\n",
    "                    projection_type='natural earth',\n",
    "                    showland=True,\n",
    "                    landcolor='lightgray',\n",
    "                    showcountries=True,\n",
    "                    countrycolor='black',\n",
    "                    lataxis=dict(range=[lat_min - 1, lat_max + 1]),\n",
    "                    lonaxis=dict(range=[lon_min - 1, lon_max + 1]),\n",
    "                ),\n",
    "                geo2=dict(\n",
    "                    scope='world',\n",
    "                    projection_type='natural earth',\n",
    "                    showland=True,\n",
    "                    landcolor='lightgray',\n",
    "                    showcountries=True,\n",
    "                    countrycolor='black',\n",
    "                    lataxis=dict(range=[lat_min - 1, lat_max + 1]),\n",
    "                    lonaxis=dict(range=[lon_min - 1, lon_max + 1]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Update frames to assign traces to correct subplots\n",
    "            for frame in fig.frames:\n",
    "                time_step_idx = int(frame.name.split()[1]) - 1\n",
    "                frame.data = [\n",
    "                    go.Scattergeo(\n",
    "                        lon=lons,\n",
    "                        lat=lats,\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=6,\n",
    "                            color=y_hat[batch, time_step_idx, :, var],\n",
    "                            colorscale='RdYlBu_r',\n",
    "                            cmin=min_val,\n",
    "                            cmax=max_val,\n",
    "                            opacity=0.8\n",
    "                        ),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    go.Scattergeo(\n",
    "                        lon=lons,\n",
    "                        lat=lats,\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=6,\n",
    "                            color=y[batch, time_step_idx, :, var],\n",
    "                            colorscale='RdYlBu_r',\n",
    "                            cmin=min_val,\n",
    "                            cmax=max_val,\n",
    "                            opacity=0.8\n",
    "                        ),\n",
    "                        showlegend=False\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            # Update layout for better appearance\n",
    "            fig.update_layout(\n",
    "                height=600,\n",
    "                width=1200,\n",
    "                margin=dict(l=50, r=50, t=100, b=50)\n",
    "            )\n",
    "\n",
    "            # Display the figure\n",
    "            fig.show()\n",
    "\n",
    "            # Optionally, save the figure to an HTML file\n",
    "            # fig.write_html(f'item_{idx+1}_batch_{batch+1}_variable_{var+1}.html')\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# Assuming you have the metadata DataFrame available\n",
    "# metadata = pd.read_parquet('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/metadata.parquet')\n",
    "\n",
    "# Ensure that predictions_test is a list of dictionaries with 'y' and 'y_hat'\n",
    "# For example:\n",
    "# predictions_test = [{'y': tensor1, 'y_hat': tensor2}, {'y': tensor3, 'y_hat': tensor4}, ...]\n",
    "\n",
    "# # Specify the indices of the items you want to visualize\n",
    "# items_to_visualize = [1]  # Replace with desired item indices (0-based indexing)\n",
    "# batches_to_visualize = [0, 1]  # Replace with desired batch indices within each item\n",
    "# variables_to_visualize = [0]  # Replace with desired variable indices (e.g., if multiple EDDI metrics)\n",
    "\n",
    "# # Call the function for specified items in predictions_test\n",
    "# for idx in items_to_visualize:\n",
    "#     pred = predictions_test[idx]\n",
    "#     visualize_predictions_plotly(\n",
    "#         pred, metadata, idx, horizon=pred['y'].shape[1],\n",
    "#         batches_to_visualize=batches_to_visualize, \n",
    "#         variables_to_visualize=variables_to_visualize\n",
    "#     )\n",
    "#     print(f\"Processed item {idx + 1}/{len(predictions_test)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
