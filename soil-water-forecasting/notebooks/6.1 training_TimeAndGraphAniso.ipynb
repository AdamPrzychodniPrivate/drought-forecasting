{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training notebook \n",
    "\n",
    "In this notebook, we will create the graph, build the STGNN model, perform training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SoilWaterDataset object \n",
    "\n",
    "SoilWaterDataset is a fundamental object created based on TabularDataset from the TSL library. Using this object, we will be able to enabling efficient loading, preprocessing, and spatiotemporal structuring of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from tsl.datasets.prototypes import TabularDataset\n",
    "from tsl.ops.similarities import gaussian_kernel\n",
    "\n",
    "class SoilWaterDataset(TabularDataset):\n",
    "\n",
    "    similarity_options = {'distance', 'grid'}\n",
    "\n",
    "    def __init__(self,\n",
    "                 root: str = None\n",
    "                 ):\n",
    "\n",
    "        self.root = root\n",
    "\n",
    "        # Load data\n",
    "        target, mask, u, dist, metadata = self.load()\n",
    "\n",
    "        covariates = {\n",
    "            'u': (u),\n",
    "            'metadata' : (metadata),\n",
    "            'distances': (dist)\n",
    "        }\n",
    "\n",
    "        super().__init__(target=target,\n",
    "                         mask=mask,\n",
    "                         covariates=covariates,\n",
    "                         similarity_score='distance',\n",
    "                         temporal_aggregation='mean',\n",
    "                         spatial_aggregation='mean',\n",
    "                         name='SoilWaterDataset')\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load data from files.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Containing target, mask, covariates, distances, and metadata.\n",
    "        \"\"\"\n",
    "        target_path = f\"{self.root}target.npy\"\n",
    "        mask_path = f\"{self.root}mask.npy\"\n",
    "        dist_path = f\"{self.root}distance_matrix.npy\"\n",
    "        covariates_path = f\"{self.root}covariates.npy\"\n",
    "        metadata_path = f\"{self.root}metadata.npy\"\n",
    "\n",
    "        target = np.load(target_path)\n",
    "        mask = np.load(mask_path)\n",
    "        u = np.load(covariates_path)\n",
    "        dist = np.load(dist_path)\n",
    "        metadata = np.load(metadata_path)\n",
    "\n",
    "        return target, mask, u, dist, metadata\n",
    "\n",
    "\n",
    "    def compute_similarity(self, method: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute similarity matrix based on the specified method.\n",
    "\n",
    "        Args:\n",
    "            method (str): The similarity computation method ('distance' or 'grid').\n",
    "            **kwargs: Additional keyword arguments for similarity computation.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Computed similarity matrix.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unknown similarity method is provided.\n",
    "        \"\"\"\n",
    "        if method == \"distance\":\n",
    "            # Calculate a Gaussian kernel similarity from the distance matrix, using a default or provided 'theta'\n",
    "            theta = kwargs.get('theta', np.std(self.distances))\n",
    "            return gaussian_kernel(self.distances, theta=theta)\n",
    "        elif method == \"grid\":\n",
    "            dist = self.distances.copy()\n",
    "            dist[dist > 16] = np.inf  # keep only grid edges\n",
    "            theta = kwargs.get('theta', 20)\n",
    "            return gaussian_kernel(dist, theta=theta)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown similarity method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SoilWaterDataset(root='ml-drought-forecasting/soil-water-forecasting/data/05_model_input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.6496307e-01],\n",
       "        [ 1.6496307e-01],\n",
       "        [ 1.6496307e-01],\n",
       "        ...,\n",
       "        [ 2.9243529e-07],\n",
       "        [ 2.9243529e-07],\n",
       "        [ 2.9243529e-07]],\n",
       "\n",
       "       [[ 1.6687536e-01],\n",
       "        [ 1.6687536e-01],\n",
       "        [ 1.6687536e-01],\n",
       "        ...,\n",
       "        [ 5.2526593e-06],\n",
       "        [ 5.2526593e-06],\n",
       "        [ 5.2526593e-06]],\n",
       "\n",
       "       [[ 1.6724145e-01],\n",
       "        [ 1.6724145e-01],\n",
       "        [ 1.6724145e-01],\n",
       "        ...,\n",
       "        [-1.0136282e-05],\n",
       "        [-1.0136282e-05],\n",
       "        [-1.0136282e-05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3.2181239e-01],\n",
       "        [ 3.2181239e-01],\n",
       "        [ 3.2181239e-01],\n",
       "        ...,\n",
       "        [ 4.5273919e-06],\n",
       "        [ 4.5273919e-06],\n",
       "        [ 4.5273919e-06]],\n",
       "\n",
       "       [[ 3.2685500e-01],\n",
       "        [ 3.2685500e-01],\n",
       "        [ 3.2685500e-01],\n",
       "        ...,\n",
       "        [-3.5299454e-06],\n",
       "        [-3.5299454e-06],\n",
       "        [-3.5299454e-06]],\n",
       "\n",
       "       [[ 3.2872993e-01],\n",
       "        [ 3.2872993e-01],\n",
       "        [ 3.2872993e-01],\n",
       "        ...,\n",
       "        [-5.4172706e-06],\n",
       "        [-5.4172706e-06],\n",
       "        [-5.4172706e-06]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has missing values: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Has missing values: {dataset.has_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_mask(dataset.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u': array([[[ 3.0585480e-01, -1.2989902e-01,  2.4335590e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         [ 3.0585480e-01, -1.2989902e-01,  2.4335590e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         [ 3.0585480e-01, -1.2989902e-01,  2.4335590e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         ...,\n",
       "         [-7.7445984e-02,  3.2210350e-02,  2.5064105e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00],\n",
       "         [-7.7445984e-02,  3.2210350e-02,  2.5064105e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00],\n",
       "         [-7.7445984e-02,  3.2210350e-02,  2.5064105e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00]],\n",
       " \n",
       "        [[ 4.1980553e-01,  1.1558628e-01,  2.3336655e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         [ 4.1980553e-01,  1.1558628e-01,  2.3336655e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         [ 4.1980553e-01,  1.1558628e-01,  2.3336655e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         ...,\n",
       "         [-4.7479630e-02,  6.0898781e-02,  2.5171616e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00],\n",
       "         [-4.7479630e-02,  6.0898781e-02,  2.5171616e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00],\n",
       "         [-4.7479630e-02,  6.0898781e-02,  2.5171616e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00]],\n",
       " \n",
       "        [[ 6.0301781e-01,  8.3531380e-02,  2.2287155e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  2.0000000e+00],\n",
       "         [ 6.0301781e-01,  8.3531380e-02,  2.2287155e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  2.0000000e+00],\n",
       "         [ 6.0301781e-01,  8.3531380e-02,  2.2287155e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  2.0000000e+00],\n",
       "         ...,\n",
       "         [-5.2743912e-02,  6.9371223e-02,  2.5145749e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  2.0000000e+00],\n",
       "         [-5.2743912e-02,  6.9371223e-02,  2.5145749e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  2.0000000e+00],\n",
       "         [-5.2743912e-02,  6.9371223e-02,  2.5145749e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  2.0000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4.6406879e+00,  1.9648352e+00,  2.2614645e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         [ 4.6406879e+00,  1.9648352e+00,  2.2614645e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         [ 4.6406879e+00,  1.9648352e+00,  2.2614645e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         ...,\n",
       "         [ 1.4898872e-01, -4.2977333e-02,  2.5982614e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00],\n",
       "         [ 1.4898872e-01, -4.2977333e-02,  2.5982614e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00],\n",
       "         [ 1.4898872e-01, -4.2977333e-02,  2.5982614e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00]],\n",
       " \n",
       "        [[ 2.4678459e+00,  2.2457905e+00,  2.3805811e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         [ 2.4678459e+00,  2.2457905e+00,  2.3805811e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         [ 2.4678459e+00,  2.2457905e+00,  2.3805811e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         ...,\n",
       "         [-2.9545174e+00, -1.2335014e-01,  2.5271436e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00],\n",
       "         [-2.9545174e+00, -1.2335014e-01,  2.5271436e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00],\n",
       "         [-2.9545174e+00, -1.2335014e-01,  2.5271436e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00]],\n",
       " \n",
       "        [[ 2.4026718e+00,  2.3765755e+00,  2.4505371e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  1.0000000e+00],\n",
       "         [ 2.4026718e+00,  2.3765755e+00,  2.4505371e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  1.0000000e+00],\n",
       "         [ 2.4026718e+00,  2.3765755e+00,  2.4505371e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  1.0000000e+00],\n",
       "         ...,\n",
       "         [ 1.7806244e-01, -1.7955780e-02,  2.5267090e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  1.0000000e+00],\n",
       "         [ 1.7806244e-01, -1.7955780e-02,  2.5267090e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  1.0000000e+00],\n",
       "         [ 1.7806244e-01, -1.7955780e-02,  2.5267090e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  1.0000000e+00]]], dtype=float32),\n",
       " 'metadata': array([[-90.,   0.],\n",
       "        [-90.,   1.],\n",
       "        [-90.,   2.],\n",
       "        ...,\n",
       "        [ 90., 357.],\n",
       "        [ 90., 358.],\n",
       "        [ 90., 359.]], dtype=float32),\n",
       " 'distances': array([[0.0000000e+00, 6.8086486e-15, 1.3616779e-14, ..., 2.0015115e+04,\n",
       "         2.0015115e+04, 2.0015115e+04],\n",
       "        [6.8086486e-15, 0.0000000e+00, 6.8086486e-15, ..., 2.0015115e+04,\n",
       "         2.0015115e+04, 2.0015115e+04],\n",
       "        [1.3616779e-14, 6.8086486e-15, 0.0000000e+00, ..., 2.0015115e+04,\n",
       "         2.0015115e+04, 2.0015115e+04],\n",
       "        ...,\n",
       "        [2.0015115e+04, 2.0015115e+04, 2.0015115e+04, ..., 0.0000000e+00,\n",
       "         6.8086486e-15, 1.3616779e-14],\n",
       "        [2.0015115e+04, 2.0015115e+04, 2.0015115e+04, ..., 6.8086486e-15,\n",
       "         0.0000000e+00, 6.8086486e-15],\n",
       "        [2.0015115e+04, 2.0015115e+04, 2.0015115e+04, ..., 1.3616779e-14,\n",
       "         6.8086486e-15, 0.0000000e+00]], dtype=float32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create connectivity to our graph \n",
    "\n",
    "Here, we adjust the connectivity to retain only the five nearest neighbors (knn=5) per node, while excluding self-loops and normalizing along the specified axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:38:41.500430Z",
     "start_time": "2024-11-08T18:38:41.498443Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim = dataset.compute_similarity(\"distance\")  # or dataset.compute_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adjust connectivity to reduce the number of edges\n",
    "# connectivity = dataset.get_connectivity(          \n",
    "#     knn=5,     \n",
    "#     include_self=False,\n",
    "#     normalize_axis=1,\n",
    "#     layout=\"edge_index\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index, edge_weight = connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13573/2527944336.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  connectivity = torch.load(\"ml-drought-forecasting/soil-water-forecasting/data/05_model_input/connectivity.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "connectivity = torch.load(\"ml-drought-forecasting/soil-water-forecasting/data/05_model_input/connectivity.pt\")\n",
    "edge_index = connectivity[\"edge_index\"].numpy()\n",
    "edge_weight = connectivity[\"edge_weight\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    0,     0,     0, ..., 65159, 65159, 65159],\n",
       "        [    1,     2,     3, ..., 65156, 65157, 65158]]),\n",
       " array([1., 1., 1., ..., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pack into the desired tuple format\n",
    "connectivity = (edge_index, edge_weight)\n",
    "connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_matrix(matrix):\n",
    "#     return pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tsl.ops.connectivity import edge_index_to_adj\n",
    "# \n",
    "# adj = edge_index_to_adj(edge_index, edge_weight)\n",
    "# print(f'A {adj.shape}:')\n",
    "# print_matrix(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create torch_dataset \n",
    "\n",
    "torch_dataset, created using SpatioTemporalDataset from the tsl library, structures time-series and spatial data (target, covariates, mask, and connectivity) into a form optimized for spatiotemporal model training, enabling easy handling of lookback windows and prediction horizons in forecasting tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data import SpatioTemporalDataset\n",
    "\n",
    "# covariates=dict(u=dataset.covariates['u'])\n",
    "covariates=dataset.covariates\n",
    "mask = dataset.mask\n",
    "\n",
    "torch_dataset = SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      mask=mask,\n",
    "                                      covariates=covariates,\n",
    "                                      connectivity=connectivity,\n",
    "                                      horizon=6, # Predict 7 step ahead\n",
    "                                      window=12, # Use 30 timestamps to predict the next one\n",
    "                                      stride=1 # Move 7 step forward each time\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dataset.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datamodule\n",
    "\n",
    "datamodule, created with SpatioTemporalDataModule, manages the SpatioTemporalDataset by applying scaling, splitting data into train/validation/test sets, and preparing data loaders with batch processing, enabling efficient, modular, and scalable data handling for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scalers = {\n",
    "    'target': MinMaxScaler(axis=(0, 1)),\n",
    "    'u': MinMaxScaler(axis=(0, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "                                 \n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=0.35, test_len=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=None, val_len=None, test_len=None, scalers=[target, u], batch_size=8)\n"
     ]
    }
   ],
   "source": [
    "# Create a SpatioTemporalDataModule\n",
    "datamodule = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    mask_scaling=True,\n",
    "    splitter=splitter,\n",
    "    batch_size=8,\n",
    "    workers=15,\n",
    "    )\n",
    "\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatioTemporalDataModule(train_len=35, val_len=13, test_len=7, scalers=[target, u], batch_size=8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34]),\n",
       " 'val': array([47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]),\n",
       " 'test': array([72, 73, 74, 75, 76, 77, 78])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.splitter.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create STGNN Model Architecture\n",
    "\n",
    "The **TimeAndGraphAnisoModel** is built based on code from [HD-TTS\n",
    " repository](https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/time_and_graph_anisotropic.py) and the research paper by Cini et al. (2023d). This model utilizes spatiotemporal architectures equipped with anisotropic message passing for effective time and space representation.\n",
    "\n",
    "### Reference\n",
    "Cini, A., Marisca, I., Zambon, D., and Alippi, C. *Taming Local Effects in Graph-Based Spatiotemporal Forecasting.* In *Advances in Neural Information Processing Systems,* volume 36, pp. 55375–55393. Curran Associates, Inc., 2023.  \n",
    "[https://arxiv.org/abs/2302.04071](https://arxiv.org/abs/2302.04071)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/layers/anisotropic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from tsl.nn.blocks import RNNBase\n",
    "from tsl.nn.layers import Dense, GraphGRUCellBase, Activation\n",
    "\n",
    "\n",
    "class GraphAnisoConv(MessagePassing):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 1,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        super(GraphAnisoConv, self).__init__(aggr=\"add\", node_dim=-2)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.msg_mlps = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2 * (in_channels if i == 0 else out_channels),\n",
    "                          out_channels),\n",
    "                Activation(activation),\n",
    "                nn.Linear(out_channels, out_channels),\n",
    "            )\n",
    "            for i in range(kernel_size)\n",
    "        ])\n",
    "\n",
    "        edge_dim = edge_dim or 1  # accommodate for edge_weight\n",
    "        self.lin_edge = nn.Linear(edge_dim, out_channels, bias=False)\n",
    "\n",
    "        self.gate_mlp = Dense(out_channels, 1, activation='sigmoid')\n",
    "\n",
    "        self.skip_conn = nn.Linear(in_channels, out_channels)\n",
    "        self.activation = Activation(activation)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr: Optional[Tensor] = None):\n",
    "        \"\"\"\"\"\"\n",
    "        out, x_ = 0, x\n",
    "        for idx in range(self.kernel_size):\n",
    "            x_ = self.propagate(edge_index, idx=idx, x=x_, edge_attr=edge_attr)\n",
    "            out += x_\n",
    "        out = self.activation(out + self.skip_conn(x))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, idx, edge_attr: Optional[Tensor] = None):\n",
    "        mij = self.msg_mlps[idx](torch.cat([x_i, x_j], -1))\n",
    "        if edge_attr is not None:\n",
    "            if edge_attr.ndim == 1:  # accommodate for edge_weight\n",
    "                edge_attr = edge_attr.view(-1, 1)\n",
    "            mij = mij + self.lin_edge(edge_attr)\n",
    "        return self.gate_mlp(mij) * mij\n",
    "\n",
    "\n",
    "class GraphAnisoGRUCell(GraphGRUCellBase):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        self.input_size = input_size\n",
    "        # instantiate gates\n",
    "        forget_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                     edge_dim=edge_dim, activation=activation)\n",
    "        update_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                     edge_dim=edge_dim, activation=activation)\n",
    "        candidate_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                        edge_dim=edge_dim,\n",
    "                                        activation=activation)\n",
    "        super(GraphAnisoGRUCell, self).__init__(hidden_size=hidden_size,\n",
    "                                                forget_gate=forget_gate,\n",
    "                                                update_gate=update_gate,\n",
    "                                                candidate_gate=candidate_gate)\n",
    "\n",
    "\n",
    "class GraphAnisoGRU(RNNBase):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 n_layers: int = 1, cat_states_layers: bool = False,\n",
    "                 return_only_last_state: bool = False,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        rnn_cells = [\n",
    "            GraphAnisoGRUCell(input_size if i == 0 else hidden_size,\n",
    "                              hidden_size, edge_dim=edge_dim,\n",
    "                              activation=activation)\n",
    "            for i in range(n_layers)\n",
    "        ]\n",
    "        super(GraphAnisoGRU, self).__init__(rnn_cells, cat_states_layers,\n",
    "                                            return_only_last_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/prototypes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch_geometric.typing import Adj\n",
    "from tsl.nn.blocks import MLPDecoder\n",
    "from tsl.nn.layers import MultiLinear, NodeEmbedding\n",
    "from tsl.nn.models import BaseModel\n",
    "from tsl.nn.utils import maybe_cat_exog\n",
    "from tsl.utils import ensure_list\n",
    "\n",
    "\n",
    "def maybe_cat_emb(x: Tensor, emb: Optional[Tensor]):\n",
    "    if emb is None:\n",
    "        return x\n",
    "    if emb.ndim < x.ndim:\n",
    "        emb = emb[[None] * (x.ndim - emb.ndim)]\n",
    "    emb = emb.expand(*x.shape[:-1], -1)\n",
    "    return torch.cat([x, emb], dim=-1)\n",
    "\n",
    "\n",
    "class STGNN(BaseModel):\n",
    "    available_embedding_pos = {'encoding', 'decoding'}\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int,\n",
    "                 n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Optional[\n",
    "                     Union[str, List[str]]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 activation: str = 'elu'):\n",
    "        super(STGNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.horizon = horizon\n",
    "        self.n_nodes = n_nodes\n",
    "        self.output_size = output_size or input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.exog_size = exog_size\n",
    "        self.activation = activation\n",
    "\n",
    "        # EMBEDDING\n",
    "        if add_embedding_before is None:\n",
    "            add_embedding_before = set()\n",
    "        else:\n",
    "            add_embedding_before = set(ensure_list(add_embedding_before))\n",
    "            if not add_embedding_before.issubset(self.available_embedding_pos):\n",
    "                raise ValueError(\"Parameter 'add_embedding_before' must be a \"\n",
    "                                 f\"subset of {self.available_embedding_pos}\")\n",
    "        self.add_embedding_before = add_embedding_before\n",
    "\n",
    "        if emb_size > 0:\n",
    "            self.emb = NodeEmbedding(n_nodes, emb_size)\n",
    "        else:\n",
    "            self.register_module('emb', None)\n",
    "\n",
    "        # ENCODER\n",
    "        self.encoder_input = input_size + exog_size\n",
    "        if 'encoding' in self.add_embedding_before and self.emb is not None:\n",
    "            self.encoder_input += emb_size\n",
    "\n",
    "        if use_local_weights is not None:\n",
    "            self.use_local_weights = set(ensure_list(use_local_weights))\n",
    "            if len(self.use_local_weights.difference(['encoder', 'decoder'])):\n",
    "                raise ValueError(\"Parameter 'use_local_weights' must be \"\n",
    "                                 \"'encoder', 'decoder', or both.\")\n",
    "        else:\n",
    "            self.use_local_weights = set()\n",
    "\n",
    "        if 'encoder' in self.use_local_weights:\n",
    "            self.encoder = MultiLinear(self.encoder_input, hidden_size, n_nodes)\n",
    "        else:\n",
    "            self.encoder = nn.Linear(self.encoder_input, hidden_size)\n",
    "\n",
    "        # DECODER\n",
    "        self.decoder_input = hidden_size\n",
    "        if 'decoding' in self.add_embedding_before and self.emb is not None:\n",
    "            self.decoder_input += emb_size\n",
    "        if 'decoder' in self.use_local_weights:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            self.decoder = MLPDecoder(input_size=self.decoder_input,\n",
    "                                      hidden_size=self.hidden_size,\n",
    "                                      output_size=self.output_size,\n",
    "                                      horizon=self.horizon,\n",
    "                                      activation=self.activation)\n",
    "\n",
    "    def stmp(self, x: Tensor, edge_index: Adj,\n",
    "             edge_weight: Optional[Tensor] = None,\n",
    "             emb: Optional[Tensor] = None) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj,\n",
    "                edge_weight: Optional[Tensor] = None,\n",
    "                u: Optional[Tensor] = None,\n",
    "                node_idx: Optional[Tensor] = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        # x: [batches steps nodes features]\n",
    "        x = maybe_cat_exog(x, u)\n",
    "        batch_size = x.size(0)\n",
    "        emb = self.emb(expand=(batch_size, -1, -1),\n",
    "                       node_index=node_idx) if self.emb is not None else None\n",
    "\n",
    "        if 'encoding' in self.add_embedding_before and emb is not None:\n",
    "            x = maybe_cat_emb(x, emb[:, None])\n",
    "\n",
    "        # ENCODER   ###########################################################\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # SPATIOTEMPORAL MESSAGE-PASSING   ####################################\n",
    "        out = self.stmp(x, edge_index, edge_weight, emb)\n",
    "\n",
    "        # DECODER   ###########################################################\n",
    "        if 'decoding' in self.add_embedding_before:\n",
    "            out = maybe_cat_emb(out, emb)\n",
    "\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TimeAndSpace(STGNN):\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int, stmp_conv: nn.Module,\n",
    "                 n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Union[str, List[str]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 activation: str = 'elu'):\n",
    "        super(TimeAndSpace, self).__init__(input_size=input_size,\n",
    "                                           horizon=horizon,\n",
    "                                           n_nodes=n_nodes,\n",
    "                                           output_size=output_size,\n",
    "                                           exog_size=exog_size,\n",
    "                                           hidden_size=hidden_size,\n",
    "                                           emb_size=emb_size,\n",
    "                                           add_embedding_before=add_embedding_before,\n",
    "                                           use_local_weights=use_local_weights,\n",
    "                                           activation=activation)\n",
    "\n",
    "        # STMP\n",
    "        self.stmp_conv = stmp_conv\n",
    "\n",
    "    def stmp(self, x: Tensor, edge_index: Adj,\n",
    "             edge_weight: Optional[Tensor] = None,\n",
    "             emb: Optional[Tensor] = None) -> Tensor:\n",
    "        # spatiotemporal encoding\n",
    "        out = self.stmp_conv(x, edge_index, edge_weight)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/time_and_graph_anisotropic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "class TimeAndGraphAnisoModel(TimeAndSpace):\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int, n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Union[str, List[str]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 n_layers: int = 1,\n",
    "                 activation: str = 'elu'):\n",
    "        stmp_conv = GraphAnisoGRU(input_size=hidden_size,\n",
    "                                  hidden_size=hidden_size,\n",
    "                                  n_layers=n_layers,\n",
    "                                  activation=activation,\n",
    "                                  return_only_last_state=True)\n",
    "        super(TimeAndGraphAnisoModel, self).__init__(\n",
    "            input_size=input_size,\n",
    "            horizon=horizon,\n",
    "            stmp_conv=stmp_conv,\n",
    "            n_nodes=n_nodes,\n",
    "            output_size=output_size,\n",
    "            exog_size=exog_size,\n",
    "            hidden_size=hidden_size,\n",
    "            emb_size=emb_size,\n",
    "            add_embedding_before=add_embedding_before,\n",
    "            use_local_weights=use_local_weights,\n",
    "            activation=activation\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model \n",
    "\n",
    "Model is configured with hidden units, feed-forward layers, multiple SpatioTemporalConvNet blocks, and utilizes temporal and spatial convolution kernels, layer normalization, and gated mechanisms; it adapts to the dataset’s input size, number of nodes, horizon, and available exogenous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 32          # Number of hidden units\n",
    "ff_size = 64             # Number of units in the feed-forward layers\n",
    "n_layers = 3              # Number of SpatioTemporalConvNet blocks\n",
    "temporal_kernel_size = 3  # Size of the temporal convolution kernel\n",
    "spatial_kernel_size = 3   # Order of the spatial diffusion process\n",
    "norm='layer'\n",
    "gated=True\n",
    "\n",
    "input_size = torch_dataset.n_channels\n",
    "n_nodes = torch_dataset.n_nodes\n",
    "horizon = torch_dataset.horizon\n",
    "exog_size = torch_dataset.input_map.u.shape[-1] if 'u' in torch_dataset else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeAndGraphAnisoModel(\n",
      "  (emb): None\n",
      "  (encoder): Linear(in_features=23, out_features=32, bias=True)\n",
      "  (decoder): MLPDecoder(\n",
      "    (readout): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Dense(\n",
      "          (affinity): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (activation): ELU(alpha=1.0)\n",
      "          (dropout): Identity()\n",
      "        )\n",
      "      )\n",
      "      (readout): Linear(in_features=32, out_features=6, bias=True)\n",
      "    )\n",
      "    (rearrange): Rearrange('b n (h f) -> b h n f', f=1, h=6)\n",
      "  )\n",
      "  (stmp_conv): GraphAnisoGRU(cell=GraphAnisoGRUCell, return_only_last_state=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TimeAndGraphAnisoModel(\n",
    "    input_size=input_size,\n",
    "    horizon=horizon,\n",
    "    n_nodes=n_nodes,\n",
    "    output_size=input_size,\n",
    "    exog_size=exog_size,\n",
    "    hidden_size=hidden_size\n",
    ")\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "Number of model (TimeAndGraphAnisoModel) parameters:     24009\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training \n",
    "\n",
    "This setup initializes a Predictor for the model with a masked mean-squared error loss function and multiple evaluation metrics (MSE, MAE, MAPE, and specific MSE at selected timesteps), then configures a Trainer using PyTorch Lightning with early stopping and model checkpointing based on validation MSE, gradient clipping to prevent exploding gradients, and 16-bit precision for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.metrics.torch import MaskedMSE, MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Predictor\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = MaskedMSE()\n",
    "\n",
    "# Setup metrics\n",
    "metrics = {\n",
    "    'mse': MaskedMSE(),\n",
    "    'mae': MaskedMAE(),\n",
    "    'mape': MaskedMAPE(),\n",
    "    'mse_at_3': MaskedMSE(at=2),  # '2' indicates the third time step\n",
    "    'mse_at_6': MaskedMSE(at=5)\n",
    "}\n",
    "\n",
    "# Setup predictor\n",
    "predictor = Predictor(\n",
    "    model=model,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs={'lr': 0.001},\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_mse',\n",
    "    patience=30,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Logs \n",
    "dirpath = Path('ml-drought-forecasting/soil-water-forecasting/data/06_models/TimeAndGraphAniso/logs')\n",
    "\n",
    "dirpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=dirpath,\n",
    "    save_top_k=1,\n",
    "    monitor='val_mse', \n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Setup trainer\n",
    "trainer = pl.Trainer(max_epochs=100,\n",
    "                    #  logger=logger,\n",
    "                    #  limit_train_batches=100,  # end an epoch after 200 updates\n",
    "                     callbacks=[early_stop_callback, checkpoint_callback],\n",
    "                     log_every_n_steps=2,\n",
    "                     gradient_clip_val=1.0,    # Prevent exploding gradients\n",
    "                     precision=16\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set float32 matmul precision to 'medium' or 'high'\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMSE              | 0      | train\n",
      "1 | train_metrics | MetricCollection       | 0      | train\n",
      "2 | val_metrics   | MetricCollection       | 0      | train\n",
      "3 | test_metrics  | MetricCollection       | 0      | train\n",
      "4 | model         | TimeAndGraphAnisoModel | 24.0 K | train\n",
      "-----------------------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n",
      "81        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebf96f0404944deb44b394034beac99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "Arguments ['distances', 'metadata'] are filtered out. Only args ['edge_weight', 'edge_index', 'x', 'u'] are forwarded to the model (TimeAndGraphAnisoModel).\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf075ffd66e347938fc4332853c94d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 518.00 MiB. GPU 0 has a total capacity of 22.19 GiB of which 137.50 MiB is free. Process 206593 has 22.05 GiB memory in use. Of the allocated memory 21.61 GiB is allocated by PyTorch, and 145.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\n\u001b[1;32m      2\u001b[0m multiprocessing\u001b[38;5;241m.\u001b[39mset_start_method(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         closure()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    170\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1277\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1281\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/amp.py:78\u001b[0m, in \u001b[0;36mMixedPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(optimizer, LBFGS):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAMP and the LBFGS optimizer are not compatible.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# If backward was skipped in automatic optimization (return None), unscaling is not needed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m skip_unscaling \u001b[38;5;241m=\u001b[39m closure_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:317\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 317\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    322\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:341\u001b[0m, in \u001b[0;36mPredictor.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# Compute predictions and compute loss\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m y_hat_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpostprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m y_hat_loss\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# Scale target and output, eventually\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:285\u001b[0m, in \u001b[0;36mPredictor.predict_batch\u001b[0;34m(self, batch, preprocess, postprocess, return_target, **forward_kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forward_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     forward_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 285\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Rescale outputs\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m postprocess:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:176\u001b[0m, in \u001b[0;36mPredictor.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_forward_kwargs:\n\u001b[1;32m    175\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_forward_kwargs(kwargs)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 114\u001b[0m, in \u001b[0;36mSTGNN.forward\u001b[0;34m(self, x, edge_index, edge_weight, u, node_idx)\u001b[0m\n\u001b[1;32m    111\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# SPATIOTEMPORAL MESSAGE-PASSING   ####################################\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstmp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# DECODER   ###########################################################\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_embedding_before:\n",
      "Cell \u001b[0;32mIn[27], line 154\u001b[0m, in \u001b[0;36mTimeAndSpace.stmp\u001b[0;34m(self, x, edge_index, edge_weight, emb)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstmp\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, edge_index: Adj,\n\u001b[1;32m    151\u001b[0m          edge_weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    152\u001b[0m          emb: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# spatiotemporal encoding\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstmp_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/nn/blocks/encoders/recurrent/base.py:67\u001b[0m, in \u001b[0;36mRNNBase.forward\u001b[0;34m(self, x, h, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m steps \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m---> 67\u001b[0m     h_out \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# for multi-state rnns (e.g., LSTMs), use first state for readout\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(h_out[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/nn/blocks/encoders/recurrent/base.py:46\u001b[0m, in \u001b[0;36mRNNBase.single_pass\u001b[0;34m(self, x, h, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, cell \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcells):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m h_new \u001b[38;5;241m=\u001b[39m \u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(h_new, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/nn/layers/recurrent/base.py:47\u001b[0m, in \u001b[0;36mGRUCellBase.forward\u001b[0;34m(self, x, h, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m x_gates \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, h], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforget_gate(x_gates, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m---> 47\u001b[0m u \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_gates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     48\u001b[0m x_c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, r \u001b[38;5;241m*\u001b[39m h], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m c \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_gate(x_c, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[26], line 45\u001b[0m, in \u001b[0;36mGraphAnisoConv.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     43\u001b[0m out, x_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, x\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size):\n\u001b[0;32m---> 45\u001b[0m     x_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x_\n\u001b[1;32m     47\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_conn(x))\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:523\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 523\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    525\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "Cell \u001b[0;32mIn[26], line 51\u001b[0m, in \u001b[0;36mGraphAnisoConv.message\u001b[0;34m(self, x_i, x_j, idx, edge_attr)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_i, x_j, idx, edge_attr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 51\u001b[0m     mij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg_mlps[idx](\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m edge_attr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# accommodate for edge_weight\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 518.00 MiB. GPU 0 has a total capacity of 22.19 GiB of which 137.50 MiB is free. Process 206593 has 22.05 GiB memory in use. Of the allocated memory 21.61 GiB is allocated by PyTorch, and 145.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "trainer.fit(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the best checkpoint\n",
    "best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "print(f\"Best checkpoint saved at: {best_checkpoint_path}\")\n",
    "\n",
    "# Load the model from the best checkpoint\n",
    "from pytorch_lightning.utilities.memory import load_obj\n",
    "\n",
    "trained_model = TimeAndGraphAnisoModel(\n",
    "    input_size=input_size,\n",
    "    horizon=horizon,\n",
    "    n_nodes=n_nodes,\n",
    "    output_size=input_size,\n",
    "    exog_size=exog_size,\n",
    "    hidden_size=hidden_size\n",
    ")\n",
    "\n",
    "# Load checkpoint weights\n",
    "state_dict = torch.load(best_checkpoint_path)[\"state_dict\"]\n",
    "trained_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/logs/epoch=86-step=1479.ckpt\n"
     ]
    }
   ],
   "source": [
    "# print(checkpoint_callback.best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n",
      "Predictor with already instantiated model is loading a state_dict from /teamspace/studios/this_studio/logs/epoch=86-step=1479.ckpt. Cannot  check if model hyperparameters are the same.\n"
     ]
    }
   ],
   "source": [
    "predictor.load_model(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n",
      "Predictor with already instantiated model is loading a state_dict from /teamspace/studios/this_studio/logs/epoch=86-step=1479.ckpt. Cannot  check if model hyperparameters are the same.\n"
     ]
    }
   ],
   "source": [
    "predictor.load_model('/teamspace/studios/this_studio/logs/epoch=86-step=1479.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbcba6804a240f7b7c07efa2568a66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arguments ['metadata', 'distances'] are filtered out. Only args ['x', 'edge_index', 'edge_weight', 'u'] are forwarded to the model (TimeAndGraphAnisoModel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.000349479349097237    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.007187105715274811    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mape         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2584.482177734375     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.000349479349097237    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mse_at_3       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00036978835123591125   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mse_at_6       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00036310526775196195   </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.000349479349097237   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.007187105715274811   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mape        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2584.482177734375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.000349479349097237   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mse_at_3      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00036978835123591125  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mse_at_6      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00036310526775196195  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_mae': 0.007187105715274811,\n",
       "  'test_mape': 2584.482177734375,\n",
       "  'test_mse': 0.000349479349097237,\n",
       "  'test_mse_at_3': 0.00036978835123591125,\n",
       "  'test_mse_at_6': 0.00036310526775196195,\n",
       "  'test_loss': 0.000349479349097237}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550f45a7372648b2ad43f5e73dd70507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00033514376264065504   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0071140737272799015   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_mape          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     636.721435546875      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00033514376264065504   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_mse_at_3        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0003464221372269094   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_mse_at_6        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0003566509112715721   </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00033514376264065504  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0071140737272799015  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_mape         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    636.721435546875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00033514376264065504  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_mse_at_3       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0003464221372269094  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_mse_at_6       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0003566509112715721  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_mae': 0.0071140737272799015,\n",
       "  'val_mape': 636.721435546875,\n",
       "  'val_mse': 0.00033514376264065504,\n",
       "  'val_mse_at_3': 0.0003464221372269094,\n",
       "  'val_mse_at_6': 0.0003566509112715721,\n",
       "  'val_loss': 0.00033514376264065504}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e86fb26dfa417096e17f19b325808d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_test = trainer.predict(predictor, datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]),\n",
       " 'val': array([153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
       "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
       "        218, 219, 220, 221]),\n",
       " 'test': array([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(ds['date'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01', '2000-02-01', '2000-03-01', '2000-04-01',\n",
       "               '2000-05-01', '2000-06-01', '2000-07-01', '2000-08-01',\n",
       "               '2000-09-01', '2000-10-01',\n",
       "               ...\n",
       "               '2022-03-01', '2022-04-01', '2022-05-01', '2022-06-01',\n",
       "               '2022-07-01', '2022-08-01', '2022-09-01', '2022-10-01',\n",
       "               '2022-11-01', '2022-12-01'],\n",
       "              dtype='datetime64[ns]', length=276, freq=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140]),\n",
       " 'val': array([153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
       "        205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
       "        218, 219, 220, 221]),\n",
       " 'test': array([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.splitter.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140]\n",
      "Validation indices: [153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221]\n",
      "Test indices: [234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258]\n",
      "Shape of y: (25, 6, 21960)\n",
      "Shape of y_hat: (25, 6, 21960)\n",
      "Shape of mask: (25, 6, 21960)\n",
      "Shape of node_ids: (3294000,)\n",
      "Shape of lat_column: (3294000,)\n",
      "Shape of lon_column: (3294000,)\n",
      "Shape of test_dates_steps: (150,)\n",
      "Shape of all_dates_expanded: (3294000,)\n",
      "Shape of y_flat: (3294000,)\n",
      "Shape of y_hat_flat: (3294000,)\n",
      "Shape of mask_flat: (3294000,)\n",
      "Shape of filtered_dates: (3294000,)\n",
      "Shape of filtered_lat: (3294000,)\n",
      "Shape of filtered_lon: (3294000,)\n",
      "Shape of filtered_y: (3294000,)\n",
      "Shape of filtered_y_hat: (3294000,)\n",
      "Shape of filtered_node_ids: (3294000,)\n",
      "        date   lat    lon  node_id        y     y_hat\n",
      "0 2019-07-01 -30.0 -180.0        0  0.00001 -0.000218\n",
      "1 2019-07-01 -30.0 -179.0        1  0.00001 -0.000157\n",
      "2 2019-07-01 -30.0 -178.0        2  0.00001 -0.000154\n",
      "3 2019-07-01 -30.0 -177.0        3  0.00001 -0.000120\n",
      "4 2019-07-01 -30.0 -176.0        4  0.00001 -0.000367\n",
      "(3294000, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import xarray as xr\n",
    "\n",
    "# 1. Load Metadata and Dates\n",
    "metadata_array = np.load('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/metadata.npy')  # Shape: (21960, 2)\n",
    "latitudes = metadata_array[:, 0]\n",
    "longitudes = metadata_array[:, 1]\n",
    "num_nodes = len(latitudes)\n",
    "\n",
    "# Load the original dataset\n",
    "# ds = xr.open_dataset('path_to_your_dataset.nc')  # Replace with your actual path\n",
    "dates = pd.to_datetime(ds['date'].values)\n",
    "total_time_steps = len(dates)\n",
    "\n",
    "# Initialize splitter\n",
    "# splitter = TemporalSplitter(val_len=0.35, test_len=0.1)\n",
    "\n",
    "# Assume you have a SpatioTemporalDataset instance\n",
    "# dataset = your_spatio_temporal_dataset  # Replace with your actual dataset variable\n",
    "\n",
    "# Fit the splitter to the dataset\n",
    "# splitter.fit(dataset)\n",
    "\n",
    "# 2. Correctly Retrieve the Split Indices\n",
    "split_indices = datamodule.splitter.indices\n",
    "train_indices = split_indices['train']\n",
    "val_indices = split_indices['val']\n",
    "test_indices = split_indices['test']\n",
    "\n",
    "print(f\"Train indices: {train_indices}\")\n",
    "print(f\"Validation indices: {val_indices}\")\n",
    "print(f\"Test indices: {test_indices}\")\n",
    "\n",
    "# 3. Process Predictions and Actual Values\n",
    "y_list = []\n",
    "y_hat_list = []\n",
    "mask_list = []\n",
    "\n",
    "for batch in predictions_test:\n",
    "    y_tensor = batch['y']\n",
    "    y_hat_tensor = batch['y_hat']\n",
    "    mask_tensor = batch['mask']\n",
    "    \n",
    "    y_np = y_tensor.cpu().numpy().squeeze(-1)      # Shape: (batch_size, steps, nodes)\n",
    "    y_hat_np = y_hat_tensor.cpu().numpy().squeeze(-1)\n",
    "    mask_np = mask_tensor.cpu().numpy().squeeze(-1)\n",
    "    \n",
    "    y_list.append(y_np)\n",
    "    y_hat_list.append(y_hat_np)\n",
    "    mask_list.append(mask_np)\n",
    "\n",
    "# Concatenate along the batch dimension\n",
    "y = np.concatenate(y_list, axis=0)         # Shape: (num_test_batches, steps, nodes)\n",
    "y_hat = np.concatenate(y_hat_list, axis=0) # Shape: (num_test_batches, steps, nodes)\n",
    "mask = np.concatenate(mask_list, axis=0)   # Shape: (num_test_batches, steps, nodes)\n",
    "\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "print(f\"Shape of y_hat: {y_hat.shape}\")\n",
    "print(f\"Shape of mask: {mask.shape}\")\n",
    "\n",
    "# 4. Map Node IDs to Geographical Coordinates\n",
    "num_steps = y.shape[1]          # Number of prediction steps (e.g., 6)\n",
    "num_test_dates = y.shape[0]     # Number of test dates (e.g., 25)\n",
    "\n",
    "# Create node_ids, lat, lon repeated for each step\n",
    "node_ids = np.tile(np.arange(num_nodes), num_test_dates * num_steps)  # Shape: (3,294,000,)\n",
    "lat_column = np.tile(latitudes, num_test_dates * num_steps)\n",
    "lon_column = np.tile(longitudes, num_test_dates * num_steps)\n",
    "\n",
    "print(f\"Shape of node_ids: {node_ids.shape}\")\n",
    "print(f\"Shape of lat_column: {lat_column.shape}\")\n",
    "print(f\"Shape of lon_column: {lon_column.shape}\")\n",
    "\n",
    "# 5. Align Predictions with Dates\n",
    "\n",
    "# Repeat each test date for the number of prediction steps\n",
    "test_dates_steps = np.repeat(dates[test_indices], num_steps)  # Shape: (25 * 6,) => (150,)\n",
    "\n",
    "# Now, repeat each date for all nodes to align with the predictions\n",
    "all_dates_expanded = np.repeat(test_dates_steps, num_nodes)   # Shape: (150 * 21960,) => (3,294,000,)\n",
    "\n",
    "print(f\"Shape of test_dates_steps: {test_dates_steps.shape}\")       # (150,)\n",
    "print(f\"Shape of all_dates_expanded: {all_dates_expanded.shape}\") # (3,294,000,)\n",
    "\n",
    "# 6. Flatten the Predictions and Mask\n",
    "y_flat = y.flatten()         # Shape: (3,294,000,)\n",
    "y_hat_flat = y_hat.flatten()\n",
    "mask_flat = mask.flatten()\n",
    "\n",
    "print(f\"Shape of y_flat: {y_flat.shape}\")\n",
    "print(f\"Shape of y_hat_flat: {y_hat_flat.shape}\")\n",
    "print(f\"Shape of mask_flat: {mask_flat.shape}\")\n",
    "\n",
    "# 7. Apply Mask to Filter Valid Entries\n",
    "valid_indices = mask_flat.astype(bool)  # Ensure mask is boolean\n",
    "\n",
    "filtered_dates = all_dates_expanded[valid_indices]  # Shape: (num_valid_entries,)\n",
    "filtered_lat = lat_column[valid_indices]\n",
    "filtered_lon = lon_column[valid_indices]\n",
    "filtered_y = y_flat[valid_indices]\n",
    "filtered_y_hat = y_hat_flat[valid_indices]\n",
    "filtered_node_ids = node_ids[valid_indices]\n",
    "\n",
    "print(f\"Shape of filtered_dates: {filtered_dates.shape}\")\n",
    "print(f\"Shape of filtered_lat: {filtered_lat.shape}\")\n",
    "print(f\"Shape of filtered_lon: {filtered_lon.shape}\")\n",
    "print(f\"Shape of filtered_y: {filtered_y.shape}\")\n",
    "print(f\"Shape of filtered_y_hat: {filtered_y_hat.shape}\")\n",
    "print(f\"Shape of filtered_node_ids: {filtered_node_ids.shape}\")\n",
    "\n",
    "# 8. Create the DataFrame\n",
    "df_predictions = pd.DataFrame({\n",
    "    'date': filtered_dates,\n",
    "    'lat': filtered_lat,\n",
    "    'lon': filtered_lon,\n",
    "    'node_id': filtered_node_ids,\n",
    "    'y': filtered_y,\n",
    "    'y_hat': filtered_y_hat\n",
    "})\n",
    "\n",
    "print(df_predictions.head())\n",
    "print(df_predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>node_id</th>\n",
       "      <th>y</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293995</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>21955</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293996</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>21956</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293997</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>21957</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293998</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>21958</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293999</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>21959</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.001478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3294000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   lat    lon  node_id         y     y_hat\n",
       "0       2019-07-01 -30.0 -180.0        0  0.000010 -0.000218\n",
       "1       2019-07-01 -30.0 -179.0        1  0.000010 -0.000157\n",
       "2       2019-07-01 -30.0 -178.0        2  0.000010 -0.000154\n",
       "3       2019-07-01 -30.0 -177.0        3  0.000010 -0.000120\n",
       "4       2019-07-01 -30.0 -176.0        4  0.000010 -0.000367\n",
       "...            ...   ...    ...      ...       ...       ...\n",
       "3293995 2021-07-01  30.0  175.0    21955 -0.000005 -0.001788\n",
       "3293996 2021-07-01  30.0  176.0    21956 -0.000005 -0.001751\n",
       "3293997 2021-07-01  30.0  177.0    21957 -0.000005 -0.001880\n",
       "3293998 2021-07-01  30.0  178.0    21958 -0.000005 -0.001606\n",
       "3293999 2021-07-01  30.0  179.0    21959 -0.000005 -0.001478\n",
       "\n",
       "[3294000 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('ml-drought-forecasting/ml-modeling-pipeline/data/07_model_output/predictions.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_variable_on_map(\n",
    "    dataset: pd.DataFrame,\n",
    "    variable: str,\n",
    "    lat_dim: str = 'latitude',\n",
    "    lon_dim: str = 'longitude',\n",
    "    projection: str = 'natural earth',\n",
    "    color_scale: str = 'Viridis',\n",
    "    title: Optional[str] = None,\n",
    "    animation_frame: Optional[str] = None,\n",
    "    hover_precision: int = 2,\n",
    ") -> go.Figure:\n",
    "\n",
    "    df = dataset\n",
    "\n",
    "    # Drop NaNs\n",
    "    df = df.dropna(subset=[variable])\n",
    "\n",
    "    # Handle animation frame\n",
    "    if animation_frame:\n",
    "        df[animation_frame] = df[animation_frame].astype(str)\n",
    "    else:\n",
    "        df['Frame'] = 'Frame'\n",
    "    \n",
    "    # Create scatter_geo plot\n",
    "    fig = px.scatter_geo(\n",
    "        df,\n",
    "        lat=lat_dim,\n",
    "        lon=lon_dim,\n",
    "        color=variable,\n",
    "        animation_frame=animation_frame if animation_frame else 'Frame',\n",
    "        projection=projection,\n",
    "        color_continuous_scale=color_scale,\n",
    "        title=title,\n",
    "        labels={variable: variable.upper()},\n",
    "        hover_data={variable: f':.{hover_precision}f'},\n",
    "    )\n",
    "    \n",
    "    # Add Play/Pause buttons\n",
    "    fig.update_layout(\n",
    "        updatemenus=[dict(\n",
    "            type='buttons',\n",
    "            buttons=[\n",
    "                dict(label='Play',\n",
    "                     method='animate',\n",
    "                     args=[None, {\"frame\": {\"duration\": 500, \"redraw\": True}, \"fromcurrent\": True}]),\n",
    "                dict(label='Pause',\n",
    "                     method='animate',\n",
    "                     args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}])\n",
    "            ],\n",
    "            showactive=False,\n",
    "            x=0.1,\n",
    "            y=0\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "fig = visualize_variable_on_map(\n",
    "    dataset=df,\n",
    "    variable='y',\n",
    "    lat_dim='lat',\n",
    "    lon_dim='lon',\n",
    "    animation_frame='date',\n",
    "    title='Volumetric soil water layer 1',\n",
    "    color_scale = [\n",
    "        [0.0, \"darkred\"],\n",
    "        [0.1, \"red\"],\n",
    "        [0.2, \"orangered\"],\n",
    "        [0.3, \"lightgreen\"],\n",
    "        [0.4, \"limegreen\"],\n",
    "        [0.5, \"green\"],\n",
    "        [0.55, \"darkseagreen\"],\n",
    "        [0.6, \"darkgreen\"],\n",
    "        [0.7, \"lightblue\"],\n",
    "        [0.8, \"skyblue\"],\n",
    "        [0.9, \"deepskyblue\"],\n",
    "        [1.0, \"blue\"]\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_plotly(predictions, metadata, idx, horizon=None, \n",
    "                                 batches_to_visualize=None, variables_to_visualize=None):\n",
    "    \"\"\"\n",
    "    Visualize predicted vs actual values using Plotly for specified batches and variables with variable-specific normalization.\n",
    "    \n",
    "    Parameters:\n",
    "    - predictions (dict): Contains 'y' and 'y_hat' tensors.\n",
    "    - metadata (pd.DataFrame): DataFrame with 'lat' and 'lon' columns.\n",
    "    - idx (int): Index of the item being visualized.\n",
    "    - horizon (int, optional): Number of time steps to visualize. Defaults to the maximum horizon in data.\n",
    "    - batches_to_visualize (list or range, optional): List of batch indices to visualize. Defaults to all batches.\n",
    "    - variables_to_visualize (list or range, optional): List of variable indices to visualize. Defaults to all variables.\n",
    "    \"\"\"\n",
    "    # Extract predictions and actual values\n",
    "    y_hat = predictions['y_hat'].squeeze().numpy()  # Shape: [batch, horizon, spatial_dim, variables]\n",
    "    y = predictions['y'].squeeze().numpy()          # Shape: [batch, horizon, spatial_dim, variables]\n",
    "\n",
    "    # Ensure y_hat and y have the same shape\n",
    "    assert y_hat.shape == y.shape, \"Predictions and actual values must have the same shape\"\n",
    "\n",
    "    # Determine the horizon if not provided\n",
    "    if horizon is None:\n",
    "        horizon = y_hat.shape[1]\n",
    "\n",
    "    # Determine the number of variables\n",
    "    if y_hat.ndim == 3:\n",
    "        # Shape: [batch, horizon, spatial_dim]\n",
    "        num_variables = 1\n",
    "        y_hat = y_hat[..., np.newaxis]  # Add a variables dimension\n",
    "        y = y[..., np.newaxis]\n",
    "    else:\n",
    "        num_variables = y_hat.shape[-1]\n",
    "\n",
    "    if variables_to_visualize is None:\n",
    "        variables_to_visualize = list(range(num_variables))\n",
    "    else:\n",
    "        # Ensure the variable indices are within the correct range\n",
    "        variables_to_visualize = [v for v in variables_to_visualize if v < num_variables]\n",
    "        if not variables_to_visualize:\n",
    "            raise ValueError(\"No valid variables to visualize. Check 'variables_to_visualize' indices.\")\n",
    "\n",
    "    # Get latitude and longitude from metadata\n",
    "    lats = metadata['lat'].values\n",
    "    lons = metadata['lon'].values\n",
    "\n",
    "    # Ensure that the number of spatial points matches the number of lats and lons\n",
    "    spatial_dim = y_hat.shape[2]\n",
    "    if spatial_dim != len(lats):\n",
    "        raise ValueError(f\"The number of spatial points in predictions ({spatial_dim}) does not match the number of locations in metadata ({len(lats)}).\")\n",
    "\n",
    "    # Calculate the min and max for lats and lons for setting map extent\n",
    "    lat_min, lat_max = lats.min(), lats.max()\n",
    "    lon_min, lon_max = lons.min(), lons.max()\n",
    "\n",
    "    # If batches_to_visualize is None, visualize all batches\n",
    "    if batches_to_visualize is None:\n",
    "        batches_to_visualize = range(y_hat.shape[0])\n",
    "    else:\n",
    "        # Ensure the batch indices are within the correct range\n",
    "        batches_to_visualize = [b for b in batches_to_visualize if b < y_hat.shape[0]]\n",
    "        if not batches_to_visualize:\n",
    "            raise ValueError(\"No valid batches to visualize. Check 'batches_to_visualize' indices.\")\n",
    "\n",
    "    # Precompute min and max for each variable in variables_to_visualize\n",
    "    var_min_max = {}\n",
    "    for var in variables_to_visualize:\n",
    "        var_data_y = y[..., var]  # Shape: [batch, horizon, spatial_dim]\n",
    "        var_data_y_hat = y_hat[..., var]  # Shape: [batch, horizon, spatial_dim]\n",
    "        min_val = min(np.min(var_data_y), np.min(var_data_y_hat))\n",
    "        max_val = max(np.max(var_data_y), np.max(var_data_y_hat))\n",
    "        import numpy as np\n",
    "\n",
    "        # ...\n",
    "\n",
    "        # Loop through each batch and variable\n",
    "        for batch in batches_to_visualize:\n",
    "            for var in variables_to_visualize:\n",
    "                frames = []\n",
    "                slider_steps = []\n",
    "\n",
    "                # Retrieve normalization for the current variable\n",
    "                min_val, max_val = var_min_max[var]\n",
    "\n",
    "                # Get the highest and lowest values of the variable\n",
    "                var_min = np.min(y_hat[batch, :, :, var])\n",
    "                var_max = np.max(y_hat[batch, :, :, var])\n",
    "\n",
    "                # Update the min and max values if necessary\n",
    "                if var_min < min_val:\n",
    "                    min_val = var_min\n",
    "                if var_max > max_val:\n",
    "                    max_val = var_max\n",
    "\n",
    "                # Update the normalization dictionary\n",
    "                var_min_max[var] = (min_val, max_val)\n",
    "\n",
    "                # ...\n",
    "\n",
    "                # Predicted data for current month\n",
    "                pred_data = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y_hat[batch, time_step, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Predicted'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Predicted',\n",
    "                    showlegend=False\n",
    "                )\n",
    "\n",
    "                # Actual data for current month\n",
    "                actual_data = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y[batch, time_step, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Actual'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Actual',\n",
    "                    showlegend=False\n",
    "                )\n",
    "\n",
    "                # ...\n",
    "\n",
    "                # Initial data (first frame)\n",
    "                pred_data_initial = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y_hat[batch, 0, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Predicted'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Predicted',\n",
    "                    showlegend=True\n",
    "                )\n",
    "\n",
    "                actual_data_initial = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y[batch, 0, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Actual'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Actual',\n",
    "                    showlegend=True\n",
    "                )\n",
    "\n",
    "                # ...\n",
    "                        visible=True,\n",
    "                        prefix=\"Date: \",\n",
    "                        xanchor=\"right\",\n",
    "                        font=dict(size=14, color=\"#666\")\n",
    "                    ),\n",
    "                )],\n",
    "                geo=dict(\n",
    "                    scope='world',\n",
    "                    projection_type='natural earth',\n",
    "                    showland=True,\n",
    "                    landcolor='lightgray',\n",
    "                    showcountries=True,\n",
    "                    countrycolor='black',\n",
    "                    lataxis=dict(range=[lat_min - 1, lat_max + 1]),\n",
    "                    lonaxis=dict(range=[lon_min - 1, lon_max + 1]),\n",
    "                ),\n",
    "                geo2=dict(\n",
    "                    scope='world',\n",
    "                    projection_type='natural earth',\n",
    "                    showland=True,\n",
    "                    landcolor='lightgray',\n",
    "                    showcountries=True,\n",
    "                    countrycolor='black',\n",
    "                    lataxis=dict(range=[lat_min - 1, lat_max + 1]),\n",
    "                    lonaxis=dict(range=[lon_min - 1, lon_max + 1]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Update frames to assign traces to correct subplots\n",
    "            for frame in fig.frames:\n",
    "                time_step_idx = int(frame.name.split()[1]) - 1\n",
    "                frame.data = [\n",
    "                    go.Scattergeo(\n",
    "                        lon=lons,\n",
    "                        lat=lats,\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=6,\n",
    "                            color=y_hat[batch, time_step_idx, :, var],\n",
    "                            colorscale='RdYlBu_r',\n",
    "                            cmin=min_val,\n",
    "                            cmax=max_val,\n",
    "                            opacity=0.8\n",
    "                        ),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    go.Scattergeo(\n",
    "                        lon=lons,\n",
    "                        lat=lats,\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=6,\n",
    "                            color=y[batch, time_step_idx, :, var],\n",
    "                            colorscale='RdYlBu_r',\n",
    "                            cmin=min_val,\n",
    "                            cmax=max_val,\n",
    "                            opacity=0.8\n",
    "                        ),\n",
    "                        showlegend=False\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            # Update layout for better appearance\n",
    "            fig.update_layout(\n",
    "                height=600,\n",
    "                width=1200,\n",
    "                margin=dict(l=50, r=50, t=100, b=50)\n",
    "            )\n",
    "\n",
    "            # Display the figure\n",
    "            fig.show()\n",
    "\n",
    "            # Optionally, save the figure to an HTML file\n",
    "            # fig.write_html(f'item_{idx+1}_batch_{batch+1}_variable_{var+1}.html')\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# Assuming you have the metadata DataFrame available\n",
    "# metadata = pd.read_parquet('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/metadata.parquet')\n",
    "\n",
    "# Ensure that predictions_test is a list of dictionaries with 'y' and 'y_hat'\n",
    "# For example:\n",
    "# predictions_test = [{'y': tensor1, 'y_hat': tensor2}, {'y': tensor3, 'y_hat': tensor4}, ...]\n",
    "\n",
    "# # Specify the indices of the items you want to visualize\n",
    "# items_to_visualize = [1]  # Replace with desired item indices (0-based indexing)\n",
    "# batches_to_visualize = [0, 1]  # Replace with desired batch indices within each item\n",
    "# variables_to_visualize = [0]  # Replace with desired variable indices (e.g., if multiple EDDI metrics)\n",
    "\n",
    "# # Call the function for specified items in predictions_test\n",
    "# for idx in items_to_visualize:\n",
    "#     pred = predictions_test[idx]\n",
    "#     visualize_predictions_plotly(\n",
    "#         pred, metadata, idx, horizon=pred['y'].shape[1],\n",
    "#         batches_to_visualize=batches_to_visualize, \n",
    "#         variables_to_visualize=variables_to_visualize\n",
    "#     )\n",
    "#     print(f\"Processed item {idx + 1}/{len(predictions_test)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
