{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SoilWaterDataset object \n",
    "\n",
    "SoilWaterDataset is a fundamental object created based on TabularDataset from the TSL library. Using this object, we will be able to enabling efficient loading, preprocessing, and spatiotemporal structuring of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from tsl.datasets.prototypes import TabularDataset\n",
    "from tsl.ops.similarities import gaussian_kernel\n",
    "\n",
    "class SoilWaterDataset(TabularDataset):\n",
    "\n",
    "    similarity_options = {'distance', 'grid'}\n",
    "\n",
    "    def __init__(self,\n",
    "                 root: str = None\n",
    "                 ):\n",
    "\n",
    "        self.root = root\n",
    "\n",
    "        # Load data\n",
    "        target, mask, u, dist, metadata = self.load()\n",
    "\n",
    "        covariates = {\n",
    "            'u': (u),\n",
    "            'metadata' : (metadata),\n",
    "            'distances': (dist)\n",
    "        }\n",
    "\n",
    "        super().__init__(target=target,\n",
    "                         mask=mask,\n",
    "                         covariates=covariates,\n",
    "                         similarity_score='distance',\n",
    "                         temporal_aggregation='mean',\n",
    "                         spatial_aggregation='mean',\n",
    "                         name='SoilWaterDataset')\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load data from files.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Containing target, mask, covariates, distances, and metadata.\n",
    "        \"\"\"\n",
    "        target_path = f\"{self.root}target.npy\"\n",
    "        mask_path = f\"{self.root}mask.npy\"\n",
    "        dist_path = f\"{self.root}distance_matrix.npy\"\n",
    "        covariates_path = f\"{self.root}covariates.npy\"\n",
    "        metadata_path = f\"{self.root}metadata.npy\"\n",
    "\n",
    "        target = np.load(target_path)\n",
    "        mask = np.load(mask_path)\n",
    "        u = np.load(covariates_path)\n",
    "        dist = np.load(dist_path)\n",
    "        metadata = np.load(metadata_path)\n",
    "\n",
    "        return target, mask, u, dist, metadata\n",
    "\n",
    "\n",
    "    def compute_similarity(self, method: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute similarity matrix based on the specified method.\n",
    "\n",
    "        Args:\n",
    "            method (str): The similarity computation method ('distance' or 'grid').\n",
    "            **kwargs: Additional keyword arguments for similarity computation.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Computed similarity matrix.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unknown similarity method is provided.\n",
    "        \"\"\"\n",
    "        if method == \"distance\":\n",
    "            # Calculate a Gaussian kernel similarity from the distance matrix, using a default or provided 'theta'\n",
    "            theta = kwargs.get('theta', np.std(self.distances))\n",
    "            return gaussian_kernel(self.distances, theta=theta)\n",
    "        elif method == \"grid\":\n",
    "            dist = self.distances.copy()\n",
    "            dist[dist > 16] = np.inf  # keep only grid edges\n",
    "            theta = kwargs.get('theta', 20)\n",
    "            return gaussian_kernel(dist, theta=theta)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown similarity method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SoilWaterDataset(root='ml-drought-forecasting/soil-water-forecasting/data/05_model_input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_mask(dataset.mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create connectivity to our graph \n",
    "\n",
    "Here, we adjust the connectivity to retain only the five nearest neighbors (knn=5) per node, while excluding self-loops and normalizing along the specified axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10663/2660955998.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  connectivity = torch.load(\"ml-drought-forecasting/soil-water-forecasting/data/05_model_input/connectivity.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "connectivity = torch.load(\"ml-drought-forecasting/soil-water-forecasting/data/05_model_input/connectivity.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create torch_dataset \n",
    "\n",
    "torch_dataset, created using SpatioTemporalDataset from the tsl library, structures time-series and spatial data (target, covariates, mask, and connectivity) into a form optimized for spatiotemporal model training, enabling easy handling of lookback windows and prediction horizons in forecasting tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data import SpatioTemporalDataset\n",
    "\n",
    "covariates=dataset.covariates\n",
    "mask = dataset.mask\n",
    "\n",
    "torch_dataset = SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      mask=mask,\n",
    "                                      covariates=covariates,\n",
    "                                      connectivity=connectivity,\n",
    "                                      horizon=6, # Predict 7 step ahead\n",
    "                                      window=12, # Use 30 timestamps to predict the next one\n",
    "                                      stride=1 # Move 7 step forward each time\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datamodule\n",
    "\n",
    "datamodule, created with SpatioTemporalDataModule, manages the SpatioTemporalDataset by applying scaling, splitting data into train/validation/test sets, and preparing data loaders with batch processing, enabling efficient, modular, and scalable data handling for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scalers = {\n",
    "    'target': MinMaxScaler(axis=(0, 1)),\n",
    "    'u': MinMaxScaler(axis=(0, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "                                 \n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=0.35, test_len=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=None, val_len=None, test_len=None, scalers=[target, u], batch_size=1)\n"
     ]
    }
   ],
   "source": [
    "# Create a SpatioTemporalDataModule\n",
    "datamodule = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    mask_scaling=True,\n",
    "    splitter=splitter,\n",
    "    batch_size=1,  # Reduce batch size\n",
    "    workers=2,     # Reduce number of workers\n",
    "    )\n",
    "\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create STGNN Model Architecture\n",
    "\n",
    "The **TimeAndGraphAnisoModel** is built based on code from [HD-TTS\n",
    " repository](https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/time_and_graph_anisotropic.py) and the research paper by Cini et al. (2023d). This model utilizes spatiotemporal architectures equipped with anisotropic message passing for effective time and space representation.\n",
    "\n",
    "### Reference\n",
    "Cini, A., Marisca, I., Zambon, D., and Alippi, C. *Taming Local Effects in Graph-Based Spatiotemporal Forecasting.* In *Advances in Neural Information Processing Systems,* volume 36, pp. 55375–55393. Curran Associates, Inc., 2023.  \n",
    "[https://arxiv.org/abs/2302.04071](https://arxiv.org/abs/2302.04071)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/layers/anisotropic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from tsl.nn.blocks import RNNBase\n",
    "from tsl.nn.layers import Dense, GraphGRUCellBase, Activation\n",
    "\n",
    "\n",
    "class GraphAnisoConv(MessagePassing):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 1,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        super(GraphAnisoConv, self).__init__(aggr=\"add\", node_dim=-2)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.msg_mlps = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2 * (in_channels if i == 0 else out_channels),\n",
    "                          out_channels),\n",
    "                Activation(activation),\n",
    "                nn.Linear(out_channels, out_channels),\n",
    "            )\n",
    "            for i in range(kernel_size)\n",
    "        ])\n",
    "\n",
    "        edge_dim = edge_dim or 1  # accommodate for edge_weight\n",
    "        self.lin_edge = nn.Linear(edge_dim, out_channels, bias=False)\n",
    "\n",
    "        self.gate_mlp = Dense(out_channels, 1, activation='sigmoid')\n",
    "\n",
    "        self.skip_conn = nn.Linear(in_channels, out_channels)\n",
    "        self.activation = Activation(activation)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr: Optional[Tensor] = None):\n",
    "        \"\"\"\"\"\"\n",
    "        out, x_ = 0, x\n",
    "        for idx in range(self.kernel_size):\n",
    "            x_ = self.propagate(edge_index, idx=idx, x=x_, edge_attr=edge_attr)\n",
    "            out += x_\n",
    "        out = self.activation(out + self.skip_conn(x))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, idx, edge_attr: Optional[Tensor] = None):\n",
    "        mij = self.msg_mlps[idx](torch.cat([x_i, x_j], -1))\n",
    "        if edge_attr is not None:\n",
    "            if edge_attr.ndim == 1:  # accommodate for edge_weight\n",
    "                edge_attr = edge_attr.view(-1, 1)\n",
    "            mij = mij + self.lin_edge(edge_attr)\n",
    "        return self.gate_mlp(mij) * mij\n",
    "\n",
    "\n",
    "class GraphAnisoGRUCell(GraphGRUCellBase):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        self.input_size = input_size\n",
    "        # instantiate gates\n",
    "        forget_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                     edge_dim=edge_dim, activation=activation)\n",
    "        update_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                     edge_dim=edge_dim, activation=activation)\n",
    "        candidate_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                        edge_dim=edge_dim,\n",
    "                                        activation=activation)\n",
    "        super(GraphAnisoGRUCell, self).__init__(hidden_size=hidden_size,\n",
    "                                                forget_gate=forget_gate,\n",
    "                                                update_gate=update_gate,\n",
    "                                                candidate_gate=candidate_gate)\n",
    "\n",
    "\n",
    "class GraphAnisoGRU(RNNBase):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 n_layers: int = 1, cat_states_layers: bool = False,\n",
    "                 return_only_last_state: bool = False,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        rnn_cells = [\n",
    "            GraphAnisoGRUCell(input_size if i == 0 else hidden_size,\n",
    "                              hidden_size, edge_dim=edge_dim,\n",
    "                              activation=activation)\n",
    "            for i in range(n_layers)\n",
    "        ]\n",
    "        super(GraphAnisoGRU, self).__init__(rnn_cells, cat_states_layers,\n",
    "                                            return_only_last_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/prototypes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch_geometric.typing import Adj\n",
    "from tsl.nn.blocks import MLPDecoder\n",
    "from tsl.nn.layers import MultiLinear, NodeEmbedding\n",
    "from tsl.nn.models import BaseModel\n",
    "from tsl.nn.utils import maybe_cat_exog\n",
    "from tsl.utils import ensure_list\n",
    "\n",
    "\n",
    "def maybe_cat_emb(x: Tensor, emb: Optional[Tensor]):\n",
    "    if emb is None:\n",
    "        return x\n",
    "    if emb.ndim < x.ndim:\n",
    "        emb = emb[[None] * (x.ndim - emb.ndim)]\n",
    "    emb = emb.expand(*x.shape[:-1], -1)\n",
    "    return torch.cat([x, emb], dim=-1)\n",
    "\n",
    "\n",
    "class STGNN(BaseModel):\n",
    "    available_embedding_pos = {'encoding', 'decoding'}\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int,\n",
    "                 n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Optional[\n",
    "                     Union[str, List[str]]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 activation: str = 'elu'):\n",
    "        super(STGNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.horizon = horizon\n",
    "        self.n_nodes = n_nodes\n",
    "        self.output_size = output_size or input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.exog_size = exog_size\n",
    "        self.activation = activation\n",
    "\n",
    "        # EMBEDDING\n",
    "        if add_embedding_before is None:\n",
    "            add_embedding_before = set()\n",
    "        else:\n",
    "            add_embedding_before = set(ensure_list(add_embedding_before))\n",
    "            if not add_embedding_before.issubset(self.available_embedding_pos):\n",
    "                raise ValueError(\"Parameter 'add_embedding_before' must be a \"\n",
    "                                 f\"subset of {self.available_embedding_pos}\")\n",
    "        self.add_embedding_before = add_embedding_before\n",
    "\n",
    "        if emb_size > 0:\n",
    "            self.emb = NodeEmbedding(n_nodes, emb_size)\n",
    "        else:\n",
    "            self.register_module('emb', None)\n",
    "\n",
    "        # ENCODER\n",
    "        self.encoder_input = input_size + exog_size\n",
    "        if 'encoding' in self.add_embedding_before and self.emb is not None:\n",
    "            self.encoder_input += emb_size\n",
    "\n",
    "        if use_local_weights is not None:\n",
    "            self.use_local_weights = set(ensure_list(use_local_weights))\n",
    "            if len(self.use_local_weights.difference(['encoder', 'decoder'])):\n",
    "                raise ValueError(\"Parameter 'use_local_weights' must be \"\n",
    "                                 \"'encoder', 'decoder', or both.\")\n",
    "        else:\n",
    "            self.use_local_weights = set()\n",
    "\n",
    "        if 'encoder' in self.use_local_weights:\n",
    "            self.encoder = MultiLinear(self.encoder_input, hidden_size, n_nodes)\n",
    "        else:\n",
    "            self.encoder = nn.Linear(self.encoder_input, hidden_size)\n",
    "\n",
    "        # DECODER\n",
    "        self.decoder_input = hidden_size\n",
    "        if 'decoding' in self.add_embedding_before and self.emb is not None:\n",
    "            self.decoder_input += emb_size\n",
    "        if 'decoder' in self.use_local_weights:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            self.decoder = MLPDecoder(input_size=self.decoder_input,\n",
    "                                      hidden_size=self.hidden_size,\n",
    "                                      output_size=self.output_size,\n",
    "                                      horizon=self.horizon,\n",
    "                                      activation=self.activation)\n",
    "\n",
    "    def stmp(self, x: Tensor, edge_index: Adj,\n",
    "             edge_weight: Optional[Tensor] = None,\n",
    "             emb: Optional[Tensor] = None) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj,\n",
    "                edge_weight: Optional[Tensor] = None,\n",
    "                u: Optional[Tensor] = None,\n",
    "                node_idx: Optional[Tensor] = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        # x: [batches steps nodes features]\n",
    "        x = maybe_cat_exog(x, u)\n",
    "        batch_size = x.size(0)\n",
    "        emb = self.emb(expand=(batch_size, -1, -1),\n",
    "                       node_index=node_idx) if self.emb is not None else None\n",
    "\n",
    "        if 'encoding' in self.add_embedding_before and emb is not None:\n",
    "            x = maybe_cat_emb(x, emb[:, None])\n",
    "\n",
    "        # ENCODER   ###########################################################\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # SPATIOTEMPORAL MESSAGE-PASSING   ####################################\n",
    "        out = self.stmp(x, edge_index, edge_weight, emb)\n",
    "\n",
    "        # DECODER   ###########################################################\n",
    "        if 'decoding' in self.add_embedding_before:\n",
    "            out = maybe_cat_emb(out, emb)\n",
    "\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TimeAndSpace(STGNN):\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int, stmp_conv: nn.Module,\n",
    "                 n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Union[str, List[str]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 activation: str = 'elu'):\n",
    "        super(TimeAndSpace, self).__init__(input_size=input_size,\n",
    "                                           horizon=horizon,\n",
    "                                           n_nodes=n_nodes,\n",
    "                                           output_size=output_size,\n",
    "                                           exog_size=exog_size,\n",
    "                                           hidden_size=hidden_size,\n",
    "                                           emb_size=emb_size,\n",
    "                                           add_embedding_before=add_embedding_before,\n",
    "                                           use_local_weights=use_local_weights,\n",
    "                                           activation=activation)\n",
    "\n",
    "        # STMP\n",
    "        self.stmp_conv = stmp_conv\n",
    "\n",
    "    def stmp(self, x: Tensor, edge_index: Adj,\n",
    "             edge_weight: Optional[Tensor] = None,\n",
    "             emb: Optional[Tensor] = None) -> Tensor:\n",
    "        # spatiotemporal encoding\n",
    "        out = self.stmp_conv(x, edge_index, edge_weight)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/time_and_graph_anisotropic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "class TimeAndGraphAnisoModel(TimeAndSpace):\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int, n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Union[str, List[str]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 n_layers: int = 1,\n",
    "                 activation: str = 'elu'):\n",
    "        stmp_conv = GraphAnisoGRU(input_size=hidden_size,\n",
    "                                  hidden_size=hidden_size,\n",
    "                                  n_layers=n_layers,\n",
    "                                  activation=activation,\n",
    "                                  return_only_last_state=True)\n",
    "        super(TimeAndGraphAnisoModel, self).__init__(\n",
    "            input_size=input_size,\n",
    "            horizon=horizon,\n",
    "            stmp_conv=stmp_conv,\n",
    "            n_nodes=n_nodes,\n",
    "            output_size=output_size,\n",
    "            exog_size=exog_size,\n",
    "            hidden_size=hidden_size,\n",
    "            emb_size=emb_size,\n",
    "            add_embedding_before=add_embedding_before,\n",
    "            use_local_weights=use_local_weights,\n",
    "            activation=activation\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model \n",
    "\n",
    "Model is configured with hidden units, feed-forward layers, multiple SpatioTemporalConvNet blocks, and utilizes temporal and spatial convolution kernels, layer normalization, and gated mechanisms; it adapts to the dataset’s input size, number of nodes, horizon, and available exogenous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 32          # Number of hidden units\n",
    "ff_size = 64             # Number of units in the feed-forward layers\n",
    "n_layers = 3              # Number of SpatioTemporalConvNet blocks\n",
    "temporal_kernel_size = 3  # Size of the temporal convolution kernel\n",
    "spatial_kernel_size = 3   # Order of the spatial diffusion process\n",
    "norm='layer'\n",
    "gated=True\n",
    "\n",
    "input_size = torch_dataset.n_channels\n",
    "n_nodes = torch_dataset.n_nodes\n",
    "horizon = torch_dataset.horizon\n",
    "exog_size = torch_dataset.input_map.u.shape[-1] if 'u' in torch_dataset else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeAndGraphAnisoModel(\n",
      "  (emb): None\n",
      "  (encoder): Linear(in_features=23, out_features=32, bias=True)\n",
      "  (decoder): MLPDecoder(\n",
      "    (readout): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Dense(\n",
      "          (affinity): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (activation): ELU(alpha=1.0)\n",
      "          (dropout): Identity()\n",
      "        )\n",
      "      )\n",
      "      (readout): Linear(in_features=32, out_features=6, bias=True)\n",
      "    )\n",
      "    (rearrange): Rearrange('b n (h f) -> b h n f', f=1, h=6)\n",
      "  )\n",
      "  (stmp_conv): GraphAnisoGRU(cell=GraphAnisoGRUCell, return_only_last_state=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TimeAndGraphAnisoModel(\n",
    "    input_size=input_size,\n",
    "    horizon=horizon,\n",
    "    n_nodes=n_nodes,\n",
    "    output_size=input_size,\n",
    "    exog_size=exog_size,\n",
    "    hidden_size=hidden_size\n",
    ")\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "Number of model (TimeAndGraphAnisoModel) parameters:     24009\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training \n",
    "\n",
    "This setup initializes a Predictor for the model with a masked mean-squared error loss function and multiple evaluation metrics (MSE, MAE, MAPE, and specific MSE at selected timesteps), then configures a Trainer using PyTorch Lightning with early stopping and model checkpointing based on validation MSE, gradient clipping to prevent exploding gradients, and 16-bit precision for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.metrics.torch import MaskedMSE, MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Predictor\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = MaskedMSE()\n",
    "\n",
    "# Setup metrics\n",
    "metrics = {\n",
    "    'mse': MaskedMSE(),\n",
    "    'mae': MaskedMAE(),\n",
    "    'mape': MaskedMAPE(),\n",
    "    'mse_at_3': MaskedMSE(at=2),  # '2' indicates the third time step\n",
    "    'mse_at_6': MaskedMSE(at=5)\n",
    "}\n",
    "\n",
    "# Setup predictor\n",
    "predictor = Predictor(\n",
    "    model=model,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs={'lr': 0.001},\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lightning.ai/docs/pytorch/stable/common/trainer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_mse',\n",
    "    patience=30,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Logs \n",
    "dirpath = Path('ml-drought-forecasting/soil-water-forecasting/data/06_models/TimeAndGraphAniso/logs')\n",
    "\n",
    "dirpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=dirpath,\n",
    "    save_top_k=1,\n",
    "    monitor='val_mse', \n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Setup trainer\n",
    "trainer = pl.Trainer(max_epochs=2,\n",
    "                    #  logger=logger,\n",
    "                    #  limit_train_batches=100,  # end an epoch after 200 updates\n",
    "                     callbacks=[early_stop_callback, checkpoint_callback],\n",
    "                     log_every_n_steps=2,\n",
    "                     gradient_clip_val=1.0,    # Prevent exploding gradients\n",
    "                     precision=16\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set float32 matmul precision to 'medium' or 'high'\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "# multiprocessing.set_start_method('spawn', force=True)\n",
    "# trainer.fit(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n",
      "Predictor with already instantiated model is loading a state_dict from /teamspace/studios/this_studio/ml-drought-forecasting/soil-water-forecasting/data/06_models/TimeAndGraphAniso/logs/epoch=1-step=70.ckpt. Cannot  check if model hyperparameters are the same.\n"
     ]
    }
   ],
   "source": [
    "# Load only the state_dict (weights) safely\n",
    "predictor.load_model('/teamspace/studios/this_studio/ml-drought-forecasting/soil-water-forecasting/data/06_models/TimeAndGraphAniso/logs/epoch=1-step=70.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SpatioTemporalDataModule.val_dataloader of SpatioTemporalDataModule(train_len=35, val_len=13, test_len=7, scalers=[target, u], batch_size=1)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:277\u001b[0m, in \u001b[0;36mPredictor.predict_batch\u001b[0;34m(self, batch, preprocess, postprocess, return_target, **forward_kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    245\u001b[0m                   batch: Data,\n\u001b[1;32m    246\u001b[0m                   preprocess: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    247\u001b[0m                   postprocess: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    248\u001b[0m                   return_target: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    249\u001b[0m                   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_kwargs):\n\u001b[1;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method takes as input a :class:`~tsl.data.Data` object and\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    outputs the predictions.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m            method.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     inputs, targets, mask, transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unpack_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocess:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, trans \u001b[38;5;129;01min\u001b[39;00m transform\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:239\u001b[0m, in \u001b[0;36mPredictor._unpack_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unpack_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    Unpack a batch into data and preprocessing dictionaries.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    :param batch: the batch\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    :return: batch_data, batch_preprocessing\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, batch\u001b[38;5;241m.\u001b[39mtarget\n\u001b[1;32m    240\u001b[0m     mask \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     transform \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'input'"
     ]
    }
   ],
   "source": [
    "predictor.predict_batch(datamodule.val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10663/1117433798.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/teamspace/studios/this_studio/ml-drought-forecasting/soil-water-forecasting/data/06_models/TimeAndGraphAniso/logs/epoch=1-step=70.ckpt')\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('/teamspace/studios/this_studio/ml-drought-forecasting/soil-water-forecasting/data/06_models/TimeAndGraphAniso/logs/epoch=1-step=70.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/serialization.py:564\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 564\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(f\u001b[38;5;241m.\u001b[39mtell())\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:121\u001b[0m, in \u001b[0;36mPredictor.load_model\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load model's weights from checkpoint at :attr:`filename`.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    Differently from\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    checkpoint's model are the same of the predictor's model.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# if predictor.model has been instantiated inside predictor\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/serialization.py:473\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _open_buffer_writer(name_or_buffer)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_buffer_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in mode but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/serialization.py:458\u001b[0m, in \u001b[0;36m_open_buffer_reader.__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer):\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(buffer)\n\u001b[0;32m--> 458\u001b[0m     \u001b[43m_check_seekable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/serialization.py:567\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (io\u001b[38;5;241m.\u001b[39mUnsupportedOperation, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 567\u001b[0m     \u001b[43mraise_err_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseek\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/serialization.py:560\u001b[0m, in \u001b[0;36m_check_seekable.<locals>.raise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m    557\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. You can only torch.load from a file that is seekable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pre-load the data into a buffer like io.BytesIO and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m try to load from it instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 560\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg)\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "source": [
    "predictor.load_model(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'load_from_checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/teamspace/studios/this_studio/ml-drought-forecasting/soil-water-forecasting/data/06_models/TimeAndGraphAniso/logs/epoch=1-step=70.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'load_from_checkpoint'"
     ]
    }
   ],
   "source": [
    "trainer = trainer.load_from_checkpoint(\"/teamspace/studios/this_studio/ml-drought-forecasting/soil-water-forecasting/data/06_models/TimeAndGraphAniso/logs/epoch=1-step=70.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd7a58dfb064bcfb9e56408eb584325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 30525, 30544) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/multiprocessing/queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:858\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:897\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    894\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    896\u001b[0m )\n\u001b[0;32m--> 897\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1020\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/prediction_loop.py:121\u001b[0m, in \u001b[0;36m_PredictionLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1144\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1143\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 30525, 30544) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "predictions_test = trainer.predict(predictor, datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'y': tensor([[[[ 2.9829e-01],\n",
       "            [ 2.9829e-01],\n",
       "            [ 2.9829e-01],\n",
       "            ...,\n",
       "            [-5.7735e-06],\n",
       "            [-5.7735e-06],\n",
       "            [-5.7735e-06]],\n",
       "  \n",
       "           [[ 2.9800e-01],\n",
       "            [ 2.9800e-01],\n",
       "            [ 2.9800e-01],\n",
       "            ...,\n",
       "            [ 4.2701e-07],\n",
       "            [ 4.2701e-07],\n",
       "            [ 4.2701e-07]],\n",
       "  \n",
       "           [[ 3.1431e-01],\n",
       "            [ 3.1431e-01],\n",
       "            [ 3.1431e-01],\n",
       "            ...,\n",
       "            [-9.6592e-06],\n",
       "            [-9.6592e-06],\n",
       "            [-9.6592e-06]],\n",
       "  \n",
       "           [[ 3.1568e-01],\n",
       "            [ 3.1568e-01],\n",
       "            [ 3.1568e-01],\n",
       "            ...,\n",
       "            [-5.9584e-06],\n",
       "            [-5.9584e-06],\n",
       "            [-5.9584e-06]],\n",
       "  \n",
       "           [[ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            ...,\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06]],\n",
       "  \n",
       "           [[ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            ...,\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06]]]]),\n",
       "  'y_hat': tensor([[[[ 0.2305],\n",
       "            [ 0.2897],\n",
       "            [ 0.2891],\n",
       "            ...,\n",
       "            [-0.0046],\n",
       "            [-0.0046],\n",
       "            [ 0.0143]],\n",
       "  \n",
       "           [[ 0.1691],\n",
       "            [ 0.2831],\n",
       "            [ 0.2826],\n",
       "            ...,\n",
       "            [-0.0070],\n",
       "            [-0.0069],\n",
       "            [-0.0139]],\n",
       "  \n",
       "           [[ 0.1598],\n",
       "            [ 0.2994],\n",
       "            [ 0.2991],\n",
       "            ...,\n",
       "            [ 0.0059],\n",
       "            [ 0.0060],\n",
       "            [ 0.1026]],\n",
       "  \n",
       "           [[ 0.2903],\n",
       "            [ 0.2908],\n",
       "            [ 0.2904],\n",
       "            ...,\n",
       "            [-0.0056],\n",
       "            [-0.0056],\n",
       "            [ 0.0156]],\n",
       "  \n",
       "           [[ 0.2462],\n",
       "            [ 0.2755],\n",
       "            [ 0.2751],\n",
       "            ...,\n",
       "            [-0.0048],\n",
       "            [-0.0048],\n",
       "            [ 0.0132]],\n",
       "  \n",
       "           [[-0.0231],\n",
       "            [ 0.3150],\n",
       "            [ 0.3144],\n",
       "            ...,\n",
       "            [ 0.0026],\n",
       "            [ 0.0026],\n",
       "            [ 0.0539]]]]),\n",
       "  'mask': tensor([[[[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]]]])},\n",
       " {'y': tensor([[[[ 2.9800e-01],\n",
       "            [ 2.9800e-01],\n",
       "            [ 2.9800e-01],\n",
       "            ...,\n",
       "            [ 4.2701e-07],\n",
       "            [ 4.2701e-07],\n",
       "            [ 4.2701e-07]],\n",
       "  \n",
       "           [[ 3.1431e-01],\n",
       "            [ 3.1431e-01],\n",
       "            [ 3.1431e-01],\n",
       "            ...,\n",
       "            [-9.6592e-06],\n",
       "            [-9.6592e-06],\n",
       "            [-9.6592e-06]],\n",
       "  \n",
       "           [[ 3.1568e-01],\n",
       "            [ 3.1568e-01],\n",
       "            [ 3.1568e-01],\n",
       "            ...,\n",
       "            [-5.9584e-06],\n",
       "            [-5.9584e-06],\n",
       "            [-5.9584e-06]],\n",
       "  \n",
       "           [[ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            ...,\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06]],\n",
       "  \n",
       "           [[ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            ...,\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06]],\n",
       "  \n",
       "           [[ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            ...,\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05]]]]),\n",
       "  'y_hat': tensor([[[[ 0.2286],\n",
       "            [ 0.2921],\n",
       "            [ 0.2919],\n",
       "            ...,\n",
       "            [-0.0063],\n",
       "            [-0.0063],\n",
       "            [ 0.0101]],\n",
       "  \n",
       "           [[ 0.1694],\n",
       "            [ 0.2869],\n",
       "            [ 0.2867],\n",
       "            ...,\n",
       "            [-0.0091],\n",
       "            [-0.0091],\n",
       "            [-0.0147]],\n",
       "  \n",
       "           [[ 0.1597],\n",
       "            [ 0.3071],\n",
       "            [ 0.3071],\n",
       "            ...,\n",
       "            [ 0.0063],\n",
       "            [ 0.0063],\n",
       "            [ 0.1041]],\n",
       "  \n",
       "           [[ 0.2910],\n",
       "            [ 0.2947],\n",
       "            [ 0.2942],\n",
       "            ...,\n",
       "            [-0.0064],\n",
       "            [-0.0064],\n",
       "            [ 0.0115]],\n",
       "  \n",
       "           [[ 0.2449],\n",
       "            [ 0.2788],\n",
       "            [ 0.2788],\n",
       "            ...,\n",
       "            [-0.0072],\n",
       "            [-0.0072],\n",
       "            [ 0.0114]],\n",
       "  \n",
       "           [[-0.0263],\n",
       "            [ 0.3219],\n",
       "            [ 0.3221],\n",
       "            ...,\n",
       "            [ 0.0012],\n",
       "            [ 0.0014],\n",
       "            [ 0.0545]]]]),\n",
       "  'mask': tensor([[[[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]]]])},\n",
       " {'y': tensor([[[[ 3.1431e-01],\n",
       "            [ 3.1431e-01],\n",
       "            [ 3.1431e-01],\n",
       "            ...,\n",
       "            [-9.6592e-06],\n",
       "            [-9.6592e-06],\n",
       "            [-9.6592e-06]],\n",
       "  \n",
       "           [[ 3.1568e-01],\n",
       "            [ 3.1568e-01],\n",
       "            [ 3.1568e-01],\n",
       "            ...,\n",
       "            [-5.9584e-06],\n",
       "            [-5.9584e-06],\n",
       "            [-5.9584e-06]],\n",
       "  \n",
       "           [[ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            ...,\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06]],\n",
       "  \n",
       "           [[ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            ...,\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06]],\n",
       "  \n",
       "           [[ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            ...,\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05]],\n",
       "  \n",
       "           [[ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            ...,\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08]]]]),\n",
       "  'y_hat': tensor([[[[ 0.2891],\n",
       "            [ 0.3039],\n",
       "            [ 0.3039],\n",
       "            ...,\n",
       "            [-0.0078],\n",
       "            [-0.0078],\n",
       "            [ 0.0096]],\n",
       "  \n",
       "           [[ 0.1836],\n",
       "            [ 0.3043],\n",
       "            [ 0.3045],\n",
       "            ...,\n",
       "            [-0.0114],\n",
       "            [-0.0115],\n",
       "            [-0.0150]],\n",
       "  \n",
       "           [[ 0.1718],\n",
       "            [ 0.3236],\n",
       "            [ 0.3238],\n",
       "            ...,\n",
       "            [ 0.0051],\n",
       "            [ 0.0051],\n",
       "            [ 0.1046]],\n",
       "  \n",
       "           [[ 0.3285],\n",
       "            [ 0.3153],\n",
       "            [ 0.3157],\n",
       "            ...,\n",
       "            [-0.0072],\n",
       "            [-0.0072],\n",
       "            [ 0.0109]],\n",
       "  \n",
       "           [[ 0.2693],\n",
       "            [ 0.2921],\n",
       "            [ 0.2923],\n",
       "            ...,\n",
       "            [-0.0089],\n",
       "            [-0.0089],\n",
       "            [ 0.0109]],\n",
       "  \n",
       "           [[ 0.0301],\n",
       "            [ 0.3303],\n",
       "            [ 0.3303],\n",
       "            ...,\n",
       "            [-0.0012],\n",
       "            [-0.0013],\n",
       "            [ 0.0545]]]]),\n",
       "  'mask': tensor([[[[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]]]])},\n",
       " {'y': tensor([[[[ 3.1568e-01],\n",
       "            [ 3.1568e-01],\n",
       "            [ 3.1568e-01],\n",
       "            ...,\n",
       "            [-5.9584e-06],\n",
       "            [-5.9584e-06],\n",
       "            [-5.9584e-06]],\n",
       "  \n",
       "           [[ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            ...,\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06]],\n",
       "  \n",
       "           [[ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            ...,\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06]],\n",
       "  \n",
       "           [[ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            ...,\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05]],\n",
       "  \n",
       "           [[ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            ...,\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08]],\n",
       "  \n",
       "           [[ 3.1582e-01],\n",
       "            [ 3.1582e-01],\n",
       "            [ 3.1582e-01],\n",
       "            ...,\n",
       "            [-7.3153e-06],\n",
       "            [-7.3153e-06],\n",
       "            [-7.3153e-06]]]]),\n",
       "  'y_hat': tensor([[[[ 0.3065],\n",
       "            [ 0.3144],\n",
       "            [ 0.3146],\n",
       "            ...,\n",
       "            [-0.0079],\n",
       "            [-0.0079],\n",
       "            [ 0.0112]],\n",
       "  \n",
       "           [[ 0.1878],\n",
       "            [ 0.3150],\n",
       "            [ 0.3152],\n",
       "            ...,\n",
       "            [-0.0124],\n",
       "            [-0.0125],\n",
       "            [-0.0158]],\n",
       "  \n",
       "           [[ 0.1754],\n",
       "            [ 0.3326],\n",
       "            [ 0.3326],\n",
       "            ...,\n",
       "            [ 0.0037],\n",
       "            [ 0.0036],\n",
       "            [ 0.1049]],\n",
       "  \n",
       "           [[ 0.3395],\n",
       "            [ 0.3303],\n",
       "            [ 0.3305],\n",
       "            ...,\n",
       "            [-0.0082],\n",
       "            [-0.0083],\n",
       "            [ 0.0115]],\n",
       "  \n",
       "           [[ 0.2762],\n",
       "            [ 0.3006],\n",
       "            [ 0.3009],\n",
       "            ...,\n",
       "            [-0.0098],\n",
       "            [-0.0099],\n",
       "            [ 0.0108]],\n",
       "  \n",
       "           [[ 0.0473],\n",
       "            [ 0.3346],\n",
       "            [ 0.3346],\n",
       "            ...,\n",
       "            [-0.0021],\n",
       "            [-0.0021],\n",
       "            [ 0.0534]]]]),\n",
       "  'mask': tensor([[[[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]]]])},\n",
       " {'y': tensor([[[[ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            [ 3.1438e-01],\n",
       "            ...,\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06],\n",
       "            [ 1.1064e-06]],\n",
       "  \n",
       "           [[ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            ...,\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06]],\n",
       "  \n",
       "           [[ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            ...,\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05]],\n",
       "  \n",
       "           [[ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            ...,\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08]],\n",
       "  \n",
       "           [[ 3.1582e-01],\n",
       "            [ 3.1582e-01],\n",
       "            [ 3.1582e-01],\n",
       "            ...,\n",
       "            [-7.3153e-06],\n",
       "            [-7.3153e-06],\n",
       "            [-7.3153e-06]],\n",
       "  \n",
       "           [[ 3.2181e-01],\n",
       "            [ 3.2181e-01],\n",
       "            [ 3.2181e-01],\n",
       "            ...,\n",
       "            [ 4.5274e-06],\n",
       "            [ 4.5274e-06],\n",
       "            [ 4.5274e-06]]]]),\n",
       "  'y_hat': tensor([[[[ 3.0242e-01],\n",
       "            [ 3.1179e-01],\n",
       "            [ 3.1179e-01],\n",
       "            ...,\n",
       "            [-8.9727e-03],\n",
       "            [-8.9727e-03],\n",
       "            [ 2.8540e-02]],\n",
       "  \n",
       "           [[ 1.8688e-01],\n",
       "            [ 3.1591e-01],\n",
       "            [ 3.1610e-01],\n",
       "            ...,\n",
       "            [-1.5480e-02],\n",
       "            [-1.5492e-02],\n",
       "            [-1.7178e-02]],\n",
       "  \n",
       "           [[ 1.7452e-01],\n",
       "            [ 3.3426e-01],\n",
       "            [ 3.3426e-01],\n",
       "            ...,\n",
       "            [-2.4925e-04],\n",
       "            [-2.2072e-04],\n",
       "            [ 1.0457e-01]],\n",
       "  \n",
       "           [[ 3.3707e-01],\n",
       "            [ 3.2939e-01],\n",
       "            [ 3.2977e-01],\n",
       "            ...,\n",
       "            [-1.0272e-02],\n",
       "            [-1.0307e-02],\n",
       "            [ 2.5988e-02]],\n",
       "  \n",
       "           [[ 2.7433e-01],\n",
       "            [ 2.9905e-01],\n",
       "            [ 2.9905e-01],\n",
       "            ...,\n",
       "            [-1.2092e-02],\n",
       "            [-1.2150e-02],\n",
       "            [ 1.3207e-02]],\n",
       "  \n",
       "           [[ 4.2796e-02],\n",
       "            [ 3.3445e-01],\n",
       "            [ 3.3426e-01],\n",
       "            ...,\n",
       "            [-3.1483e-03],\n",
       "            [-3.2156e-03],\n",
       "            [ 4.6565e-02]]]]),\n",
       "  'mask': tensor([[[[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]]]])},\n",
       " {'y': tensor([[[[ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            [ 3.1875e-01],\n",
       "            ...,\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06],\n",
       "            [-9.4743e-06]],\n",
       "  \n",
       "           [[ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            ...,\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05]],\n",
       "  \n",
       "           [[ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            ...,\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08]],\n",
       "  \n",
       "           [[ 3.1582e-01],\n",
       "            [ 3.1582e-01],\n",
       "            [ 3.1582e-01],\n",
       "            ...,\n",
       "            [-7.3153e-06],\n",
       "            [-7.3153e-06],\n",
       "            [-7.3153e-06]],\n",
       "  \n",
       "           [[ 3.2181e-01],\n",
       "            [ 3.2181e-01],\n",
       "            [ 3.2181e-01],\n",
       "            ...,\n",
       "            [ 4.5274e-06],\n",
       "            [ 4.5274e-06],\n",
       "            [ 4.5274e-06]],\n",
       "  \n",
       "           [[ 3.2686e-01],\n",
       "            [ 3.2686e-01],\n",
       "            [ 3.2686e-01],\n",
       "            ...,\n",
       "            [-3.5299e-06],\n",
       "            [-3.5299e-06],\n",
       "            [-3.5299e-06]]]]),\n",
       "  'y_hat': tensor([[[[ 0.2320],\n",
       "            [ 0.3142],\n",
       "            [ 0.3135],\n",
       "            ...,\n",
       "            [-0.0078],\n",
       "            [-0.0078],\n",
       "            [ 0.0238]],\n",
       "  \n",
       "           [[ 0.1701],\n",
       "            [ 0.3109],\n",
       "            [ 0.3099],\n",
       "            ...,\n",
       "            [-0.0150],\n",
       "            [-0.0150],\n",
       "            [-0.0109]],\n",
       "  \n",
       "           [[ 0.1604],\n",
       "            [ 0.3339],\n",
       "            [ 0.3331],\n",
       "            ...,\n",
       "            [-0.0008],\n",
       "            [-0.0008],\n",
       "            [ 0.0984]],\n",
       "  \n",
       "           [[ 0.2929],\n",
       "            [ 0.3249],\n",
       "            [ 0.3238],\n",
       "            ...,\n",
       "            [-0.0093],\n",
       "            [-0.0093],\n",
       "            [ 0.0269]],\n",
       "  \n",
       "           [[ 0.2462],\n",
       "            [ 0.2970],\n",
       "            [ 0.2964],\n",
       "            ...,\n",
       "            [-0.0111],\n",
       "            [-0.0111],\n",
       "            [ 0.0180]],\n",
       "  \n",
       "           [[-0.0231],\n",
       "            [ 0.3399],\n",
       "            [ 0.3397],\n",
       "            ...,\n",
       "            [-0.0035],\n",
       "            [-0.0035],\n",
       "            [ 0.0526]]]]),\n",
       "  'mask': tensor([[[[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]]]])},\n",
       " {'y': tensor([[[[ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            [ 3.2019e-01],\n",
       "            ...,\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05],\n",
       "            [ 1.0451e-05]],\n",
       "  \n",
       "           [[ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            [ 3.2091e-01],\n",
       "            ...,\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08],\n",
       "            [-9.4995e-08]],\n",
       "  \n",
       "           [[ 3.1582e-01],\n",
       "            [ 3.1582e-01],\n",
       "            [ 3.1582e-01],\n",
       "            ...,\n",
       "            [-7.3153e-06],\n",
       "            [-7.3153e-06],\n",
       "            [-7.3153e-06]],\n",
       "  \n",
       "           [[ 3.2181e-01],\n",
       "            [ 3.2181e-01],\n",
       "            [ 3.2181e-01],\n",
       "            ...,\n",
       "            [ 4.5274e-06],\n",
       "            [ 4.5274e-06],\n",
       "            [ 4.5274e-06]],\n",
       "  \n",
       "           [[ 3.2686e-01],\n",
       "            [ 3.2686e-01],\n",
       "            [ 3.2686e-01],\n",
       "            ...,\n",
       "            [-3.5299e-06],\n",
       "            [-3.5299e-06],\n",
       "            [-3.5299e-06]],\n",
       "  \n",
       "           [[ 3.2873e-01],\n",
       "            [ 3.2873e-01],\n",
       "            [ 3.2873e-01],\n",
       "            ...,\n",
       "            [-5.4173e-06],\n",
       "            [-5.4173e-06],\n",
       "            [-5.4173e-06]]]]),\n",
       "  'y_hat': tensor([[[[ 0.2367],\n",
       "            [ 0.3204],\n",
       "            [ 0.3197],\n",
       "            ...,\n",
       "            [-0.0074],\n",
       "            [-0.0074],\n",
       "            [ 0.0243]],\n",
       "  \n",
       "           [[ 0.1712],\n",
       "            [ 0.3176],\n",
       "            [ 0.3168],\n",
       "            ...,\n",
       "            [-0.0125],\n",
       "            [-0.0125],\n",
       "            [-0.0097]],\n",
       "  \n",
       "           [[ 0.1613],\n",
       "            [ 0.3376],\n",
       "            [ 0.3373],\n",
       "            ...,\n",
       "            [-0.0010],\n",
       "            [-0.0010],\n",
       "            [ 0.0971]],\n",
       "  \n",
       "           [[ 0.2961],\n",
       "            [ 0.3303],\n",
       "            [ 0.3292],\n",
       "            ...,\n",
       "            [-0.0094],\n",
       "            [-0.0094],\n",
       "            [ 0.0282]],\n",
       "  \n",
       "           [[ 0.2481],\n",
       "            [ 0.3037],\n",
       "            [ 0.3032],\n",
       "            ...,\n",
       "            [-0.0083],\n",
       "            [-0.0084],\n",
       "            [ 0.0192]],\n",
       "  \n",
       "           [[-0.0189],\n",
       "            [ 0.3447],\n",
       "            [ 0.3447],\n",
       "            ...,\n",
       "            [-0.0023],\n",
       "            [-0.0023],\n",
       "            [ 0.0535]]]]),\n",
       "  'mask': tensor([[[[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]],\n",
       "  \n",
       "           [[True],\n",
       "            [True],\n",
       "            [True],\n",
       "            ...,\n",
       "            [True],\n",
       "            [True],\n",
       "            [True]]]])}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34]),\n",
       " 'val': array([47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]),\n",
       " 'test': array([72, 73, 74, 75, 76, 77, 78])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Load the dataset\n",
    "ds = xr.open_dataset(\n",
    "    'ml-drought-forecasting/soil-water-forecasting/data/04_feature/features.nc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(ds['date'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import xarray as xr\n",
    "\n",
    "# 1. Load Metadata and Dates\n",
    "metadata_array = np.load('ml-drought-forecasting/soil-water-forecasting/data/05_model_input/metadata.npy')  # Shape: (21960, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = metadata_array[:, 0]\n",
    "longitudes = metadata_array[:, 1]\n",
    "num_nodes = len(latitudes)\n",
    "total_time_steps = len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Correctly Retrieve the Split Indices\n",
    "split_indices = datamodule.splitter.indices\n",
    "train_indices = split_indices['train']\n",
    "val_indices = split_indices['val']\n",
    "test_indices = split_indices['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Predictions and Actual Values\n",
    "y_list = []\n",
    "y_hat_list = []\n",
    "mask_list = []\n",
    "\n",
    "for batch in predictions_test:\n",
    "    y_tensor = batch['y']\n",
    "    y_hat_tensor = batch['y_hat']\n",
    "    mask_tensor = batch['mask']\n",
    "    \n",
    "    y_np = y_tensor.cpu().numpy().squeeze(-1)      # Shape: (batch_size, steps, nodes)\n",
    "    y_hat_np = y_hat_tensor.cpu().numpy().squeeze(-1)\n",
    "    mask_np = mask_tensor.cpu().numpy().squeeze(-1)\n",
    "    \n",
    "    y_list.append(y_np)\n",
    "    y_hat_list.append(y_hat_np)\n",
    "    mask_list.append(mask_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate along the batch dimension\n",
    "y = np.concatenate(y_list, axis=0)         # Shape: (num_test_batches, steps, nodes)\n",
    "y_hat = np.concatenate(y_hat_list, axis=0) # Shape: (num_test_batches, steps, nodes)\n",
    "mask = np.concatenate(mask_list, axis=0)   # Shape: (num_test_batches, steps, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Node IDs to Geographical Coordinates\n",
    "num_steps = y.shape[1]          # Number of prediction steps (e.g., 6)\n",
    "num_test_dates = y.shape[0]     # Number of test dates (e.g., 25)\n",
    "\n",
    "# Create node_ids, lat, lon repeated for each step\n",
    "node_ids = np.tile(np.arange(num_nodes), num_test_dates * num_steps)  # Shape: (3,294,000,)\n",
    "lat_column = np.tile(latitudes, num_test_dates * num_steps)\n",
    "lon_column = np.tile(longitudes, num_test_dates * num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align Predictions with Dates\n",
    "\n",
    "# Repeat each test date for the number of prediction steps\n",
    "test_dates_steps = np.repeat(dates[test_indices], num_steps)  # Shape: (25 * 6,) => (150,)\n",
    "\n",
    "# Now, repeat each date for all nodes to align with the predictions\n",
    "all_dates_expanded = np.repeat(test_dates_steps, num_nodes)   # Shape: (150 * 21960,) => (3,294,000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Flatten the Predictions and Mask\n",
    "y_flat = y.flatten()         # Shape: (3,294,000,)\n",
    "y_hat_flat = y_hat.flatten()\n",
    "mask_flat = mask.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Apply Mask to Filter Valid Entries\n",
    "valid_indices = mask_flat.astype(bool)  # Ensure mask is boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dates = all_dates_expanded[valid_indices]  # Shape: (num_valid_entries,)\n",
    "filtered_lat = lat_column[valid_indices]\n",
    "filtered_lon = lon_column[valid_indices]\n",
    "filtered_y = y_flat[valid_indices]\n",
    "filtered_y_hat = y_hat_flat[valid_indices]\n",
    "filtered_node_ids = node_ids[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'date': filtered_dates,\n",
    "    'lat': filtered_lat,\n",
    "    'lon': filtered_lon,\n",
    "    'node_id': filtered_node_ids,\n",
    "    'y': filtered_y,\n",
    "    'y_hat': filtered_y_hat\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>node_id</th>\n",
       "      <th>y</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298288</td>\n",
       "      <td>0.230512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298288</td>\n",
       "      <td>0.289690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.298288</td>\n",
       "      <td>0.289128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.298288</td>\n",
       "      <td>0.289128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.298288</td>\n",
       "      <td>0.289128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736715</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>65155</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.002268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736716</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>65156</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736717</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>65157</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736718</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>65158</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736719</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>65159</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.053494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2736720 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   lat    lon  node_id         y     y_hat\n",
       "0       2022-01-01 -90.0    0.0        0  0.298288  0.230512\n",
       "1       2022-01-01 -90.0    1.0        1  0.298288  0.289690\n",
       "2       2022-01-01 -90.0    2.0        2  0.298288  0.289128\n",
       "3       2022-01-01 -90.0    3.0        3  0.298288  0.289128\n",
       "4       2022-01-01 -90.0    4.0        4  0.298288  0.289128\n",
       "...            ...   ...    ...      ...       ...       ...\n",
       "2736715 2022-07-01  90.0  355.0    65155 -0.000005 -0.002268\n",
       "2736716 2022-07-01  90.0  356.0    65156 -0.000005 -0.002290\n",
       "2736717 2022-07-01  90.0  357.0    65157 -0.000005 -0.002290\n",
       "2736718 2022-07-01  90.0  358.0    65158 -0.000005 -0.002266\n",
       "2736719 2022-07-01  90.0  359.0    65159 -0.000005  0.053494\n",
       "\n",
       "[2736720 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('ml-drought-forecasting/ml-modeling-pipeline/data/07_model_output/predictions.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_variable_on_map(\n",
    "    dataset: pd.DataFrame,\n",
    "    variable: str,\n",
    "    lat_dim: str = 'latitude',\n",
    "    lon_dim: str = 'longitude',\n",
    "    projection: str = 'natural earth',\n",
    "    color_scale: str = 'Viridis',\n",
    "    title: Optional[str] = None,\n",
    "    animation_frame: Optional[str] = None,\n",
    "    hover_precision: int = 2,\n",
    ") -> go.Figure:\n",
    "\n",
    "    df = dataset\n",
    "\n",
    "    # Drop NaNs\n",
    "    df = df.dropna(subset=[variable])\n",
    "\n",
    "    # Handle animation frame\n",
    "    if animation_frame:\n",
    "        df[animation_frame] = df[animation_frame].astype(str)\n",
    "    else:\n",
    "        df['Frame'] = 'Frame'\n",
    "    \n",
    "    # Create scatter_geo plot\n",
    "    fig = px.scatter_geo(\n",
    "        df,\n",
    "        lat=lat_dim,\n",
    "        lon=lon_dim,\n",
    "        color=variable,\n",
    "        animation_frame=animation_frame if animation_frame else 'Frame',\n",
    "        projection=projection,\n",
    "        color_continuous_scale=color_scale,\n",
    "        title=title,\n",
    "        labels={variable: variable.upper()},\n",
    "        hover_data={variable: f':.{hover_precision}f'},\n",
    "    )\n",
    "    \n",
    "    # Add Play/Pause buttons\n",
    "    fig.update_layout(\n",
    "        updatemenus=[dict(\n",
    "            type='buttons',\n",
    "            buttons=[\n",
    "                dict(label='Play',\n",
    "                     method='animate',\n",
    "                     args=[None, {\"frame\": {\"duration\": 500, \"redraw\": True}, \"fromcurrent\": True}]),\n",
    "                dict(label='Pause',\n",
    "                     method='animate',\n",
    "                     args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}])\n",
    "            ],\n",
    "            showactive=False,\n",
    "            x=0.1,\n",
    "            y=0\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "fig = visualize_variable_on_map(\n",
    "    dataset=df,\n",
    "    variable='y',\n",
    "    lat_dim='lat',\n",
    "    lon_dim='lon',\n",
    "    animation_frame='date',\n",
    "    title='Volumetric soil water layer 1',\n",
    "    color_scale = [\n",
    "        [0.0, \"darkred\"],\n",
    "        [0.1, \"red\"],\n",
    "        [0.2, \"orangered\"],\n",
    "        [0.3, \"lightgreen\"],\n",
    "        [0.4, \"limegreen\"],\n",
    "        [0.5, \"green\"],\n",
    "        [0.55, \"darkseagreen\"],\n",
    "        [0.6, \"darkgreen\"],\n",
    "        [0.7, \"lightblue\"],\n",
    "        [0.8, \"skyblue\"],\n",
    "        [0.9, \"deepskyblue\"],\n",
    "        [1.0, \"blue\"]\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_plotly(predictions, metadata, idx, horizon=None, \n",
    "                                 batches_to_visualize=None, variables_to_visualize=None):\n",
    "    \"\"\"\n",
    "    Visualize predicted vs actual values using Plotly for specified batches and variables with variable-specific normalization.\n",
    "    \n",
    "    Parameters:\n",
    "    - predictions (dict): Contains 'y' and 'y_hat' tensors.\n",
    "    - metadata (pd.DataFrame): DataFrame with 'lat' and 'lon' columns.\n",
    "    - idx (int): Index of the item being visualized.\n",
    "    - horizon (int, optional): Number of time steps to visualize. Defaults to the maximum horizon in data.\n",
    "    - batches_to_visualize (list or range, optional): List of batch indices to visualize. Defaults to all batches.\n",
    "    - variables_to_visualize (list or range, optional): List of variable indices to visualize. Defaults to all variables.\n",
    "    \"\"\"\n",
    "    # Extract predictions and actual values\n",
    "    y_hat = predictions['y_hat'].squeeze().numpy()  # Shape: [batch, horizon, spatial_dim, variables]\n",
    "    y = predictions['y'].squeeze().numpy()          # Shape: [batch, horizon, spatial_dim, variables]\n",
    "\n",
    "    # Ensure y_hat and y have the same shape\n",
    "    assert y_hat.shape == y.shape, \"Predictions and actual values must have the same shape\"\n",
    "\n",
    "    # Determine the horizon if not provided\n",
    "    if horizon is None:\n",
    "        horizon = y_hat.shape[1]\n",
    "\n",
    "    # Determine the number of variables\n",
    "    if y_hat.ndim == 3:\n",
    "        # Shape: [batch, horizon, spatial_dim]\n",
    "        num_variables = 1\n",
    "        y_hat = y_hat[..., np.newaxis]  # Add a variables dimension\n",
    "        y = y[..., np.newaxis]\n",
    "    else:\n",
    "        num_variables = y_hat.shape[-1]\n",
    "\n",
    "    if variables_to_visualize is None:\n",
    "        variables_to_visualize = list(range(num_variables))\n",
    "    else:\n",
    "        # Ensure the variable indices are within the correct range\n",
    "        variables_to_visualize = [v for v in variables_to_visualize if v < num_variables]\n",
    "        if not variables_to_visualize:\n",
    "            raise ValueError(\"No valid variables to visualize. Check 'variables_to_visualize' indices.\")\n",
    "\n",
    "    # Get latitude and longitude from metadata\n",
    "    lats = metadata['lat'].values\n",
    "    lons = metadata['lon'].values\n",
    "\n",
    "    # Ensure that the number of spatial points matches the number of lats and lons\n",
    "    spatial_dim = y_hat.shape[2]\n",
    "    if spatial_dim != len(lats):\n",
    "        raise ValueError(f\"The number of spatial points in predictions ({spatial_dim}) does not match the number of locations in metadata ({len(lats)}).\")\n",
    "\n",
    "    # Calculate the min and max for lats and lons for setting map extent\n",
    "    lat_min, lat_max = lats.min(), lats.max()\n",
    "    lon_min, lon_max = lons.min(), lons.max()\n",
    "\n",
    "    # If batches_to_visualize is None, visualize all batches\n",
    "    if batches_to_visualize is None:\n",
    "        batches_to_visualize = range(y_hat.shape[0])\n",
    "    else:\n",
    "        # Ensure the batch indices are within the correct range\n",
    "        batches_to_visualize = [b for b in batches_to_visualize if b < y_hat.shape[0]]\n",
    "        if not batches_to_visualize:\n",
    "            raise ValueError(\"No valid batches to visualize. Check 'batches_to_visualize' indices.\")\n",
    "\n",
    "    # Precompute min and max for each variable in variables_to_visualize\n",
    "    var_min_max = {}\n",
    "    for var in variables_to_visualize:\n",
    "        var_data_y = y[..., var]  # Shape: [batch, horizon, spatial_dim]\n",
    "        var_data_y_hat = y_hat[..., var]  # Shape: [batch, horizon, spatial_dim]\n",
    "        min_val = min(np.min(var_data_y), np.min(var_data_y_hat))\n",
    "        max_val = max(np.max(var_data_y), np.max(var_data_y_hat))\n",
    "        import numpy as np\n",
    "\n",
    "        # ...\n",
    "\n",
    "        # Loop through each batch and variable\n",
    "        for batch in batches_to_visualize:\n",
    "            for var in variables_to_visualize:\n",
    "                frames = []\n",
    "                slider_steps = []\n",
    "\n",
    "                # Retrieve normalization for the current variable\n",
    "                min_val, max_val = var_min_max[var]\n",
    "\n",
    "                # Get the highest and lowest values of the variable\n",
    "                var_min = np.min(y_hat[batch, :, :, var])\n",
    "                var_max = np.max(y_hat[batch, :, :, var])\n",
    "\n",
    "                # Update the min and max values if necessary\n",
    "                if var_min < min_val:\n",
    "                    min_val = var_min\n",
    "                if var_max > max_val:\n",
    "                    max_val = var_max\n",
    "\n",
    "                # Update the normalization dictionary\n",
    "                var_min_max[var] = (min_val, max_val)\n",
    "\n",
    "                # ...\n",
    "\n",
    "                # Predicted data for current month\n",
    "                pred_data = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y_hat[batch, time_step, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Predicted'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Predicted',\n",
    "                    showlegend=False\n",
    "                )\n",
    "\n",
    "                # Actual data for current month\n",
    "                actual_data = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y[batch, time_step, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Actual'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Actual',\n",
    "                    showlegend=False\n",
    "                )\n",
    "\n",
    "                # ...\n",
    "\n",
    "                # Initial data (first frame)\n",
    "                pred_data_initial = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y_hat[batch, 0, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Predicted'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Predicted',\n",
    "                    showlegend=True\n",
    "                )\n",
    "\n",
    "                actual_data_initial = go.Scattergeo(\n",
    "                    lon=lons,\n",
    "                    lat=lats,\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=y[batch, 0, :, var],\n",
    "                        colorscale='RdYlBu_r',\n",
    "                        cmin=min_val,\n",
    "                        cmax=max_val,\n",
    "                        colorbar=dict(title='Actual'),\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name='Actual',\n",
    "                    showlegend=True\n",
    "                )\n",
    "\n",
    "                # ...\n",
    "                        visible=True,\n",
    "                        prefix=\"Date: \",\n",
    "                        xanchor=\"right\",\n",
    "                        font=dict(size=14, color=\"#666\")\n",
    "                    ),\n",
    "                )],\n",
    "                geo=dict(\n",
    "                    scope='world',\n",
    "                    projection_type='natural earth',\n",
    "                    showland=True,\n",
    "                    landcolor='lightgray',\n",
    "                    showcountries=True,\n",
    "                    countrycolor='black',\n",
    "                    lataxis=dict(range=[lat_min - 1, lat_max + 1]),\n",
    "                    lonaxis=dict(range=[lon_min - 1, lon_max + 1]),\n",
    "                ),\n",
    "                geo2=dict(\n",
    "                    scope='world',\n",
    "                    projection_type='natural earth',\n",
    "                    showland=True,\n",
    "                    landcolor='lightgray',\n",
    "                    showcountries=True,\n",
    "                    countrycolor='black',\n",
    "                    lataxis=dict(range=[lat_min - 1, lat_max + 1]),\n",
    "                    lonaxis=dict(range=[lon_min - 1, lon_max + 1]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Update frames to assign traces to correct subplots\n",
    "            for frame in fig.frames:\n",
    "                time_step_idx = int(frame.name.split()[1]) - 1\n",
    "                frame.data = [\n",
    "                    go.Scattergeo(\n",
    "                        lon=lons,\n",
    "                        lat=lats,\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=6,\n",
    "                            color=y_hat[batch, time_step_idx, :, var],\n",
    "                            colorscale='RdYlBu_r',\n",
    "                            cmin=min_val,\n",
    "                            cmax=max_val,\n",
    "                            opacity=0.8\n",
    "                        ),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    go.Scattergeo(\n",
    "                        lon=lons,\n",
    "                        lat=lats,\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=6,\n",
    "                            color=y[batch, time_step_idx, :, var],\n",
    "                            colorscale='RdYlBu_r',\n",
    "                            cmin=min_val,\n",
    "                            cmax=max_val,\n",
    "                            opacity=0.8\n",
    "                        ),\n",
    "                        showlegend=False\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            # Update layout for better appearance\n",
    "            fig.update_layout(\n",
    "                height=600,\n",
    "                width=1200,\n",
    "                margin=dict(l=50, r=50, t=100, b=50)\n",
    "            )\n",
    "\n",
    "            # Display the figure\n",
    "            fig.show()\n",
    "\n",
    "            # Optionally, save the figure to an HTML file\n",
    "            # fig.write_html(f'item_{idx+1}_batch_{batch+1}_variable_{var+1}.html')\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# Assuming you have the metadata DataFrame available\n",
    "# metadata = pd.read_parquet('ml-drought-forecasting/ml-modeling-pipeline/data/05_model_input/metadata.parquet')\n",
    "\n",
    "# Ensure that predictions_test is a list of dictionaries with 'y' and 'y_hat'\n",
    "# For example:\n",
    "# predictions_test = [{'y': tensor1, 'y_hat': tensor2}, {'y': tensor3, 'y_hat': tensor4}, ...]\n",
    "\n",
    "# # Specify the indices of the items you want to visualize\n",
    "# items_to_visualize = [1]  # Replace with desired item indices (0-based indexing)\n",
    "# batches_to_visualize = [0, 1]  # Replace with desired batch indices within each item\n",
    "# variables_to_visualize = [0]  # Replace with desired variable indices (e.g., if multiple EDDI metrics)\n",
    "\n",
    "# # Call the function for specified items in predictions_test\n",
    "# for idx in items_to_visualize:\n",
    "#     pred = predictions_test[idx]\n",
    "#     visualize_predictions_plotly(\n",
    "#         pred, metadata, idx, horizon=pred['y'].shape[1],\n",
    "#         batches_to_visualize=batches_to_visualize, \n",
    "#         variables_to_visualize=variables_to_visualize\n",
    "#     )\n",
    "#     print(f\"Processed item {idx + 1}/{len(predictions_test)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
