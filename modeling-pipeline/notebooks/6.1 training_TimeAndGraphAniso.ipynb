{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training notebook \n",
    "\n",
    "In this notebook, we will create the graph, build the STGNN model, perform training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SoilWaterDataset object \n",
    "\n",
    "SoilWaterDataset is a fundamental object created based on TabularDataset from the TSL library. Using this object, we will be able to enabling efficient loading, preprocessing, and spatiotemporal structuring of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from tsl.datasets.prototypes import TabularDataset\n",
    "from tsl.ops.similarities import gaussian_kernel\n",
    "\n",
    "class SoilWaterDataset(TabularDataset):\n",
    "\n",
    "    similarity_options = {'distance', 'grid'}\n",
    "\n",
    "    def __init__(self,\n",
    "                 root: str = None\n",
    "                 ):\n",
    "\n",
    "        self.root = root\n",
    "\n",
    "        # Load data\n",
    "        target, mask, u, dist, metadata = self.load()\n",
    "\n",
    "        covariates = {\n",
    "            'u': (u),\n",
    "            'metadata' : (metadata),\n",
    "            'distances': (dist)\n",
    "        }\n",
    "\n",
    "        super().__init__(target=target,\n",
    "                         mask=mask,\n",
    "                         covariates=covariates,\n",
    "                         similarity_score='distance',\n",
    "                         temporal_aggregation='mean',\n",
    "                         spatial_aggregation='mean',\n",
    "                         name='SoilWaterDataset')\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load data from files.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Containing target, mask, covariates, distances, and metadata.\n",
    "        \"\"\"\n",
    "        target_path = f\"{self.root}target.npy\"\n",
    "        mask_path = f\"{self.root}mask.npy\"\n",
    "        dist_path = f\"{self.root}distance_matrix.npy\"\n",
    "        covariates_path = f\"{self.root}covariates.npy\"\n",
    "        metadata_path = f\"{self.root}metadata.npy\"\n",
    "\n",
    "        target = np.load(target_path)\n",
    "        mask = np.load(mask_path)\n",
    "        u = np.load(covariates_path)\n",
    "        dist = np.load(dist_path)\n",
    "        metadata = np.load(metadata_path)\n",
    "\n",
    "        return target, mask, u, dist, metadata\n",
    "\n",
    "\n",
    "    def compute_similarity(self, method: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute similarity matrix based on the specified method.\n",
    "\n",
    "        Args:\n",
    "            method (str): The similarity computation method ('distance' or 'grid').\n",
    "            **kwargs: Additional keyword arguments for similarity computation.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Computed similarity matrix.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unknown similarity method is provided.\n",
    "        \"\"\"\n",
    "        if method == \"distance\":\n",
    "            # Calculate a Gaussian kernel similarity from the distance matrix, using a default or provided 'theta'\n",
    "            theta = kwargs.get('theta', np.std(self.distances))\n",
    "            return gaussian_kernel(self.distances, theta=theta)\n",
    "        elif method == \"grid\":\n",
    "            dist = self.distances.copy()\n",
    "            dist[dist > 16] = np.inf  # keep only grid edges\n",
    "            theta = kwargs.get('theta', 20)\n",
    "            return gaussian_kernel(dist, theta=theta)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown similarity method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SoilWaterDataset(root='soil-water-forecasting/modeling-pipeline/data/05_model_input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.16496307],\n",
       "        [0.16496307],\n",
       "        [0.16496307],\n",
       "        ...,\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ]],\n",
       "\n",
       "       [[0.16687536],\n",
       "        [0.16687536],\n",
       "        [0.16687536],\n",
       "        ...,\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ]],\n",
       "\n",
       "       [[0.16724145],\n",
       "        [0.16724145],\n",
       "        [0.16724145],\n",
       "        ...,\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.29661715],\n",
       "        [0.29661715],\n",
       "        [0.29661715],\n",
       "        ...,\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ]],\n",
       "\n",
       "       [[0.29527402],\n",
       "        [0.29527402],\n",
       "        [0.29527402],\n",
       "        ...,\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ]],\n",
       "\n",
       "       [[0.29758725],\n",
       "        [0.29758725],\n",
       "        [0.29758725],\n",
       "        ...,\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has missing values: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Has missing values: {dataset.has_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]],\n",
       "\n",
       "       [[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_mask(dataset.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u': array([[[ 3.0585480e-01, -1.2989902e-01,  2.4335590e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         [ 3.0585480e-01, -1.2989902e-01,  2.4335590e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         [ 3.0585480e-01, -1.2989902e-01,  2.4335590e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         ...,\n",
       "         [-7.7445984e-02,  3.2210350e-02,  2.5064105e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00],\n",
       "         [-7.7445984e-02,  3.2210350e-02,  2.5064105e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00],\n",
       "         [-7.7445984e-02,  3.2210350e-02,  2.5064105e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00]],\n",
       " \n",
       "        [[ 4.1980553e-01,  1.1558628e-01,  2.3336655e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         [ 4.1980553e-01,  1.1558628e-01,  2.3336655e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         [ 4.1980553e-01,  1.1558628e-01,  2.3336655e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  1.0000000e+00],\n",
       "         ...,\n",
       "         [-4.7479630e-02,  6.0898781e-02,  2.5171616e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00],\n",
       "         [-4.7479630e-02,  6.0898781e-02,  2.5171616e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00],\n",
       "         [-4.7479630e-02,  6.0898781e-02,  2.5171616e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  1.0000000e+00]],\n",
       " \n",
       "        [[ 6.0301781e-01,  8.3531380e-02,  2.2287155e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  2.0000000e+00],\n",
       "         [ 6.0301781e-01,  8.3531380e-02,  2.2287155e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  2.0000000e+00],\n",
       "         [ 6.0301781e-01,  8.3531380e-02,  2.2287155e+02, ...,\n",
       "           0.0000000e+00,  2.7355104e+04,  2.0000000e+00],\n",
       "         ...,\n",
       "         [-5.2743912e-02,  6.9371223e-02,  2.5145749e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  2.0000000e+00],\n",
       "         [-5.2743912e-02,  6.9371223e-02,  2.5145749e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  2.0000000e+00],\n",
       "         [-5.2743912e-02,  6.9371223e-02,  2.5145749e+02, ...,\n",
       "           0.0000000e+00,  3.2275391e-01,  2.0000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4.4391603e+00, -9.8398209e-02,  2.2407355e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         [ 4.4391603e+00, -9.8398209e-02,  2.2407355e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         [ 4.4391603e+00, -9.8398209e-02,  2.2407355e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         ...,\n",
       "         [-3.6003904e+00, -1.3160133e-01,  2.6177277e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00],\n",
       "         [-3.6003904e+00, -1.3160133e-01,  2.6177277e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00],\n",
       "         [-3.6003904e+00, -1.3160133e-01,  2.6177277e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00]],\n",
       " \n",
       "        [[ 3.4496737e+00,  8.2430935e-01,  2.3500414e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         [ 3.4496737e+00,  8.2430935e-01,  2.3500414e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         [ 3.4496737e+00,  8.2430935e-01,  2.3500414e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  4.0000000e+00],\n",
       "         ...,\n",
       "         [ 3.6099434e-02,  4.0194607e-01,  2.5241820e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00],\n",
       "         [ 3.6099434e-02,  4.0194607e-01,  2.5241820e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00],\n",
       "         [ 3.6099434e-02,  4.0194607e-01,  2.5241820e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  4.0000000e+00]],\n",
       " \n",
       "        [[ 2.9151220e+00,  9.7912121e-01,  2.4445224e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  1.0000000e+00],\n",
       "         [ 2.9151220e+00,  9.7912121e-01,  2.4445224e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  1.0000000e+00],\n",
       "         [ 2.9151220e+00,  9.7912121e-01,  2.4445224e+02, ...,\n",
       "           0.0000000e+00,  2.7718275e+04,  1.0000000e+00],\n",
       "         ...,\n",
       "         [-8.4366703e-01,  3.3624220e+00,  2.4979794e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  1.0000000e+00],\n",
       "         [-8.4366703e-01,  3.3624220e+00,  2.4979794e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  1.0000000e+00],\n",
       "         [-8.4366703e-01,  3.3624220e+00,  2.4979794e+02, ...,\n",
       "           0.0000000e+00, -1.2397461e+00,  1.0000000e+00]]], dtype=float32),\n",
       " 'metadata': array([[-90.,   0.],\n",
       "        [-90.,   1.],\n",
       "        [-90.,   2.],\n",
       "        ...,\n",
       "        [ 90., 357.],\n",
       "        [ 90., 358.],\n",
       "        [ 90., 359.]], dtype=float32),\n",
       " 'distances': array([[0.0000000e+00, 6.8086486e-15, 1.3616779e-14, ..., 2.0015115e+04,\n",
       "         2.0015115e+04, 2.0015115e+04],\n",
       "        [6.8086486e-15, 0.0000000e+00, 6.8086486e-15, ..., 2.0015115e+04,\n",
       "         2.0015115e+04, 2.0015115e+04],\n",
       "        [1.3616779e-14, 6.8086486e-15, 0.0000000e+00, ..., 2.0015115e+04,\n",
       "         2.0015115e+04, 2.0015115e+04],\n",
       "        ...,\n",
       "        [2.0015115e+04, 2.0015115e+04, 2.0015115e+04, ..., 0.0000000e+00,\n",
       "         6.8086486e-15, 1.3616779e-14],\n",
       "        [2.0015115e+04, 2.0015115e+04, 2.0015115e+04, ..., 6.8086486e-15,\n",
       "         0.0000000e+00, 6.8086486e-15],\n",
       "        [2.0015115e+04, 2.0015115e+04, 2.0015115e+04, ..., 1.3616779e-14,\n",
       "         6.8086486e-15, 0.0000000e+00]], dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create connectivity to our graph \n",
    "\n",
    "Here, we adjust the connectivity to retain only the five nearest neighbors (knn=5) per node, while excluding self-loops and normalizing along the specified axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:38:41.500430Z",
     "start_time": "2024-11-08T18:38:41.498443Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim = dataset.compute_similarity(\"distance\")  # or dataset.compute_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adjust connectivity to reduce the number of edges\n",
    "# connectivity = dataset.get_connectivity(  \n",
    "#     method='distance',\n",
    "#     knn=4,     \n",
    "#     include_self=False,\n",
    "#     force_symmetric=True, \n",
    "#     layout=\"csr\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14278/3741746759.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  connectivity = torch.load(\"soil-water-forecasting/modeling-pipeline/data/05_model_input/connectivity.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "connectivity = torch.load(\"soil-water-forecasting/modeling-pipeline/data/05_model_input/connectivity.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create torch_dataset \n",
    "\n",
    "torch_dataset, created using SpatioTemporalDataset from the tsl library, structures time-series and spatial data (target, covariates, mask, and connectivity) into a form optimized for spatiotemporal model training, enabling easy handling of lookback windows and prediction horizons in forecasting tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data import SpatioTemporalDataset\n",
    "\n",
    "# covariates=dict(u=dataset.covariates['u'])\n",
    "covariates=dataset.covariates\n",
    "mask = dataset.mask\n",
    "\n",
    "torch_dataset = SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      mask=mask,\n",
    "                                      covariates=covariates,\n",
    "                                      connectivity=connectivity,\n",
    "                                      horizon=6, \n",
    "                                      window=12, \n",
    "                                      stride=1 \n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]],\n",
       "\n",
       "        [[True],\n",
       "         [True],\n",
       "         [True],\n",
       "         ...,\n",
       "         [True],\n",
       "         [True],\n",
       "         [True]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dataset.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datamodule\n",
    "\n",
    "datamodule, created with SpatioTemporalDataModule, manages the SpatioTemporalDataset by applying scaling, splitting data into train/validation/test sets, and preparing data loaders with batch processing, enabling efficient, modular, and scalable data handling for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scalers = {\n",
    "    'target': MinMaxScaler(axis=(0, 1)),\n",
    "    'u': MinMaxScaler(axis=(0, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "                                 \n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=0.35, test_len=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=None, val_len=None, test_len=None, scalers=[target, u], batch_size=1)\n"
     ]
    }
   ],
   "source": [
    "# Create a SpatioTemporalDataModule\n",
    "datamodule = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    mask_scaling=True,\n",
    "    splitter=splitter,\n",
    "    batch_size=1  # Reduce batch size\n",
    "    )\n",
    "\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatioTemporalDataModule(train_len=28, val_len=9, test_len=6, scalers=[target, u], batch_size=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]),\n",
       " 'val': array([40, 41, 42, 43, 44, 45, 46, 47, 48]),\n",
       " 'test': array([61, 62, 63, 64, 65, 66])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.splitter.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create STGNN Model Architecture\n",
    "\n",
    "The **TimeAndGraphAnisoModel** is built based on code from [HD-TTS\n",
    " repository](https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/time_and_graph_anisotropic.py) and the research paper by Cini et al. (2023d). This model utilizes spatiotemporal architectures equipped with anisotropic message passing for effective time and space representation.\n",
    "\n",
    "### Reference\n",
    "Cini, A., Marisca, I., Zambon, D., and Alippi, C. *Taming Local Effects in Graph-Based Spatiotemporal Forecasting.* In *Advances in Neural Information Processing Systems,* volume 36, pp. 55375–55393. Curran Associates, Inc., 2023.  \n",
    "[https://arxiv.org/abs/2302.04071](https://arxiv.org/abs/2302.04071)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/layers/anisotropic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from tsl.nn.blocks import RNNBase\n",
    "from tsl.nn.layers import Dense, GraphGRUCellBase, Activation\n",
    "\n",
    "\n",
    "class GraphAnisoConv(MessagePassing):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 1,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        super(GraphAnisoConv, self).__init__(aggr=\"add\", node_dim=-2)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.msg_mlps = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2 * (in_channels if i == 0 else out_channels),\n",
    "                          out_channels),\n",
    "                Activation(activation),\n",
    "                nn.Linear(out_channels, out_channels),\n",
    "            )\n",
    "            for i in range(kernel_size)\n",
    "        ])\n",
    "\n",
    "        edge_dim = edge_dim or 1  # accommodate for edge_weight\n",
    "        self.lin_edge = nn.Linear(edge_dim, out_channels, bias=False)\n",
    "\n",
    "        self.gate_mlp = Dense(out_channels, 1, activation='sigmoid')\n",
    "\n",
    "        self.skip_conn = nn.Linear(in_channels, out_channels)\n",
    "        self.activation = Activation(activation)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr: Optional[Tensor] = None):\n",
    "        \"\"\"\"\"\"\n",
    "        out, x_ = 0, x\n",
    "        for idx in range(self.kernel_size):\n",
    "            x_ = self.propagate(edge_index, idx=idx, x=x_, edge_attr=edge_attr)\n",
    "            out += x_\n",
    "        out = self.activation(out + self.skip_conn(x))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, idx, edge_attr: Optional[Tensor] = None):\n",
    "        mij = self.msg_mlps[idx](torch.cat([x_i, x_j], -1))\n",
    "        if edge_attr is not None:\n",
    "            if edge_attr.ndim == 1:  # accommodate for edge_weight\n",
    "                edge_attr = edge_attr.view(-1, 1)\n",
    "            mij = mij + self.lin_edge(edge_attr)\n",
    "        return self.gate_mlp(mij) * mij\n",
    "\n",
    "\n",
    "class GraphAnisoGRUCell(GraphGRUCellBase):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        self.input_size = input_size\n",
    "        # instantiate gates\n",
    "        forget_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                     edge_dim=edge_dim, activation=activation)\n",
    "        update_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                     edge_dim=edge_dim, activation=activation)\n",
    "        candidate_gate = GraphAnisoConv(input_size + hidden_size, hidden_size,\n",
    "                                        edge_dim=edge_dim,\n",
    "                                        activation=activation)\n",
    "        super(GraphAnisoGRUCell, self).__init__(hidden_size=hidden_size,\n",
    "                                                forget_gate=forget_gate,\n",
    "                                                update_gate=update_gate,\n",
    "                                                candidate_gate=candidate_gate)\n",
    "\n",
    "\n",
    "class GraphAnisoGRU(RNNBase):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int,\n",
    "                 edge_dim: Optional[int] = None,\n",
    "                 n_layers: int = 1, cat_states_layers: bool = False,\n",
    "                 return_only_last_state: bool = False,\n",
    "                 activation: str = 'leaky_relu'):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        rnn_cells = [\n",
    "            GraphAnisoGRUCell(input_size if i == 0 else hidden_size,\n",
    "                              hidden_size, edge_dim=edge_dim,\n",
    "                              activation=activation)\n",
    "            for i in range(n_layers)\n",
    "        ]\n",
    "        super(GraphAnisoGRU, self).__init__(rnn_cells, cat_states_layers,\n",
    "                                            return_only_last_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/prototypes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch_geometric.typing import Adj\n",
    "from tsl.nn.blocks import MLPDecoder\n",
    "from tsl.nn.layers import MultiLinear, NodeEmbedding\n",
    "from tsl.nn.models import BaseModel\n",
    "from tsl.nn.utils import maybe_cat_exog\n",
    "from tsl.utils import ensure_list\n",
    "\n",
    "\n",
    "def maybe_cat_emb(x: Tensor, emb: Optional[Tensor]):\n",
    "    if emb is None:\n",
    "        return x\n",
    "    if emb.ndim < x.ndim:\n",
    "        emb = emb[[None] * (x.ndim - emb.ndim)]\n",
    "    emb = emb.expand(*x.shape[:-1], -1)\n",
    "    return torch.cat([x, emb], dim=-1)\n",
    "\n",
    "\n",
    "class STGNN(BaseModel):\n",
    "    available_embedding_pos = {'encoding', 'decoding'}\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int,\n",
    "                 n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Optional[\n",
    "                     Union[str, List[str]]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 activation: str = 'elu'):\n",
    "        super(STGNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.horizon = horizon\n",
    "        self.n_nodes = n_nodes\n",
    "        self.output_size = output_size or input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.exog_size = exog_size\n",
    "        self.activation = activation\n",
    "\n",
    "        # EMBEDDING\n",
    "        if add_embedding_before is None:\n",
    "            add_embedding_before = set()\n",
    "        else:\n",
    "            add_embedding_before = set(ensure_list(add_embedding_before))\n",
    "            if not add_embedding_before.issubset(self.available_embedding_pos):\n",
    "                raise ValueError(\"Parameter 'add_embedding_before' must be a \"\n",
    "                                 f\"subset of {self.available_embedding_pos}\")\n",
    "        self.add_embedding_before = add_embedding_before\n",
    "\n",
    "        if emb_size > 0:\n",
    "            self.emb = NodeEmbedding(n_nodes, emb_size)\n",
    "        else:\n",
    "            self.register_module('emb', None)\n",
    "\n",
    "        # ENCODER\n",
    "        self.encoder_input = input_size + exog_size\n",
    "        if 'encoding' in self.add_embedding_before and self.emb is not None:\n",
    "            self.encoder_input += emb_size\n",
    "\n",
    "        if use_local_weights is not None:\n",
    "            self.use_local_weights = set(ensure_list(use_local_weights))\n",
    "            if len(self.use_local_weights.difference(['encoder', 'decoder'])):\n",
    "                raise ValueError(\"Parameter 'use_local_weights' must be \"\n",
    "                                 \"'encoder', 'decoder', or both.\")\n",
    "        else:\n",
    "            self.use_local_weights = set()\n",
    "\n",
    "        if 'encoder' in self.use_local_weights:\n",
    "            self.encoder = MultiLinear(self.encoder_input, hidden_size, n_nodes)\n",
    "        else:\n",
    "            self.encoder = nn.Linear(self.encoder_input, hidden_size)\n",
    "\n",
    "        # DECODER\n",
    "        self.decoder_input = hidden_size\n",
    "        if 'decoding' in self.add_embedding_before and self.emb is not None:\n",
    "            self.decoder_input += emb_size\n",
    "        if 'decoder' in self.use_local_weights:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            self.decoder = MLPDecoder(input_size=self.decoder_input,\n",
    "                                      hidden_size=self.hidden_size,\n",
    "                                      output_size=self.output_size,\n",
    "                                      horizon=self.horizon,\n",
    "                                      activation=self.activation)\n",
    "\n",
    "    def stmp(self, x: Tensor, edge_index: Adj,\n",
    "             edge_weight: Optional[Tensor] = None,\n",
    "             emb: Optional[Tensor] = None) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj,\n",
    "                edge_weight: Optional[Tensor] = None,\n",
    "                u: Optional[Tensor] = None,\n",
    "                node_idx: Optional[Tensor] = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        # x: [batches steps nodes features]\n",
    "        x = maybe_cat_exog(x, u)\n",
    "        batch_size = x.size(0)\n",
    "        emb = self.emb(expand=(batch_size, -1, -1),\n",
    "                       node_index=node_idx) if self.emb is not None else None\n",
    "\n",
    "        if 'encoding' in self.add_embedding_before and emb is not None:\n",
    "            x = maybe_cat_emb(x, emb[:, None])\n",
    "\n",
    "        # ENCODER   ###########################################################\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # SPATIOTEMPORAL MESSAGE-PASSING   ####################################\n",
    "        out = self.stmp(x, edge_index, edge_weight, emb)\n",
    "\n",
    "        # DECODER   ###########################################################\n",
    "        if 'decoding' in self.add_embedding_before:\n",
    "            out = maybe_cat_emb(out, emb)\n",
    "\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TimeAndSpace(STGNN):\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int, stmp_conv: nn.Module,\n",
    "                 n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Union[str, List[str]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 activation: str = 'elu'):\n",
    "        super(TimeAndSpace, self).__init__(input_size=input_size,\n",
    "                                           horizon=horizon,\n",
    "                                           n_nodes=n_nodes,\n",
    "                                           output_size=output_size,\n",
    "                                           exog_size=exog_size,\n",
    "                                           hidden_size=hidden_size,\n",
    "                                           emb_size=emb_size,\n",
    "                                           add_embedding_before=add_embedding_before,\n",
    "                                           use_local_weights=use_local_weights,\n",
    "                                           activation=activation)\n",
    "\n",
    "        # STMP\n",
    "        self.stmp_conv = stmp_conv\n",
    "\n",
    "    def stmp(self, x: Tensor, edge_index: Adj,\n",
    "             edge_weight: Optional[Tensor] = None,\n",
    "             emb: Optional[Tensor] = None) -> Tensor:\n",
    "        # spatiotemporal encoding\n",
    "        out = self.stmp_conv(x, edge_index, edge_weight)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/marshka/hdtts/blob/main/lib/nn/models/baselines/stgnns/time_and_graph_anisotropic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "class TimeAndGraphAnisoModel(TimeAndSpace):\n",
    "\n",
    "    def __init__(self, input_size: int, horizon: int, n_nodes: int = None,\n",
    "                 output_size: int = None,\n",
    "                 exog_size: int = 0,\n",
    "                 hidden_size: int = 32,\n",
    "                 emb_size: int = 0,\n",
    "                 add_embedding_before: Union[str, List[str]] = 'encoding',\n",
    "                 use_local_weights: Union[str, List[str]] = None,\n",
    "                 n_layers: int = 1,\n",
    "                 activation: str = 'elu'):\n",
    "        stmp_conv = GraphAnisoGRU(input_size=hidden_size,\n",
    "                                  hidden_size=hidden_size,\n",
    "                                  n_layers=n_layers,\n",
    "                                  activation=activation,\n",
    "                                  return_only_last_state=True)\n",
    "        super(TimeAndGraphAnisoModel, self).__init__(\n",
    "            input_size=input_size,\n",
    "            horizon=horizon,\n",
    "            stmp_conv=stmp_conv,\n",
    "            n_nodes=n_nodes,\n",
    "            output_size=output_size,\n",
    "            exog_size=exog_size,\n",
    "            hidden_size=hidden_size,\n",
    "            emb_size=emb_size,\n",
    "            add_embedding_before=add_embedding_before,\n",
    "            use_local_weights=use_local_weights,\n",
    "            activation=activation\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model \n",
    "\n",
    "Model is configured with hidden units, feed-forward layers, multiple SpatioTemporalConvNet blocks, and utilizes temporal and spatial convolution kernels, layer normalization, and gated mechanisms; it adapts to the dataset’s input size, number of nodes, horizon, and available exogenous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 32          # Number of hidden units\n",
    "ff_size = 64             # Number of units in the feed-forward layers\n",
    "n_layers = 3              # Number of SpatioTemporalConvNet blocks\n",
    "temporal_kernel_size = 3  # Size of the temporal convolution kernel\n",
    "spatial_kernel_size = 3   # Order of the spatial diffusion process\n",
    "norm='layer'\n",
    "gated=True\n",
    "\n",
    "input_size = torch_dataset.n_channels\n",
    "n_nodes = torch_dataset.n_nodes\n",
    "horizon = torch_dataset.horizon\n",
    "exog_size = torch_dataset.input_map.u.shape[-1] if 'u' in torch_dataset else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeAndGraphAnisoModel(\n",
      "  (emb): None\n",
      "  (encoder): Linear(in_features=23, out_features=32, bias=True)\n",
      "  (decoder): MLPDecoder(\n",
      "    (readout): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Dense(\n",
      "          (affinity): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (activation): ELU(alpha=1.0)\n",
      "          (dropout): Identity()\n",
      "        )\n",
      "      )\n",
      "      (readout): Linear(in_features=32, out_features=6, bias=True)\n",
      "    )\n",
      "    (rearrange): Rearrange('b n (h f) -> b h n f', f=1, h=6)\n",
      "  )\n",
      "  (stmp_conv): GraphAnisoGRU(cell=GraphAnisoGRUCell, return_only_last_state=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TimeAndGraphAnisoModel(\n",
    "    input_size=input_size,\n",
    "    horizon=horizon,\n",
    "    n_nodes=n_nodes,\n",
    "    output_size=input_size,\n",
    "    exog_size=exog_size,\n",
    "    hidden_size=hidden_size\n",
    ")\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "Number of model (TimeAndGraphAnisoModel) parameters:     24009\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training \n",
    "\n",
    "This setup initializes a Predictor for the model with a masked mean-squared error loss function and multiple evaluation metrics (MSE, MAE, MAPE, and specific MSE at selected timesteps), then configures a Trainer using PyTorch Lightning with early stopping and model checkpointing based on validation MSE, gradient clipping to prevent exploding gradients, and 16-bit precision for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.metrics.torch import MaskedMSE, MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Predictor\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = MaskedMSE()\n",
    "\n",
    "# Setup metrics\n",
    "metrics = {\n",
    "    'mse': MaskedMSE(),\n",
    "    'mae': MaskedMAE(),\n",
    "    'mape': MaskedMAPE(),\n",
    "    'mse_at_3': MaskedMSE(at=2),  # '2' indicates the third time step\n",
    "    'mse_at_6': MaskedMSE(at=5)\n",
    "}\n",
    "\n",
    "# Setup predictor\n",
    "predictor = Predictor(\n",
    "    model=model,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs={'lr': 0.001},\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lightning.ai/docs/pytorch/stable/common/trainer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_mse',\n",
    "    patience=30,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Logs \n",
    "dirpath = Path('soil-water-forecasting/modeling-pipeline/data/06_models/TimeAndGraphAniso/logs')\n",
    "\n",
    "dirpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=dirpath,\n",
    "    save_top_k=1,\n",
    "    monitor='val_mse', \n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Setup trainer\n",
    "trainer = pl.Trainer(max_epochs=2,\n",
    "                    #  logger=logger,\n",
    "                    #  limit_train_batches=100,  # end an epoch after 200 updates\n",
    "                     callbacks=[early_stop_callback, checkpoint_callback],\n",
    "                     log_every_n_steps=2,\n",
    "                     gradient_clip_val=1.0,    # Prevent exploding gradients\n",
    "                     precision=16\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set float32 matmul precision to 'medium' or 'high'\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMSE              | 0      | train\n",
      "1 | train_metrics | MetricCollection       | 0      | train\n",
      "2 | val_metrics   | MetricCollection       | 0      | train\n",
      "3 | test_metrics  | MetricCollection       | 0      | train\n",
      "4 | model         | TimeAndGraphAnisoModel | 24.0 K | train\n",
      "-----------------------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n",
      "81        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cac570251b42d9b604450beae7639f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "Arguments ['distances', 'metadata'] are filtered out. Only args ['u', 'edge_index', 'x'] are forwarded to the model (TimeAndGraphAnisoModel).\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1924214155e74c00a70ac2194c1ee87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6809ea4c97ce4965aef6d531cc9c18e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e063402920cc48a1a3dcc0d1ab79095f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "trainer.fit(predictor, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/soil-water-forecasting/modeling-pipeline/data/06_models/TimeAndGraphAniso/logs/epoch=1-step=56.ckpt'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the best checkpoint\n",
    "best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "best_checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n",
      "Predictor with already instantiated model is loading a state_dict from /teamspace/studios/this_studio/soil-water-forecasting/modeling-pipeline/data/06_models/TimeAndGraphAniso/logs/epoch=1-step=56.ckpt. Cannot  check if model hyperparameters are the same.\n"
     ]
    }
   ],
   "source": [
    "predictor.load_model(best_checkpoint_path)\n",
    "predictor.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52a34df1fed4a49aaea072162f80b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.017232103273272514    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08050652593374252    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mape         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         33529.625         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.017232105135917664    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mse_at_3       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.016210881993174553    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mse_at_6       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01829056441783905    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.017232103273272514   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08050652593374252   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mape        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        33529.625        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.017232105135917664   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mse_at_3      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.016210881993174553   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mse_at_6      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01829056441783905   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_mae': 0.08050652593374252,\n",
       "  'test_mape': 33529.625,\n",
       "  'test_mse': 0.017232105135917664,\n",
       "  'test_mse_at_3': 0.016210881993174553,\n",
       "  'test_mse_at_6': 0.01829056441783905,\n",
       "  'test_loss': 0.017232103273272514}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(predictor, dataloaders=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f140ba8fd9a42e58851873807139e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.017223218455910683    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0805424228310585     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_mape          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        8914.265625        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.017223216593265533    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_mse_at_3        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01589186303317547    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_mse_at_6        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.018310438841581345    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.017223218455910683   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0805424228310585    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_mape         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       8914.265625       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.017223216593265533   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_mse_at_3       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01589186303317547   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_mse_at_6       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.018310438841581345   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_mae': 0.0805424228310585,\n",
       "  'val_mape': 8914.265625,\n",
       "  'val_mse': 0.017223216593265533,\n",
       "  'val_mse_at_3': 0.01589186303317547,\n",
       "  'val_mse_at_6': 0.018310438841581345,\n",
       "  'val_loss': 0.017223218455910683}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(predictor, dataloaders=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
